import helpers;
import module;
import ansi;


// TODO re: rewrite -
//
// We need a principled fn fail() here,
//  something that can relate most problems to a token somewhere in your sources,
//   so we can raise error messages with the usual formatting.


// TODO FAILCASE - doesn't parse here, weird
// fn fail = fn throw;

// TODO FAILCASE - doesn't work either
// fn fail = .throw;

fn fail(reason: string) throw(reason);


//

let TODO_FIX_ignoredWarnings = ""

    // clang issue with float->bool,
    //  if we have an explicit !! codegen this can be fixed,
    //   an x != 0 works, this can be also used for a non-zero non-nan check.
    //
    ~ "-Wno-float-conversion " // opt-out

    // gcc & clang complain about unused-but-set variables
    //  that we fail to eliminate in templated iterators,
    //   gotta figure out something, but for the time being we gotta opt out.
    //
    ~ "-Wno-unused-but-set-variable " // opt-out

    // Not every clang has unused-but-set-variable
    //
    ~ "-Wno-unknown-warning-option " // opt-out

    // Running into a bunch of weird warnings on gcc12.
    //
    // Array bounds errors after size is checked,
    //  sequence-points for assignments (RTL by standard), etc.
    //   Can't have false positives break builds.
    //
    // TODO instead of silencing them,
    //  we probably want to simply not treat them as hard errors.
    //
    ~ "-Wno-maybe-uninitialized -Wno-stringop-overflow -Wno-array-bounds -Wno-sequence-point -Wno-error=dangling-reference "

    ;



//

fn ensure_local_fname(fname: string, dir_src: string): string
{
    if (fname.starts(with: dir_src))
        return fname;

    let foreign = dir_src ~ ".foreign/";
    fs::mkdir_p(foreign);

    let rel = path::relative(from: dir_src, to: fname)
        .replace(all: "../", with: "up__")
        .replace(all:   "/", with:   "__");

    return foreign ~ rel;
}

fn tmpfile(mut dir_wrk_tmp!fname: string)
{
    mut r = rand::next_u64();
    for (mut i = 0; i < 8; i++)
    {
        let v = r & 0x1f;
        fname ~= byte(
            v < 10  ? '0'.i32 + v.i32
                    : 'a'.i32 + v.i32 - 10);
        r >>= 5;
    }

    return fname;
}

fn atomic_write(dir_wrk_tmp!: string, fname!: string, data: string)
{
    let tmp = tmpfile(:dir_wrk_tmp);

    let err = file::write(tmp, data) || file::rename(tmp, fname);
    if (err)
        file::unlink(tmp);

    return err;
}

fn update_file_dest(
    fname       !: string,
    dir_src     !: string,
    dir_cpp     !: string)
{
    shadow let fname = ensure_local_fname(:fname, :dir_src);
    fname.starts(with: dir_src) || fail("ensure_local_fname broken");

    return dir_cpp ~ fname.slice(dir_src.len);
}

fn update_file(
    fname       !: string,
    data        !: string,
    dir_src     !: string,
    dir_cpp     !: string,
    dir_wrk_tmp !: string)
{
    return update_file(
        dest: update_file_dest(:fname, :dir_src, :dir_cpp),
        :data, :dir_cpp, :dir_wrk_tmp);
}

fn update_file(
    dest!fname   : string,
    data        !: string,
    dir_cpp     !: string,
    dir_wrk_tmp !: string)
{
    mut xcheck: string;
    if (file::read(fname, into: xcheck) || xcheck != data)
    {
        for (;;)
        {
            let err = atomic_write(:fname, data, :dir_wrk_tmp);
            if (err)
            {
                if (err == Errno::ENOENT)
                {
                    mut last = -1;
                    for (mut i = dir_cpp.len + 1; i < fname.len; i++)
                        if (fname[i] == '/')
                            last = i;

                    if (last >= 0)
                        if !(fs::mkdir_p(fname.slice(0, last + 1)))
                            continue;
                }

                fail("Failed to write `" ~ fname ~ "`, error: #" ~ err);
            }

            println("  WROTE " ~ fname);
            break;
        }
    }

    return fname;
}


// TODO FIX

fn exec(cmd: string, ref stdout: string)
{
    mut status: spawn::ExitStatus = 0;
    mut err: ::Errno;

    // TODO FIX remove this nonsense -
    //  this is currently used for pkg-config queries,
    //   should run those separately instead of scripting them here
    //
    if (cmd.has("$("))
    {
        // We want "-rpath $ORIGIN" to pass through unchanged.
        shadow let cmd =
            cmd.replace(all: "$", with: "\\$")
               .replace(all: "\\$(", with: "$(");

        err = ::exec(cmd, :status, stdout);
    }
    else
        err = ::spawn(cmd.split(' '), :status, :stdout, stderr: stdout);

    return err.int || status.int;
}

pub fn gcc_version()
{
    mut stdout: string;

    let code = exec("gcc --version", :stdout);
    if (code)
    {
        if (stdout)
            stdout ~= stdout.ends(with: '\n') ? "\n" : "\n\n";

        stdout ~= "NON-ZERO EXIT CODE: " ~ code ~ "\n";
    }

    return stdout;
}


//

using flags DEV_OnFail
{
    OnFail_PrintOutput
    OnFail_WriteRepro
};

pub enum RunMode
{
    None        = 0
    Normally
    CompilerTestcase
    EnsureExecutableButDontRun
}

pub flags BuildScheme
{
    shared
    hotswap
    nocache
    watch

    // NOTE re: the weird negations here -
    //  The zerofilled default == release build, thus:
    //   - debug-symbols are opt-in,
    //   - optimizations are opt-out,
    //   - assertions are opt-in, etc.
    //
    debuggable
    unoptimized
    assertions
    TODO_FIX_retail
}

pub let DEBUG_SCHEME    = BuildScheme.debuggable
                        | BuildScheme.unoptimized
                        | BuildScheme.assertions;

pub fn tryGetScheme(name: string)
{
    if (name == "debug")
        return DEBUG_SCHEME;

    if (name == "reldeb")
        return BuildScheme.debuggable;

    return name == "retail" &&
        BuildScheme.TODO_FIX_retail;
}


//

struct BuildOutput
{
    executable:     string;
    watch_list:     string[];

    using output:   test_output::TestOutput;
};

pub fn build(
    implicit ctx: Context,

    mut dir_wrk  !: string,

    mut fulib   !?: string,

    mut bin     !?: string,
    mut dir_obj !?: string,
    mut dir_src !?: string,
    mut dir_cpp !?: string,
        unity   !?: string,
        onfail  !?: DEV_OnFail,

        // TODO clean these up, this makes NO SENSE //
        runmode !?: RunMode,    expect_exit!?: int,
        bscheme !?: BuildScheme,
        //////////////////////////////////////////////

        flags_cc!?: string[],
        flags_ld!?: string[]): BuildOutput
{
    // Where we do our dirtywork.
    if (dir_wrk.if_last != '/')
    {
        dir_wrk || fail("No workspace directory provided.");
        dir_wrk ~= '/';
    }

    //
    if (dir_obj && dir_obj.if_last != '/') dir_obj ~= '/';
    if (dir_src && dir_src.if_last != '/') dir_src ~= '/';
    if (dir_cpp && dir_cpp.if_last != '/') dir_cpp ~= '/';

    // Optimization level.
    mut O_lvl   = bscheme & "unoptimized"
                ? "-Og "
                : "-O3 ";

    // TODO rearrange these, the -fno-math-errno should go back up into the -O3:
    //  this will thrash all tests, so when doing this,
    //   also disable 'debuggable' for the debug-built testcases,
    //    we don't need debug info there, we just want to test
    //     with and without optimizations.
    //
    if !(bscheme & "assertions")
        O_lvl ~= "-DNDEBUG ";

    if !(bscheme & "unoptimized")
        O_lvl ~= "-fno-math-errno ";

    // Debug symbols.
    if (bscheme & "debuggable")
        O_lvl ~= "-g ";

    if (bscheme & "TODO_FIX_retail")
        O_lvl ~= "-Dfu_RETAIL ";

    // Previously just shared,
    //  now trying to reuse the same objects for both server & client.
    if (bscheme & "hotswap" || bscheme & "shared")
        O_lvl ~= "-fPIC ";

    // TODO FIX should be just if (hotswap), currently:
    //  - hotswap builds need a shared fulib;
    //  - the fulib is shared=true, hotswap=false, but needs to include the fu_HOTSWAP stuff.
    if (bscheme & "hotswap" || bscheme & "shared")
        O_lvl ~= "-Dfu_HOTSWAP ";

    let GCChash = "g++ -std=c++1z " ~ O_lvl;

    // Not considering warnings when hashing files.
    let GCC_CMD = GCChash
                ~ "-pedantic-errors -Wall -Wextra -Werror " // opt-in
                ~ "-Wdouble-promotion " // opt-in
                ~ "-Wconversion -Wsign-conversion " // opt-in

                // Opt-outs, stuff we fail to clean up right now.
                ~ TODO_FIX_ignoredWarnings

                // Clang warns extern "C" hotswap fns are incompatible with c
                ~ (bscheme & "hotswap" && process::APPLE && "-Wno-return-type-c-linkage ")

                // TODO request this from within the lib
                ~ (process::LINUX && "-pthread -ldl ")
                ;

    shadow let GCChash = tea::hash(GCChash);

    //
    fulib ||= path::join(ctx.fudir,
        bscheme & "hotswap" ? "include/fu/_sharedlib.cpp"
                            : "include/fu/_fulib.cpp");

    mut fulib_cpp: string;
    if (let err = file::read(fulib, into: fulib_cpp))
        fail("Failed to read fulib @ " ~ fulib ~ ": " ~ err);

    shadow let fulib_cpp = CodegenOutput(src: fulib_cpp);

    // Map modules into translation units,
    //  this is the partial unity build thing,
    //   we could use this to guarantee static init order,
    //    access to private values & optimize build time.
    mut unit_mapping: i32[];

    flags CacheCleanup { Obj; Cpp }

    struct TranslationUnit
    {
        // Original filename or whatever describes what this is,
        //  we'll print it out in case of error.
        human?:             string;

        // Zero/one/many modules' codegen output.
        src?:               string;

        // Dirname to resolve #includes "with quotes" relative to.
        iquote?:            string;

        // Unit own-source-code.
        self_src_hash?:     tea::TEA;

        // Hash of all mutable headers this unit #includes in the src.
        includes_hash?:     tea::TEA;

        // Where this goes to if cpp-source output is requested.
        src_output_file?:   string;

        // .fu-cache cpp file, what we feed to gcc/clang & co - ideally temp,
        //  but there's some benefit to leaving these around
        //   when investigating failing tests.
        //
        // The ideal generated filename is a shallow hash
        //  of just the text contents of the file itself.
        //
        cpp_cache_file?:    string;

        // .fu-cache obj file, ideal filename is -
        //  .fu-cache/cache_cpp_file-[hash includes + build options]
        //
        // We want a clean mapping from one single source file
        //  to multiple object files, and we want new object files
        //   when we fiddle with e.g. the builtin headers or whatever.
        //
        obj_cache_file?:    string;

        // In case we need to build this unit,
        //  this is the tmp file
        //
        tmp_file?:          string;

        //
        //
        cache_cleanup?:     CacheCleanup;

        //
        HACK_pkgConfig_cflags?: string;
    };

    mut units: TranslationUnit[];


    // Delete temp files, if any.

    defer for (mut i = 0; i < units.len; i++)
    {
        let unit = units[i];

        // Unlink + print & ignore errors.
        fn try_unlink(path: string) {
            if (path) {
                let err = file::unlink(:path);
                if (err)
                    println(" UNLINK " ~ ("E" ~ err).qBAD ~ " " ~ path);
            }
        }

        try_unlink(unit.tmp_file);

        //
        if (unit.cache_cleanup & "Cpp")
            try_unlink(unit.cpp_cache_file);
        if (unit.cache_cleanup & "Obj")
            try_unlink(unit.obj_cache_file);
    }

    //
    let modules = ctx.modules;


    // Depedency sort.

    struct ModuleSortHelper { compile_index: i32; };

    using fn GET(using _: ModuleSortHelper) modules[compile_index];

    shadow let modules =
    {
        mut result: ModuleSortHelper[];
        for (mut i = 0; i < ctx.dep_order.len; i++)
            result ~= ModuleSortHelper(ctx.dep_order[i]);

        // Empty dep_order -> runtime only
        if (!result)
        {
            modules.len == 1 && bscheme & "shared" || fail(
                "ctx.dep_order: modules.len(" ~ modules.len ~ ") bscheme(" ~ bscheme ~ ")");

            result ~= ModuleSortHelper(0);
        }

        //
        result
    };


    //

    for (mut i = 0; i < modules.len; i++)
    {
        let module  = modules[i];
        let cpp     = i ? module.out.cpp
                        : fulib_cpp;
        if (!cpp.src)
        {
            unit_mapping ~= -1;
            continue;
        }

        let fname   = i ? module.fname
                        : "fulib runtime";

        let human   = i ? module.fname.path::filename
                        : "fulib runtime";

        let iquote  = i ? module.fname.path::dirname
                        : "";

        mut unit_index = i;
/*
        for (shadow mut i = 0; i < cpp.unity.len; i++)
        {
            let u = unit_mapping[cpp.unity[i]];
            if (unit_index > u)
                unit_index = u;
        }

        for (shadow mut i = 0; i < cpp.unity.len; i++)
        {
            let m = cpp.unity[i];
            let u = unit_mapping[m];
            if (u != unit_index)
                for (shadow mut i = u; i < unit_mapping.len; i++)
                    if (unit_mapping[i] == u)
                        unit_mapping[i] = unit_index;
        }
*/
        unit_mapping ~= unit_index;
        units.ensure(exists: unit_index) =
            TranslationUnit(
                src_output_file: fname ~ ".cpp",
                :human, :iquote);
    }

    // Concat unit sources.
    struct FileInvariants {
        path:   string;
        stat:   file::Stat;
    };

    mut file_invariants: FileInvariants[];
    {
        mut content_hashes: flat::Map(string, u64);

        fn getContentHash(
            include: string,
            start_fname: string,
            include_dirs: string[])
        {
            shadow let fail = |reason|
                fail("Failed to hash the #includes of:\n\t" ~ include.qID ~ "\n\n\t" ~ reason);

            fn tryFollow(dir: string, file: string): u64
            {
                let path = path::join(dir, file);

                ref hash = content_hashes.ref(path);
                if (hash)
                    return hash;

                mut stat: file::Stat;
                if (let err = file::stat(:path, into: stat))
                    fail(("E" ~ err).qBAD ~ " while attempting to stat: " ~ path.qBAD);

                // We want to make sure these remain unchanged
                //  while we're building object files.
                //
                file_invariants ~= FileInvariants(:path, stat);

                //
                mut src: string;
                if (let err = file::read(:path, into: src))
                    fail(("E" ~ err).qBAD ~ " while attempting to read: " ~ path.qBAD);

                shadow let hash = (hash = tea::hash(src).u64);

                // Traverse #includes recursively.
                mut hash_deep = parseIncludes(:path, :src);
                if (hash_deep)
                {
                    shadow ref hash = content_hashes.ref(path);

                    hash_deep.hash(hash);
                    return hash = hash_deep.u64;
                }

                // TODO FIX parse & follow #includes inside
                return hash;
            }

            fn parseIncludes(path: string, src: string): tea::TEA
            {
                mut hash_all: tea::TEA;

                :NEXT_INCLUDE
                src.split("#include", each: |match, first|
                {
                    if (first)
                        continue :NEXT_INCLUDE;

                    fn matchFail(lax reason: string)
                    {
                        let firstNewline = match.find('\n');
                        shadow let match = firstNewline > 0
                                 ? match.slice(start: 0, end: firstNewline)
                                 : match;

                        shadow let match = match.len > 90
                                 ? match.slice(start: 0, end: 80)
                                 : match;

                        println("  FISHY #include in " ~ path ~ " (" ~ reason ~ "):\n\n" ~ match.qBAD);

                        continue :NEXT_INCLUDE;
                    }

                    // Trim leading whitespace.
                    mut trimLeft = 0;
                    for (mut i = 0; i < match.len; i++)
                    {
                        if (match[i] > ' ') {
                            trimLeft = i;
                            break;
                        }
                    }

                    shadow let match = match.slice(start: trimLeft);

                    //
                    let lead = match.len > 2 && match[0];

                    let endChar = lead == '"' ? '"'
                                : lead == '<' ? '>'
                                : matchFail("no leading " ~ "\"".qKW ~ " or " ~ "<".qKW);

                    //
                    for (mut i = 1; i < match.len; i++)
                    {
                        let c = match[i];
                        if (c <= ' ')
                            matchFail("contains whitespace");

                        if (c == endChar)
                        {
                            shadow let include = match.slice(0, i + 1);
                            hash_all.hash(visitInclude(:include, start_fname: path));
                            continue :NEXT_INCLUDE;
                        }
                    }

                    matchFail("no trailing " ~ (endChar ~ "").qKW);
                });

                return hash_all;
            }

            fn visitInclude(shadow include: string, shadow start_fname: string): u64
            {
                let f = include.slice(1, include.len - 1);

                if (include.starts(with: '"'))
                    return tryFollow(path::dirname(start_fname), f);

                // TODO FIX not all of our headers start with fu/,
                //  there's the par/ and dl/ nonsense,
                //   gotta move those back in.
                //
                if (include.starts(with: "<fu/"))
                    return tryFollow(fudir::FU_INCLUDE, f);

                if (include_dirs)
                {
                    // TODO FIX the include_dirs stuff doesn't make amazing sense,
                    //  we need to skope them somehow so we know
                    //   which headers need to be looked up where.
                }

                // TODO FIX we need to tell the system headers from
                //  whatever custom stuff people add to their include_dirs
                //
                // Maybe we want to introduce an extra #include convension,
                //  e.g. <<sys/time.h>>, to explicitly opt-out of content hashing.
                //
                // Alternatively, we'd have to locate the std headers on disk
                //  and just treat them like any other header.
                //   Here's one way to do it (see https://stackoverflow.com/a/33485647):
                //
                //  LC_ALL=C gcc -v -E -xc - < /dev/null 2>&1 |
                //  LC_ALL=C sed -ne '/starts here/,/End of/p'
                //
                // Basically, we'd ignore includes without an extension (std cpp),
                //  and check the ones with an extension & treat them as usual,
                //   or ignore when found / error when not found?
                //    What's the point i wonder.
                //
                // println("  CACHE TODO FIX Assuming " ~ include.qID ~ " is immutable, TODO resolve + hash + follow.");

                return 0;
            }

            return visitInclude(:include, :start_fname);
        }

        for (mut i = 0; i < modules.len; i++)
        {
            let module  = modules[i];
            let cpp     = i ? module.out.cpp
                            : fulib_cpp;
            if (cpp.src)
            {
                ref unit = units[unit_mapping[i]];
                unit.src ~= cpp.src;

                //
                ref includes_hash = unit.includes_hash;
                for (shadow mut i = 0; i < cpp.includes_headers.len; i++)
                {
                    let hash = getContentHash(
                        include:        cpp.includes_headers[i],
                        start_fname:    module.fname,
                        include_dirs:   cpp.hacks.include_dirs.keys_asc);

                    if (hash)
                        includes_hash.hash(hash);
                }
            }
        }
    }

    //
    let dir_wrk_cpp = dir_wrk ~ "cpp/";     fs::mkdir_p(dir_wrk_cpp);
    let dir_wrk_obj = dir_wrk ~ "obj/";     fs::mkdir_p(dir_wrk_obj);
    let dir_wrk_bin = dir_wrk ~ "bin/";     fs::mkdir_p(dir_wrk_bin);

    // TODO FIX - the novec on parallel_for prevents us from binding to dir_wrk_tmp as a variable,
    //  the novec has to go, we'd rather have something
    //
    fn  dir_wrk_tmp = dir_wrk ~ "tmp/";     fs::mkdir_p(dir_wrk_tmp);

    // Hash unit content.
    units.each: |ref unit|
        if (unit.src)
            unit.self_src_hash.hash(unit.src);

    //
    mut len_all: i32;
    mut hash_all: tea::TEA;
    for (mut i = 0; i < units.len; i++)
    {
        ref unit = units[i];

        let cpp = unit.src;
        if (!cpp)
            continue;

        // Cpp cache file -
        //  we only care about the immediate content hash here,
        //   no includes, no dependencies, no gcc flags, nothing.
        //
        mut hash = unit.self_src_hash;

        unit.cpp_cache_file = hash.digest16 ~ "-" ~ cpp.len;

        // Obj cache file -
        //  we care about the contents of everything that's
        //   included by this source file:
        //
        hash.hash(unit.includes_hash);
        //
        //  and we care about compiler/linker flags:
        //
        hash.hash(GCChash);
        //
        // TODO FIX we should probably care about compiler version too,
        //  we could resolve it once on boot by gcc --version and hash its output.

        len_all += cpp.len;
        hash_all.hash(hash);

        unit.obj_cache_file = dir_wrk_obj ~ unit.cpp_cache_file ~ "-" ~ hash.digest16 ~ ".o";
        unit.cpp_cache_file = dir_wrk_cpp ~ unit.cpp_cache_file ~ ".cpp";
    }

    ////////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////
    ////
    ////  Total nonsense, tbd how we're gonna do this,
    ////   but I'd like us to have something that
    ////    just-works for the simplest things like your local glfw.
    ////
    mut HACK_linkFlags:         flat::Set(string);
    mut HACK_pkgConfig_libs:    flat::Set(string);

    mut HACK_include_dirs:      flat::Set(string);

    for (mut i = 0; i < modules.len; i++)
    {
        let module = modules[i];

        //
        let include_dirs = module.out.cpp.hacks.include_dirs;
        if (include_dirs)
        {
            let dir = path::dirname(module.fname);
            include_dirs.each: |incl|
                HACK_include_dirs.add(
                    incl.starts(with: '.')
                        ? path::join(dir, incl)
                        : incl);
        }

        //
        mut cflags = "";

        mut libs = module.out.cpp.hacks.link;
        for (shadow mut i = 0; i < libs.len; i++)
        {
            mut lib = libs[i];

            if (lib.starts(with: "-")) {
                HACK_linkFlags.add(lib);
            }
            else {
                cflags ~= lib;
                HACK_pkgConfig_libs.add(lib);
            }
        }

        if (cflags)
            units[unit_mapping[i]].HACK_pkgConfig_cflags =
                " $(pkg-config --cflags " ~ cflags ~ ")";
    }

    let INCLUDE = (flags_cc && " " ~ flags_cc.join(' ')) ~ " -I " ~ ctx.fudir ~ "include"
                ~ (HACK_include_dirs && " -I " ~ HACK_include_dirs.keys_asc.join(" -I "));

    let LIBS = (flags_ld && " " ~ flags_ld.join(' '))
             ~ (HACK_linkFlags      && " "                     ~ HACK_linkFlags.keys_asc.join(" "))
             ~ (HACK_pkgConfig_libs && " $(pkg-config --libs " ~ HACK_pkgConfig_libs.keys_asc.join(" ") ~ ")");
    ////
    ////////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////
    ////////////////////////////////////////////////////////////////

    //
    len_all += LIBS.len;
    hash_all.hash(LIBS);

    //
    mut code:   i32;
    mut stdout: string;

    fn ERR(mut cpp?: string)
    {
        units.each: |ref unit|
            unit.cache_cleanup &= ~CacheCleanup.Cpp;

        if (onfail & OnFail_WriteRepro)
        {
            if (!cpp) for (mut i = units.len; i --> 0; )
            {
                ref unit = units[i];
                if (unit.cpp_cache_file)
                    cpp ~= "#include \"" ~ unit.cpp_cache_file ~ "\"\n";
            }

            let fname = dir_wrk ~ "failing-testcase.cpp";
            println("  WRITE " ~ fname);
            atomic_write(:fname, cpp, :dir_wrk_tmp);
        }

        // Print exit code.
        if (stdout)
            stdout ~= "\n\n";

        stdout ~= "   EXIT code: " ~ code;

        //
        mut explain = "";
        if (onfail)
        {
            explain = "\n\n\tCOMPILER BUG or INCORRECT TESTCASE:\n\n";

            units.each: |unit|
                explain ~= unit.human ~ "\n";

            if (onfail & OnFail_PrintOutput)
            {
                explain ~= "\n\n\tGenerated code:\n\n";
                units.each: |unit|
                    explain ~= unit.src;
            }
        }

        return fail(stdout ~ explain);
    }

    //
    let F_exe       = dir_wrk_bin ~ hash_all.digest16 ~ "-" ~ len_all;
    let old_size    = !(bscheme & "nocache") && file::size(F_exe);

    ////////////////////////////////////////////////
    // TEMP re-run tests without allocation stats //
    shadow let old_size = old_size != 4 && old_size;
    // TEMP re-run tests without allocation stats //
    ////////////////////////////////////////////////

    if (old_size < 1 && (bin || runmode))
    {
        struct BuildError {
            code: i32;
            cpp: string;
            stdout: string;
        };

        fn buildUnit(ref unit: TranslationUnit, i: int): BuildError
        {
            let F_cpp = unit.cpp_cache_file;
            let F_obj = unit.obj_cache_file;
            if (!F_cpp || !F_obj)
                return [];

            if (file::size(F_obj) > 0 && !(bscheme & "nocache"))
                return [];

            // We'll be doing work here.
            unit.tmp_file = tmpfile(:dir_wrk_tmp);

            unit.cache_cleanup |= "Cpp";

            let cpp = unit.src;
            atomic_write(fname: F_cpp, cpp, :dir_wrk_tmp);

            println("  BUILD ", unit.human, " ", F_cpp);

            let t0 = now::hr();

            ///////////////////////////////////////////////////////////////////
            shadow let INCLUDE = INCLUDE ~ unit.HACK_pkgConfig_cflags;
            ///////////////////////////////////////////////////////////////////

            ////////////////////////////////////////////////////////////////////////////////////////////////
            shadow let INCLUDE = INCLUDE ~ (unit.iquote && " -iquote " ~ unit.iquote);
            ////////////////////////////////////////////////////////////////////////////////////////////////

            let CMD = GCC_CMD ~ "-c" ~ INCLUDE ~ " -o " ~ unit.tmp_file ~ " " ~ F_cpp;

            // println("      > ", CMD);
            shadow mut stdout: string;

            shadow let code = exec(CMD, :stdout);
            if (code)
                return BuildError(:code, :cpp, :stdout);

            // Testcases -
            // Discard object files after linking.
            if (runmode == "CompilerTestcase" && i > 0)
                unit.cache_cleanup |= "Obj";

            //
            let t1 = now::hr();
            println("     OK ", unit.human, " ", t1 - t0, "s");
            return [];
        }

        // Build.
        let buildErrors = units.par::map(fn buildUnit);

        for (mut i = 0; i < buildErrors.len; i++)
        {
            let err = buildErrors[i];
            if ((code = err.code))
            {
                stdout = err.stdout;
                return ERR(err.cpp);
            }
        }


        // We've built all object files, they're still under workspace/temp.
        //  We can't trust the hashes if some header was modified while we were building,
        //   so we'll have to check if we need to scrap this build.

        mut _didCrosscheckHeaders: int;

        fn crosscheckHeaders_beforePersistingTempObjects()
        {
            if (_didCrosscheckHeaders++)
                return;

            file_invariants.each: |file_invariant|
            {
                let expect = file_invariant.stat;

                mut actual: file::Stat;
                let err = file::stat(:file_invariant.path, into: actual);

                if (err || actual.size != expect.size
                        || actual.mtime != expect.mtime)
                {
                    fail("Header crosscheck failed for:"
                        ~ "\n\t" ~ file_invariant.path
                        ~ "\n\n\tError: " ~ (err ? ("E" ~ err).qBAD : "mtime changed."));
                }

                // Uncomment this to verify this isn't running unnecessarily.
                // println(" HEADOK " ~ file_invariant.path ~ " " ~ actual.size ~ "b");
            }
        }

        for (mut i = 0; i < units.len; i++)
        {
            ref unit = units[i];
            if (unit.tmp_file)
            {
                crosscheckHeaders_beforePersistingTempObjects();

                //
                let from = unit.tmp_file;
                let to   = unit.obj_cache_file;

                let err = file::rename(:from, :to);
                if (err)
                    fail("Build cache failed to move temporary:\n\t" ~ from
                        ~ "\n\n\tto the object cache at:\n\t" ~ to
                        ~ "\n\n\tError: " ~ ("E" ~ err).qBAD);

                unit.tmp_file.clear();
            }
        }


        // Link.

        let F_tmp = tmpfile(:dir_wrk_tmp);

        mut cmd = GCC_CMD ~ "-o " ~ F_tmp;

        if (bscheme & "shared")
        {
            cmd ~= " -shared";

            // Linker -soname
            let soname = path::filename(bin);
            if (process::APPLE)
                cmd ~= " -Wl,-install_name,@rpath/" ~ soname;
            else
                cmd ~= " -Wl,-soname," ~ soname;
        }

        for (mut i = 0; i < units.len; i++)
        {
            let unit = units[i];
            if (unit.obj_cache_file)
                cmd ~= " " ~ unit.obj_cache_file;
        }

        //
        {
            println("   LINK ", F_exe, LIBS);

            let t0 = now::hr();

            let CMD = cmd ~ LIBS;

            // println("      > ", CMD);

            code = exec(CMD, :stdout)
                || file::chmod(F_tmp, file::RWX_RX_RX).int
                || file::rename(F_tmp, F_exe).int;

            if (code)
            {
                println("   FAIL " ~ CMD ~ " EXIT=" ~ code ~ "\n" ~ stdout);
                return ERR;
            }

            let t1 = now::hr();
            println("     OK ", t1 - t0, "s");
        }

        if (code) return ERR;
    }

    //
    mut output: test_output::TestOutput;

    if (runmode &&
        runmode != "EnsureExecutableButDontRun")
    {
        // TODO FIX This needs to get out of here,
        //  but brief this is the compiler test suite runner,
        //   includes caching for test results so we don't have to
        //    constantly rerun them.
        //
        let OPTI_StatusCode = runmode == "CompilerTestcase";

        mut status: spawn::ExitStatus;

        //
        fn READ_cachedTestOutput()
        {
            mut src: string;
            file::read(F_exe, into: src);

            output  = test_output::parse(src);
            status  = output.status;
        }

        fn WRITE_cachedTestOutput()
        {
            let out = test_output::serialize(output);
            out.len == 20 || fail("TestOutput.len != 20");
            atomic_write(fname: F_exe, out, :dir_wrk_tmp);
        }

        //
        if (OPTI_StatusCode
            && old_size.test_output::looks_legit)
        {
            READ_cachedTestOutput();
        }
        else
        {
            {
                println("    RUN " F_exe);
                shadow mut stdout: string;

                let t0  = now::hr();
                code    = ::spawn([ F_exe ], :status, :stdout, stderr: stdout, passthrough: runmode == "Normally").int;
                output  = test_output::from(:stdout, :status);
                let t1  = now::hr();

                println("     OK ", t1 - t0, "s",
                    status.signalled && " signal(" ~ status.signal ~ ")",
                    status.exited    && " exit(" ~ status.exit ~ ")",
                    code             && " errno(" ~ code ~ ")");
            }

            //
            if (OPTI_StatusCode)
            {
                // However, when tests run in parallel this can totally brick itself -
                //  if for some reason we already did this and tried to run the 4-byte exe,
                //   it obviously breaks and here we'd persist the broken result forever.
                //
                let new_size = file::size(F_exe);
                if (new_size.test_output::looks_legit)
                {
                    // We can notice the exe has shrunk to 4 bytes though,
                    //  and discard the result of our run with the one
                    //   that was just cached by a parallel run.
                    //
                    READ_cachedTestOutput();
                }
                else if (!code)
                {
                    WRITE_cachedTestOutput();
                }
            }
        }

        if (!code)
            if !(status.exited && status.exit == expect_exit)
                code = status.int || -1;
    }

    if (code)
        return ERR;

    // .cpp file output.
    if (dir_cpp && dir_src)
    {
        fs::mkdir_p(dir_cpp);

        mut cpp_files: string[];

        for (mut i = 1; i < units.len; i++)
        {
            let unit            = units[i];

            // TODO NEXT BOOTSTRAP failcase exits + fixed
            // TODO let data    = unit.src; + replace unit.src below with data

            let fname           = unit.src && unit.src_output_file;
            shadow let fname    = fname && update_file(
                :fname, data: unit.src,
                :dir_src, :dir_cpp,
                :dir_wrk_tmp);

            cpp_files.push(fname);
        }

        // .unity.cpp
        if (unity)
        {
            mut data    = "#ifdef fu_UNITY_FULIB\n"
                        ~ "#include <fu/_fulib.cpp>\n"
                        ~ "#endif\n\n";

            let fname   = unity ~ ".unity.cpp";
            let dest    = update_file_dest(:fname, :dir_src, :dir_cpp);

            for (mut i = 0; i < cpp_files.len; i++)
                if (let incl = cpp_files[i])
                    data ~= "#include \"" ~ path::relative(dest, incl) ~ "\"\n";

            update_file(:dest, :data, :dir_cpp, :dir_wrk_tmp);
        }
    }

    // output binary.
    if (bin)
    {
        fs::mkdir_p( path::dirname(bin) );

        code = file::rename(F_exe, bin).int;
    }

    if (code) return ERR;

    //
    fn generateWatchList()
    {
        mut watch_list: string[];

        for (mut i = 1; i < modules.len; i++) {
            let fname = modules[i].fname;
            if (fname)
                watch_list ~= fname;
        }

        file_invariants.each: |file_invariant|
            if (file_invariant.path)
                watch_list ~= file_invariant.path;

        return watch_list;
    }

    //
    return BuildOutput(
        executable: bin || F_exe,
        watch_list: bscheme & "watch" && generateWatchList(),
        :output);
}
