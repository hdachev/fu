import helpers;
import module;
import ansi;


// TODO re: rewrite -
//
// We need a principled fn fail() here,
//  something that can relate most problems to a token somewhere in your sources,
//   so we can raise error messages with the usual formatting.


// TODO FAILCASE - doesn't parse here, weird
// fn fail = fn throw;

// TODO FAILCASE - doesn't work either
// fn fail = .throw;

fn fail(reason: string) throw(reason);


//

let TODO_FIX_ignoredWarnings = ""

    // clang issue with float->bool,
    //  if we have an explicit !! codegen this can be fixed,
    //   an x != 0 works, this can be also used for a non-zero non-nan check.
    //
    ~ "-Wno-float-conversion " // opt-out

    // gcc & clang complain about unused-but-set variables
    //  that we fail to eliminate in templated iterators,
    //   gotta figure out something, but for the time being we gotta opt out.
    //
    ~ "-Wno-unused-but-set-variable " // opt-out

    // Not every clang has unused-but-set-variable
    //
    ~ "-Wno-unknown-warning-option " // opt-out

    // Running into a bunch of weird warnings on gcc12.
    //
    // Array bounds errors after size is checked,
    //  sequence-points for assignments (RTL by standard), etc.
    //   Can't have false positives break builds.
    //
    // TODO instead of silencing them,
    //  we probably want to simply not treat them as hard errors.
    //
    ~ "-Wno-maybe-uninitialized -Wno-stringop-overflow -Wno-array-bounds -Wno-sequence-point -Wno-dangling-reference "

    ;


//

nocopy struct DirWrk
{
    cpp: string;
    obj: string;
    bin: string;
    out: string;
    tmp: string;
};

fn DirWrk(dir_wrk!: string)
{
    let ret = DirWrk(
        cpp: dir_wrk ~ "cpp/",
        obj: dir_wrk ~ "obj/",
        bin: dir_wrk ~ "bin/",
        out: dir_wrk ~ "out/",
        tmp: dir_wrk ~ "tmp/");

    for (fieldname i: DirWrk)
        fs::mkdir_p(ret.i);

    return ret;
}


//

fn ensure_local_fname(fname: string, dir_src: string): string
{
    if (fname.starts(with: dir_src))
        return fname;

    let foreign = dir_src ~ ".foreign/";
    fs::mkdir_p(foreign);

    let rel = path::relative(from: dir_src, to: fname)
        .replace(all: "../", with: "up__")
        .replace(all:   "/", with:   "__");

    return foreign ~ rel;
}

fn tmpfile(implicit dir_wrk: DirWrk)
{
    mut fname = dir_wrk.tmp;

    mut r = rand::next_u64();
    for (mut i = 0; i < 8; i++)
    {
        let v = r & 0x1f;
        fname ~= byte(
            v < 10  ? '0'.i32 + v.i32
                    : 'a'.i32 + v.i32 - 10);
        r >>= 5;
    }

    return fname;
}

fn atomic_write(fname!: string, data: string)
{
    let tmp = tmpfile();

    let err = file::write(tmp, data) || file::rename(tmp, fname);
    if (err)
        file::unlink(tmp);

    return err;
}

fn update_file_dest(
    fname       !: string,
    dir_src     !: string,
    dir_cpp     !: string)
{
    shadow let fname = ensure_local_fname(:fname, :dir_src);
    fname.starts(with: dir_src) || fail("ensure_local_fname broken");

    return dir_cpp ~ fname.slice(dir_src.len);
}

fn update_file(
    fname       !: string,
    data        !: string,
    dir_src     !: string,
    dir_cpp     !: string)
{
    return update_file(
        dest: update_file_dest(:fname, :dir_src, :dir_cpp),
        :data, :dir_cpp);
}

fn update_file(
    dest!fname   : string,
    data        !: string,
    dir_cpp     !: string)
{
    mut xcheck: string;
    if (file::read(fname, into: xcheck) || xcheck != data)
    {
        for (;;)
        {
            let err = atomic_write(:fname, data);
            if (err)
            {
                if (err == Errno::ENOENT)
                {
                    mut last = -1;
                    for (mut i = dir_cpp.len + 1; i < fname.len; i++)
                        if (fname[i] == '/')
                            last = i;

                    if (last >= 0)
                        if !(fs::mkdir_p(fname.slice(0, last + 1)))
                            continue;
                }

                fail("Failed to write `" ~ fname ~ "`, error: #" ~ err);
            }

            println("  WROTE " ~ fname);
            break;
        }
    }

    return fname;
}


// TODO FIX

fn exec(cmd: string, ref stdout: string)
{
    mut status: spawn::ExitStatus = 0;
    mut err: ::Errno;

    // TODO FIX remove this nonsense -
    //  this is currently used for pkg-config queries,
    //   should run those separately instead of scripting them here
    //
    if (cmd.has("$("))
    {
        // We want "-rpath $ORIGIN" to pass through unchanged.
        shadow let cmd =
            cmd.replace(all: "$", with: "\\$")
               .replace(all: "\\$(", with: "$(");

        err = ::exec(cmd, :status, stdout);
    }
    else
        err = ::spawn(cmd.split(' '), :status, :stdout, stderr: stdout);

    return err.int || status.int;
}

pub fn gcc_version()
{
    mut stdout: string;

    let code = exec("gcc --version", :stdout);
    if (code)
    {
        if (stdout)
            stdout ~= stdout.ends(with: '\n') ? "\n" : "\n\n";

        stdout ~= "NON-ZERO EXIT CODE: " ~ code ~ "\n";
    }

    return stdout;
}


//

using flags DEV_OnFail
{
    OnFail_PrintInput
    OnFail_PrintOutput
    OnFail_WriteRepro
};

pub enum RunMode
{
    None        = 0
    Normally
    Testsuite
    CompilerTestcase
    EnsureExecutableButDontRun
}

pub flags BuildScheme: u16
{
    shared
    hotswap
    nocache
    notest
    watch

    // NOTE re: the weird negations here -
    //  The zerofilled default == release build, thus:
    //   - debug-symbols are opt-in,
    //   - optimizations are opt-out,
    //   - assertions are opt-in, etc.
    //
    debuggable
    unoptimized
    assertions
    TODO_FIX_retail
}

pub let DEBUG_SCHEME    = BuildScheme.debuggable
                        | BuildScheme.unoptimized
                        | BuildScheme.assertions;

pub fn tryGetScheme(name: string)
{
    if (name == "debug")
        return DEBUG_SCHEME;

    if (name == "reldeb")
        return BuildScheme.debuggable;

    return name == "retail" &&
        BuildScheme.TODO_FIX_retail;
}


//

struct BuildOutput
{
    executable:     string;
    watch_list?:    string[];

    using output:   test_output::TestOutput;
};

flags CacheCleanup { Obj; Cpp }

struct TranslationUnit
{
    // Original filename or whatever describes what this is,
    //  we'll print it out in case of error.
    human?:             string;

    // Zero/one/many modules' codegen output.
    src?:               string;

    // Dirname to resolve #includes "with quotes" relative to.
    iquote?:            string;

    // Hash of all mutable headers this unit #includes in the src.
    includes_hash?:     tea::TEA;

    // Where this goes to if cpp-source output is requested.
    src_output_file?:   string;

    // .fu-cache cpp file, what we feed to gcc/clang & co - ideally temp,
    //  but there's some benefit to leaving these around
    //   when investigating failing tests.
    //
    // The ideal generated filename is a shallow hash
    //  of just the text contents of the file itself.
    //
    cpp_cache_file?:    string;

    // .fu-cache obj file, ideal filename is -
    //  .fu-cache/cache_cpp_file-[hash includes + build options]
    //
    // We want a clean mapping from one single source file
    //  to multiple object files, and we want new object files
    //   when we fiddle with e.g. the builtin headers or whatever.
    //
    obj_hash?:          tea::TEA;
    obj_cache_file?:    string;

    // In case we need to build this unit,
    //  this is the tmp file we're going to have the cpp compiler emit,
    //   to only be renamed to the cache-persisted obj_cache_file
    //    if no headers&co changed in the meantime.
    //
    tmp_file?:          string;
    cache_cleanup?:     CacheCleanup;

    // TODO FIX unwrap these, not using all members, overall bad idea
    hacks?:             BuildHacks;

    // Unlike module.testsuite_modids,
    //  here we have unit indices.
    //
    testsuite_units?:   flat::Set(i32);
};

struct FileInvariants {
    path:   string;
    stat:   file::Stat;
};


//

pub fn build(
    implicit ctx: Context,

    mut dir_wrk  !: string,

    mut fulib   !?: string,

    mut bin     !?: string,
    mut dir_obj !?: string,
    mut dir_src !?: string,
    mut dir_cpp !?: string,
        unity   !?: string,
        onfail  !?: DEV_OnFail,

        // TODO clean these up, this makes NO SENSE //
        runmode !?: RunMode,    expect_exit!?: int,
        bscheme !?: BuildScheme,
        //////////////////////////////////////////////

        flags_cc!?: string[],
        flags_ld!?: string[]): BuildOutput
{
    // Where we do our dirtywork.
    if (dir_wrk.if_last != '/')
    {
        dir_wrk || fail("No workspace directory provided.");
        dir_wrk ~= '/';
    }

    //
    if (dir_obj && dir_obj.if_last != '/') dir_obj ~= '/';
    if (dir_src && dir_src.if_last != '/') dir_src ~= '/';
    if (dir_cpp && dir_cpp.if_last != '/') dir_cpp ~= '/';

    // Optimization level.
    mut O_lvl   = bscheme & "unoptimized"
                ? "-Og "
                : "-O3 ";

    // TODO rearrange these, the -fno-math-errno should go back up into the -O3:
    //  this will thrash all tests, so when doing this,
    //   also disable 'debuggable' for the debug-built testcases,
    //    we don't need debug info there, we just want to test
    //     with and without optimizations.
    //
    if !(bscheme & "assertions")
        O_lvl ~= "-DNDEBUG ";

    if !(bscheme & "unoptimized")
        O_lvl ~= "-fno-math-errno ";

    // Debug symbols.
    if (bscheme & "debuggable")
        O_lvl ~= "-g ";

    if (bscheme & "TODO_FIX_retail")
        O_lvl ~= "-Dfu_RETAIL ";

    // Previously just shared,
    //  now trying to reuse the same objects for both server & client.
    if (bscheme & "hotswap" || bscheme & "shared")
        O_lvl ~= "-fPIC ";

    // TODO FIX should be just if (hotswap), currently:
    //  - hotswap builds need a shared fulib;
    //  - the fulib is shared=true, hotswap=false, but needs to include the fu_HOTSWAP stuff.
    if (bscheme & "hotswap" || bscheme & "shared")
        O_lvl ~= "-Dfu_HOTSWAP ";

    let GCChash = "g++ -std=c++1z " ~ O_lvl;

    // Not considering warnings when hashing files.
    let GCC_CMD = GCChash
                ~ "-pedantic-errors -Wall -Wextra -Werror " // opt-in
                ~ "-Wdouble-promotion " // opt-in
                ~ "-Wconversion -Wsign-conversion " // opt-in

                // Opt-outs, stuff we fail to clean up right now.
                ~ TODO_FIX_ignoredWarnings

                // Clang warns extern "C" hotswap fns are incompatible with c
                ~ (bscheme & "hotswap" && process::APPLE && "-Wno-return-type-c-linkage ")

                // TODO request this from within the lib
                ~ (process::LINUX && "-pthread -ldl ")
                ;

    shadow let GCChash = tea::hash(GCChash);

    //
    fulib ||= path::join(ctx.fudir,
        bscheme & "hotswap" ? "include/fu/_sharedlib.cpp"
                            : "include/fu/_fulib.cpp");

    mut fulib_cpp: string;
    if (let err = file::read(fulib, into: fulib_cpp))
        fail("Failed to read fulib @ " ~ fulib ~ ": " ~ err);

    shadow let fulib_cpp = CodegenOutput(src: fulib_cpp);

    // Map modules into translation units,
    //  this is the partial unity build thing,
    //   we could use this to guarantee static init order,
    //    access to private values & optimize build time.
    //
    mut unit_indices = ctx.modules.map(|_| -1);

    mut units: TranslationUnit[];


    //

    mut file_invariants: FileInvariants[];
    mut include_hashes: flat::Map(string, u64);

    fn getIncludeHash(
        include: string,
        start_fname: string,
        include_dirs: string[])
    {
        shadow let fail = |reason|
            fail("Failed to hash the #includes of:\n\t" ~ include.qID ~ "\n\n\t" ~ reason);

        fn tryFollow(dir: string, file: string): u64
        {
            let path = path::join(dir, file);

            ref hash = include_hashes.ref(path);
            if (hash)
                return hash;

            mut stat: file::Stat;
            if (let err = file::stat(:path, into: stat))
                fail(("E" ~ err).qBAD ~ " while attempting to stat: " ~ path.qBAD);

            // We want to make sure these remain unchanged
            //  while we're building object files.
            //
            file_invariants ~= FileInvariants(:path, stat);

            //
            mut src: string;
            if (let err = file::read(:path, into: src))
                fail(("E" ~ err).qBAD ~ " while attempting to read: " ~ path.qBAD);

            shadow let hash = (hash = tea::hash(src).u64);

            // Traverse #includes recursively.
            mut hash_deep = parseIncludes(:path, :src);
            if (hash_deep)
            {
                shadow ref hash = include_hashes.ref(path);

                hash_deep.hash(hash);
                return hash = hash_deep.u64;
            }

            // TODO FIX parse & follow #includes inside
            return hash;
        }

        fn parseIncludes(path: string, src: string): tea::TEA
        {
            mut hash_all: tea::TEA;

            :NEXT_INCLUDE
            src.split("#include", each: |match, first|
            {
                if (first)
                    continue :NEXT_INCLUDE;

                fn matchFail(lax reason: string)
                {
                    let firstNewline = match.find('\n');
                    shadow let match = firstNewline > 0
                             ? match.slice(start: 0, end: firstNewline)
                             : match;

                    shadow let match = match.len > 90
                             ? match.slice(start: 0, end: 80)
                             : match;

                    println("  FISHY #include in " ~ path ~ " (" ~ reason ~ "):\n\n" ~ match.qBAD);

                    continue :NEXT_INCLUDE;
                }

                // Trim leading whitespace.
                mut trimLeft = 0;
                for (mut i = 0; i < match.len; i++)
                {
                    if (match[i] > ' ') {
                        trimLeft = i;
                        break;
                    }
                }

                shadow let match = match.slice(start: trimLeft);

                //
                let lead = match.len > 2 && match[0];

                let endChar = lead == '"' ? '"'
                            : lead == '<' ? '>'
                            : matchFail("no leading " ~ "\"".qKW ~ " or " ~ "<".qKW);

                //
                for (mut i = 1; i < match.len; i++)
                {
                    let c = match[i];
                    if (c <= ' ')
                        matchFail("contains whitespace");

                    if (c == endChar)
                    {
                        shadow let include = match.slice(0, i + 1);
                        hash_all.hash(visitInclude(:include, start_fname: path));
                        continue :NEXT_INCLUDE;
                    }
                }

                matchFail("no trailing " ~ (endChar ~ "").qKW);
            });

            return hash_all;
        }

        fn visitInclude(shadow include: string, shadow start_fname: string): u64
        {
            let f = include.slice(1, include.len - 1);

            if (include.starts(with: '"'))
                return tryFollow(path::dirname(start_fname), f);

            // TODO FIX not all of our headers start with fu/,
            //  there's the par/ and dl/ nonsense,
            //   gotta move those back in.
            //
            if (include.starts(with: "<fu/"))
                return tryFollow(fudir::FU_INCLUDE, f);

            if (include_dirs)
            {
                // TODO FIX the include_dirs stuff doesn't make amazing sense,
                //  we need to skope them somehow so we know
                //   which headers need to be looked up where.
            }

            // TODO FIX we need to tell the system headers from
            //  whatever custom stuff people add to their include_dirs
            //
            // Maybe we want to introduce an extra #include convension,
            //  e.g. <<sys/time.h>>, to explicitly opt-out of content hashing.
            //
            // Alternatively, we'd have to locate the std headers on disk
            //  and just treat them like any other header.
            //   Here's one way to do it (see https://stackoverflow.com/a/33485647):
            //
            //  LC_ALL=C gcc -v -E -xc - < /dev/null 2>&1 |
            //  LC_ALL=C sed -ne '/starts here/,/End of/p'
            //
            // Basically, we'd ignore includes without an extension (std cpp),
            //  and check the ones with an extension & treat them as usual,
            //   or ignore when found / error when not found?
            //    What's the point i wonder.
            //
            // println("  CACHE TODO FIX Assuming " ~ include.qID ~ " is immutable, TODO resolve + hash + follow.");

            return 0;
        }

        return visitInclude(:include, :start_fname);
    }


    //

    let dep_order = ctx.dep_order || [ 0 ]; // TODO FIX Empty dep_order -> runtime only

    for (mut i = 0; i < dep_order.len; i++)
    {
        let modid   = dep_order[i];
        let module  = ctx.modules[modid];

        let cpp     = i ? module.out.cpp
                        : fulib_cpp;
        if (!cpp.src)
            continue;

        let fname   = i ? module.fname
                        : "fulib runtime";

        let human   = i ? module.fname.path::filename
                        : "fulib runtime";

        let iquote  = i ? module.fname.path::dirname
                        : "";

        //
        units.push(
            TranslationUnit(
                src_output_file: fname ~ ".cpp",
                :human, :iquote,
                :cpp.src));

        let unit_index  = unit_indices[modid] = units.len - 1;
        ref unit        = units[unit_index];

        //
        ref includes_hash = unit.includes_hash;
        for (shadow mut i = 0; i < cpp.includes_headers.len; i++)
        {
            let hash = getIncludeHash(
                include:        cpp.includes_headers[i],
                start_fname:    module.fname,
                include_dirs:   cpp.hacks.include_dirs.keys_asc);

            if (hash)
                includes_hash.hash(hash);
        }

        //
        if (cpp.hacks)
        {
            unit.hacks.link.add(cpp.hacks.link);

            let include_dirs = cpp.hacks.include_dirs;
            if (include_dirs)
            {
                let dir = path::dirname(module.fname);
                include_dirs.each: |incl|
                    unit.hacks.include_dirs.add(
                        incl.starts(with: '.')
                            ? path::join(dir, incl)
                            : incl);
            }
        }
    }


    // Hash unit content & generate all intermediate filenames.

    shadow let implicit dir_wrk = DirWrk(:dir_wrk);

    for (mut i = 0; i < units.len; i++)
    {
        ref unit = units[i];

        let cpp = unit.src || fail("Empty translation unit.");

        ref hash = unit.obj_hash; assert(!hash);

        hash.hash(unit.src);

        // Cpp cache file -
        //  we only care about the immediate content hash here,
        //   no includes, no dependencies, no gcc flags, nothing.
        //
        unit.cpp_cache_file = hash.digest16 ~ "-" ~ cpp.len;

        // Obj cache file -
        //  we care about the contents of everything that's
        //   included by this source file:
        //
        hash.hash(unit.includes_hash);
        //
        //  and we care about compiler/linker flags:
        //
        hash.hash(GCChash);
        //
        // TODO FIX we should probably care about compiler version too,
        //  we could resolve it once on boot by gcc --version and hash its output.

        unit.obj_cache_file = dir_wrk.obj ~ unit.cpp_cache_file ~ "-" ~ hash.digest16 ~ ".o";
        unit.cpp_cache_file = dir_wrk.cpp ~ unit.cpp_cache_file ~ ".cpp";
    }


    //

    mut ret = buildTarget(
        :units, :file_invariants,
        :flags_cc, :flags_ld, :onfail,
        :bscheme, :runmode, :expect_exit,
        :bin, :GCC_CMD);

    if (bscheme & "watch")
    {
        // Previously generateWatchList:
        assert(!ret.watch_list);

        for (mut i = 1; i < ctx.modules.len; i++) {
            let fname = ctx.modules[i].fname;
            if (fname)
                ret.watch_list ~= fname;
        }

        file_invariants.each: |file_invariant|
            if (file_invariant.path)
                ret.watch_list ~= file_invariant.path;
    }


    //

    if !(bscheme & "notest")
    {
        // Now that all modules are assigned to translation units,
        //  and all units have their content and dependencies hashed,
        //   we can go and determine the exact dependencies of each testcase.
        //
        for (mut i = 1; i < ctx.modules.len; i++)
        {
            let testsuite_modids = ctx.modules[i].out.cpp.testsuite_modids;
            if (!testsuite_modids)
                continue;

            let unit_index = unit_indices[i];
            unit_index > 0 || fail("Testsuite without a translation unit.");

            ref unit = units[unit_index];
            testsuite_modids.each: |modid|
            {
                shadow let unit_index = unit_indices[modid];
                if (unit_index < 0)
                    continue;

                unit.testsuite_units.add(unit_index);
            }
        }

        for (mut i = 0; i < units.len; i++)
        {
            ref unit = units[i];
            if (!unit.testsuite_units)
                continue;

            // TODO FIX this is a POC, should be doable without rampant copying
            mut testsuite = unit;

            // We need to bump the obj_hash here, will be compiled with different options -
            testsuite.obj_hash.hash(".testsuite");
            testsuite.obj_cache_file ~= ".testsuite";
            testsuite.src_output_file ~= ".testsuite";

            mut testsuite_units =
                unit.testsuite_units.keys_asc.map(|unit_index|
                    units[unit_index])
                        ~ testsuite;

            buildTarget(
                testsuite_units, :file_invariants,
                :bscheme, :flags_cc, :flags_ld, :GCC_CMD,

                onfail: onfail
                      | OnFail_PrintInput
                      | OnFail_WriteRepro,

                runmode: "Testsuite",
                expect_exit: 0);
        }
    }


    //

    outputSources(units, :dir_cpp, :dir_src, :unity);


    //

    return ret;
}


// No modules past this point.

fn buildTarget(
    implicit ctx:       Context,
    implicit dir_wrk:   DirWrk,

    // TODO we need to clean up two things here -
    //  one, mutating units here doesn't make sense if we want to build targets in parallel -
    //   two - there's this file_invariants check before we commit temp files to the obj cache,
    //    which is also an effort we don't want to duplicate between build targets
    //     if we're gonna build them in parallel.
    //
    ref units:          TranslationUnit[],
    file_invariants:    FileInvariants[],

    //
    flags_cc!:          string[],
    flags_ld!:          string[],

    // TODO FIX all of these -
    onfail!:            DEV_OnFail,
    runmode!:           RunMode,
    expect_exit!:       int,
    bscheme!:           BuildScheme,
    ////////////////////////////////

    // Now it's obvious a single bin can't make sense
    //  if we'll want to build multiple libs and executables in one go
    bin!?:              string,

    //
    GCC_CMD!:           string)
{

    // Schedule cleanup - will delete temp files, if any.

    defer for (mut i = 0; i < units.len; i++)
    {
        let unit = units[i];

        // Unlink + print & ignore errors.
        fn try_unlink(path: string) {
            if (path) {
                let err = file::unlink(:path);
                if (err)
                    println(" UNLINK " ~ ("E" ~ err).qBAD ~ " " ~ path);
            }
        }

        try_unlink(unit.tmp_file);

        //
        if (unit.cache_cleanup & "Cpp")
            try_unlink(unit.cpp_cache_file);
        if (unit.cache_cleanup & "Obj")
            try_unlink(unit.obj_cache_file);
    }


    //

    mut HACK_linkFlags:         flat::Set(string);
    mut HACK_pkgConfig_libs:    flat::Set(string);
    mut HACK_include_dirs:      flat::Set(string);

    fn link_each(link: flat::Set(string), each)
    {
        for (mut i = 0; i < link.keys_asc.len; i++)
        {
            let item = link[i];
            let isFlag = item.starts(with: '-');
            each(flag?: isFlag && item, lib?: !isFlag && item);
        }
    }

    mut len_all: i32;
    mut hash_all: tea::TEA;

    units.each: |ref unit|
    {
        len_all += unit.src.len;
        hash_all.hash(unit.obj_hash);

        HACK_include_dirs.add(unit.hacks.include_dirs);

        unit.hacks.link.link_each: |flag, lib|
            if (flag)
                HACK_linkFlags.add(flag);
            else if (lib)
                HACK_pkgConfig_libs.add(lib);
    }

    let INCLUDE = (flags_cc && " " ~ flags_cc.join(' ')) ~ " -I " ~ ctx.fudir ~ "include"
                ~ (HACK_include_dirs && " -I " ~ HACK_include_dirs.keys_asc.join(" -I "));

    let LIBS = (flags_ld && " " ~ flags_ld.join(' '))
             ~ (HACK_linkFlags      && " "                     ~ HACK_linkFlags.keys_asc.join(" "))
             ~ (HACK_pkgConfig_libs && " $(pkg-config --libs " ~ HACK_pkgConfig_libs.keys_asc.join(" ") ~ ")");

    //
    len_all += LIBS.len;
    hash_all.hash(LIBS);

    //
    mut code:   i32;
    mut stdout: string;

    fn ERR(mut cpp?: string)
    {
        units.each: |ref unit|
            unit.cache_cleanup &= ~CacheCleanup.Cpp;

        if (onfail & OnFail_WriteRepro)
        {
            if (!cpp) for (mut i = units.len; i --> 0; )
            {
                ref unit = units[i];
                if (unit.cpp_cache_file)
                    cpp ~= "#include \"" ~ unit.cpp_cache_file ~ "\"\n";
            }

            let fname = dir_wrk.cpp ~ "failing-testcase.cpp";
            println("  WRITE " ~ fname);
            atomic_write(:fname, cpp);
        }

        // Print exit code.
        if (stdout)
            stdout ~= "\n\n";

        stdout ~= "   EXIT code: " ~ code;

        //
        mut explain = "";

        if (onfail & OnFail_PrintInput)
        {
            explain ~= runmode == "CompilerTestcase"
                ? "\n\n\tCOMPILER BUG or INCORRECT TESTCASE:\n\n"
                : "\n\n\tFAILING TESTCASE:\n\n";

            units.each: |unit|
                explain ~= unit.human ~ "\n";
        }

        if (onfail & OnFail_PrintOutput)
        {
            explain ~= "\n\n\tGenerated code:\n\n";
            units.each: |unit|
                explain ~= unit.src;
        }

        return fail(stdout ~ explain);
    }

    //
    let F_exe       = dir_wrk.bin ~ hash_all.digest16 ~ "-" ~ len_all;
    let old_size    = !(bscheme & "nocache") && file::size(F_exe);

    ////////////////////////////////////////////////
    // TEMP re-run tests without allocation stats //
    shadow let old_size = old_size != 4 && old_size;
    // TEMP re-run tests without allocation stats //
    ////////////////////////////////////////////////

    if (old_size < 1 && (bin || runmode))
    {
        struct BuildError {
            code: i32;
            cpp: string;
            stdout: string;
        };

        fn buildUnit(ref unit: TranslationUnit, i: int): BuildError
        {
            let F_cpp = unit.cpp_cache_file;
            let F_obj = unit.obj_cache_file;
            if (!F_cpp || !F_obj)
                return [];

            if (file::size(F_obj) > 0 && !(bscheme & "nocache"))
                return [];

            // We'll be doing work here.
            unit.tmp_file = tmpfile();

            unit.cache_cleanup |= "Cpp";

            let cpp = unit.src;
            atomic_write(fname: F_cpp, cpp);

            println("  BUILD ", unit.human, " ", F_cpp);

            let t0 = now::hr();

            //
            mut HACK_pkgConfig_cflags: string;

            unit.hacks.link.link_each: |lib|
            {
                if (!lib)
                    continue;
                if (!HACK_pkgConfig_cflags)
                    HACK_pkgConfig_cflags = " $(pkg-config --cflags";

                HACK_pkgConfig_cflags ~=
                    HACK_pkgConfig_cflags
                        ? " "
                        : " $(pkg-config --cflags ";

                HACK_pkgConfig_cflags ~= lib;
            }

            if (HACK_pkgConfig_cflags)
                HACK_pkgConfig_cflags ~= ")";

            ///////////////////////////////////////////////////////////////////
            shadow let INCLUDE = INCLUDE ~ HACK_pkgConfig_cflags;
            ///////////////////////////////////////////////////////////////////

            ////////////////////////////////////////////////////////////////////////////////////////////////
            shadow let INCLUDE = INCLUDE ~ (unit.iquote && " -iquote " ~ unit.iquote);
            ////////////////////////////////////////////////////////////////////////////////////////////////

            let TODO_FIX_define_fu_TESTSUITE =
                F_obj.ends(with: ".o.testsuite") && "-Dfu_TESTSUITE ";

            let CMD = GCC_CMD
                    ~ TODO_FIX_define_fu_TESTSUITE
                    ~ "-c" ~ INCLUDE ~ " -o " ~ unit.tmp_file ~ " " ~ F_cpp;

            // println("      > ", CMD);
            shadow mut stdout: string;

            shadow let code = exec(CMD, :stdout);
            if (code)
                return BuildError(:code, :cpp, :stdout);

            // Testcases -
            // Discard object files after linking.
            if (runmode == "CompilerTestcase" && i > 0)
                unit.cache_cleanup |= "Obj";

            //
            let t1 = now::hr();
            println("     OK ", unit.human, " ", t1 - t0, "s");
            return [];
        }

        // Build.
        let buildErrors = units.par::map(fn buildUnit);

        for (mut i = 0; i < buildErrors.len; i++)
        {
            let err = buildErrors[i];
            if ((code = err.code))
            {
                stdout = err.stdout;
                return ERR(err.cpp);
            }
        }


        // We've built all object files, they're still under workspace/temp.
        //  We can't trust the hashes if some header was modified while we were building,
        //   so we'll have to check if we need to scrap this build.

        mut _didCrosscheckHeaders: int;

        fn crosscheckHeaders_beforePersistingTempObjects()
        {
            if (_didCrosscheckHeaders++)
                return;

            file_invariants.each: |file_invariant|
            {
                let expect = file_invariant.stat;

                mut actual: file::Stat;
                let err = file::stat(:file_invariant.path, into: actual);

                if (err || actual.size != expect.size
                        || actual.mtime != expect.mtime)
                {
                    fail("Header crosscheck failed for:"
                        ~ "\n\t" ~ file_invariant.path
                        ~ "\n\n\tError: " ~ (err ? ("E" ~ err).qBAD : "mtime changed."));
                }

                // Uncomment this to verify this isn't running unnecessarily.
                // println(" HEADOK " ~ file_invariant.path ~ " " ~ actual.size ~ "b");
            }
        }

        for (mut i = 0; i < units.len; i++)
        {
            ref unit = units[i];
            if (unit.tmp_file)
            {
                crosscheckHeaders_beforePersistingTempObjects();

                //
                let from = unit.tmp_file;
                let to   = unit.obj_cache_file;

                let err = file::rename(:from, :to);
                if (err)
                    fail("Build cache failed to move temporary:\n\t" ~ from
                        ~ "\n\n\tto the object cache at:\n\t" ~ to
                        ~ "\n\n\tError: " ~ ("E" ~ err).qBAD);

                unit.tmp_file.clear();
            }
        }


        // Link.

        let F_tmp = tmpfile();

        mut cmd = GCC_CMD ~ "-o " ~ F_tmp;

        if (bscheme & "shared")
        {
            cmd ~= " -shared";

            // Linker -soname
            let soname = path::filename(bin);
            if (process::APPLE)
                cmd ~= " -Wl,-install_name,@rpath/" ~ soname;
            else
                cmd ~= " -Wl,-soname," ~ soname;
        }

        for (mut i = 0; i < units.len; i++)
        {
            let unit = units[i];
            if (unit.obj_cache_file)
                cmd ~= " " ~ unit.obj_cache_file;
        }

        //
        {
            println("   LINK ", F_exe, LIBS);

            let t0 = now::hr();

            let CMD = cmd ~ LIBS;

            // println("      > ", CMD);

            code = exec(CMD, :stdout)
                || file::chmod(F_tmp, file::RWX_RX_RX).int
                || file::rename(F_tmp, F_exe).int;

            if (code)
            {
                println("   FAIL " ~ CMD ~ " EXIT=" ~ code ~ "\n" ~ stdout);
                return ERR;
            }

            let t1 = now::hr();
            println("     OK ", t1 - t0, "s");
        }

        if (code) return ERR;
    }

    //
    mut output: test_output::TestOutput;

    if (runmode &&
        runmode != "EnsureExecutableButDontRun")
    {
        // TODO FIX This needs to get out of here,
        //  but brief this is the compiler test suite runner,
        //   includes caching for test results so we don't have to
        //    constantly rerun them.
        //
        let OPTI_StatusCode = runmode == "CompilerTestcase"
                           || runmode == "Testsuite";

        let F_out = OPTI_StatusCode && dir_wrk.out ~ F_exe[dir_wrk.bin.len ..];
        let READ_LAZILY = "\read lazily";

        mut status: spawn::ExitStatus;

        //
        fn READ_cachedTestOutput()
        {
            mut src: string;
            file::read(F_exe, into: src);

            output  = test_output::parse(src);
            status  = output.status;
            stdout  = READ_LAZILY;
        }

        fn WRITE_cachedTestOutput()
        {
            let out = test_output::serialize(output);
            out.len == 20 || fail("TestOutput.len != 20");
            atomic_write(fname: F_exe, out);

            if (stdout)
                atomic_write(fname: F_out, stdout);
        }

        //
        stdout = "";

        if (OPTI_StatusCode
            && old_size.test_output::looks_legit)
        {
            READ_cachedTestOutput();
        }
        else
        {
            {
                println("    RUN " F_exe);

                let t0  = now::hr();
                code    = ::spawn([ F_exe ], :status, :stdout, stderr: stdout, passthrough: runmode == "Normally").int;
                output  = test_output::from(:stdout, :status);
                let t1  = now::hr();

                println("     OK ", t1 - t0, "s",
                    status.signalled && " signal(" ~ status.signal ~ ")",
                    status.exited    && " exit(" ~ status.exit ~ ")",
                    code             && " errno(" ~ code ~ ")");
            }

            //
            if (OPTI_StatusCode)
            {
                // However, when tests run in parallel this can totally brick itself -
                //  if for some reason we already did this and tried to run the 4-byte exe,
                //   it obviously breaks and here we'd persist the broken result forever.
                //
                let new_size = file::size(F_exe);
                if (new_size.test_output::looks_legit)
                {
                    // We can notice the exe has shrunk to 4 bytes though,
                    //  and discard the result of our run with the one
                    //   that was just cached by a parallel run.
                    //
                    READ_cachedTestOutput();
                }
                else if (!code)
                {
                    WRITE_cachedTestOutput();
                }
            }
        }

        if (!code)
            if !(status.exited && status.exit == expect_exit)
                code = status.int || -1;

        // Only read cached outputs when we're about to abort.
        if (OPTI_StatusCode && code && stdout == READ_LAZILY) {
            stdout = "";
            file::read(F_out, into: stdout);
        }
    }

    if (code)
        return ERR;

    // output binary.
    if (bin)
    {
        fs::mkdir_p( path::dirname(bin) );

        code = file::rename(F_exe, bin).int;
    }

    if (code) return ERR;

    //
    return BuildOutput(executable: bin || F_exe, :output);
}


//

fn outputSources(
    units:              TranslationUnit[],
    dir_src!:           string,
    dir_cpp!:           string,
    unity!:             string)
{
    // .cpp file output.
    if (dir_cpp && dir_src)
    {
        fs::mkdir_p(dir_cpp);

        mut cpp_files: string[];

        for (mut i = 1; i < units.len; i++)
        {
            let unit            = units[i];

            // TODO NEXT BOOTSTRAP failcase exits + fixed
            // TODO let data    = unit.src; + replace unit.src below with data
            let fname           = unit.src_output_file || fail("Translation unit has no src_output_file.");
            shadow let fname    = update_file(
                :fname, data: unit.src,
                :dir_src, :dir_cpp);

            cpp_files.push(fname);
        }

        // .unity.cpp
        if (unity)
        {
            mut data    = "#ifdef fu_UNITY_FULIB\n"
                        ~ "#include <fu/_fulib.cpp>\n"
                        ~ "#endif\n\n";

            let fname   = unity ~ ".unity.cpp";
            let dest    = update_file_dest(:fname, :dir_src, :dir_cpp);

            for (mut i = 0; i < cpp_files.len; i++)
                if (let incl = cpp_files[i])
                    data ~= "#include \"" ~ path::relative(dest, incl) ~ "\"\n";

            update_file(:dest, :data, :dir_cpp);
        }
    }
}
