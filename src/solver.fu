import ansi;
import helpers;
import flags;
import scope;
import context;
import types;
import quals;
import structs;
import flow;
import effects;
import module;
import notes;
import fail;


//

let OPTI_autoshadow         = true;
let OPTI_dedupe_vars        = true;
let OPTI_flatten_blocks     = true;
let OPTI_bck                = true;

let USE_nontriv_autocopy    = true;

let SELF_TEST               = true;


// When you have an if (a -> $T) somewhere,
//  it's just not very useful for -> to match on default-anything,
//   so let's define `->` to be the `is` operator.
//
// We have the `=>` as the `as` operator,
//  we need a counterpart for an `assigns to` operator,
//   which can naturally fit zeroes.
//
let DONT_match_zeroes       = true;



///////////////////////////////////////
///////////////////////////////////////
///////////////////////////////////////
///////////////////////////////////////
////////
////////
////////
////////     Solver.

pub fn solve(
    implicit ctx: Context,
    implicit ref module: Module,
    implicit options: options::Options): SolverOutput
{
    let parse = module.in.parse.root;

    let shortModuleName = module.modid && getShortModuleName(module.fname);


    //

    let implicit mut _here: TokenIdx;


    //

    mut _scope:         Scope;
    mut _root_scope:    ScopeMemo;
    mut _ss:            ScopeSkipMemos;
    mut _field_items:   ScopeItem[];
    mut _notes:         i32;

    struct RWEvent
    {
        rw_target:      i32;
    };

    struct ReadID  { id: i32 };
    struct WriteID { id: i32 };

    struct EventsSnap
    {
        // Writes invalidate subsequent reads -
        invalidated_by:     WriteID[][];
    };

    struct Events
    {
        using snap:         EventsSnap;

        // In a loop, reads forbid subsequent writes -
        used_in_a_loop:     ReadID[];

        // The arguments at risk aparata.
        ever_written:       bitset::BitSet;

        // The read/write journal, for checking order of eval.
        //  I think unordered access should be super strict,
        //   everything that's not disjoint must error out.
        //
        reads:              RWEvent[];
        writes:             RWEvent[];
    };

    fn Events_merge(ref events: Events, snap: EventsSnap)
    {
        fn Events_merge(ref dest: $T[], src: $T[])
        {
            if (dest.len < src.len)
                dest.grow(src.len);

            for (mut i = 0; i < src.len; i++) {
                shadow let src = src[i];
                if (src)
                    dest[i].set::add(src);
            }
        }

        for (fieldname i: snap)
            events.i.Events_merge(snap.i);
    }

    struct CurrentFn
    {
        using out:      SolvedNode;

        // Start-of-func scope0 for implicit scopeskip.
        scope0:         ScopeMemo;

        using flow?:    Flow;

        effects?:       Effects;
        events?:        Events;
        loop_start?:    i32;

        // The replacement for the callsites stuff.
        var_usage?:     Type[];
    };

    mut _current_fn:                CurrentFn;
    let implicit mut _helpers:      Helpers[];      // TODO rename, this is the block helpers stack, unwinds during solve
    let implicit mut _helpers_data: HelpersData[];  // TODO rename, this is the block helpers repo, survives till end of function

    fn push(data: HelpersData)
    {
        _helpers       ~= Helpers(index: _helpers_data.len);
        _helpers_data  ~= data;
    }

    mut _anons:         i32;
    fn ANON(): string = "0" ~ _anons++;


    // Setup the module globals helper.

    _scope.extended ~= Extended();  // global nodes and such
    push(HelpersData());            // not sure why this is needed

    mut _current_fn_or_type = Target(:module.modid, index: 0); // root!


    // Can't we just list them all and scan through?
    //  Do we need the mangling nonsense?
    //   We can bucket however many times we want here,
    //    its append only and trivial to maintain.

    mut _specs: map::Map(string, Target); // mangle -> spec
    mut _spec_errors = [ "BUG: Specializer reentry." ];


    //

    struct Warning {
        token:      TokenIdx;
        message:    string;
    };

    mut _warnings: Warning[];


    //

    let t_string = createArray(t_byte);

    struct TypeParam {
        matched:  Type;
        consumed: Type;
    };

    type TypeParams = map::Map(string, TypeParam);


    //

    using inline fn GET(h: Helpers): HelpersData
    {
        return _helpers_data[h.index];
    }

    fn fail(mut reason: string): never
    {
        reason || BUG();

        // What were we currently solving?
        mut callstack = 0;
        for (mut i = _helpers.len; i --> 0; )
        {
            let h = _helpers[i];
            if (h.isFnOrType)
            {
                if (!callstack++)
                    reason ~= "\n\n        Solving ";
                else
                    reason ~=   "\n                ";

                let o = GET(h.target);
                reason ~= o.qWHAT;
            }
        }

        return FAIL(reason);
    }

    fn qWHAT(o: Overload)
    {
        let kind = o.kind;

        shadow let kind = kind == "var" && o.flags & F_ARG
            ? "arg"
            : kind;

        return kind.qKW ~ " " ~ o.name.human.qID;
    }

    fn qWHAT(arg: Argument)
    {
        return "arg".qKW ~ " " ~ arg.name.human.qID;
    }

    fn human(id: string)
    {
        let t = hacks::tryParseClosureID(:id).target;
        if (!t)
            return id;

        return GET(t.parent).name ~ ":" ~ GET(t).name;
    }

    fn makeNote(note: i32)
    {
        if (note & options.break_notes)
            fail("`break_notes`: Unwanted event: `" ~ note ~ "`.");

        _notes |= note;
    }


    // Public & private imports.

    fn _Scope_import__forceCopy(modid: i32): void
    {
        let s = ctx.modules[modid].out.solve.scope;

        _scope.items    ~= s.items   [0, s.pub_items ];
        _scope.converts ~= s.converts[0, s.pub_cnvrts];
    }

    fn _Scope_import__forceCopy_privates(modid: i32): void
    {
        let s = ctx.modules[modid].out.solve.scope;

        _scope.items    ~= s.items   [s.pub_items , s.items.len   ];
        _scope.converts ~= s.converts[s.pub_cnvrts, s.converts.len];
    }

    fn Scope_import(modid: i32): void
    {
        _scope.imports.each(_ss.imports): |m|
            if (m == modid)
                return;

        modid || BUG("Attempting to import modid-0.");
        _scope.imports ~= modid;
        _Scope_import__forceCopy(modid);
    }

    fn Scope_import_privates(modid: i32): void
    {
        _scope.privates.each(_ss.privates): |m|
            if (m == modid)
                return;

        modid || BUG("Attempting to import_privates modid-0.");
        _scope.privates ~= modid;
        _Scope_import__forceCopy_privates(modid);
    }


    //

    fn isLocal(target: Target)
    {
        return target.modid < 0;
    }

    using fn GET(target: Target)
    {
        if (target.isLocal)
            return _scope.extended[-target.modid].locals[target.index - 1];

        if (target.modid == module.modid)
            return _scope.overloads[target.index - 1];

        return ctx.modules[target.modid]
            .out.solve.scope.overloads[target.index - 1];
    }

    fn GET_mut(target: Target)
    {
        if (target.modid < 0)
            return _scope.extended[-target.modid].locals[target.index - 1];

        target.index > 0 && target.modid == module.modid || assert();
        return _scope.overloads[target.index - 1];
    }

    using fn EXT(target: Target)
    {
        if (target.modid == module.modid)
            return _scope.extended.unless_oob(target.index);

        return target.modid >= 0
            && ctx.modules[target.modid].out.solve.scope.extended.unless_oob(target.index);
    }

    fn localOf(target: Target)
    {
        if (target.isLocal)
            return -target.modid;

        return target.local_of;
    }

    fn parent(target: Target)
    {
        return Target(:module.modid, target.localOf);
    }

    fn EXT_mut(target: Target)
    {
        target.modid == module.modid || assert();
        return _scope.extended.grow_if_oob(target.index);
    }

    fn GET_next_local_index(implicit _current_fnort: Target)
    {
        return _current_fn.target.index
            && _scope.extended[_current_fnort.index].locals.len + 1;
    }

    fn nested(index: i32, implicit _current_fnort: Target)
    {
        return Target(modid: -_current_fnort.index || module.modid, :index);
    }

    // TODO failcase: uncommenting this leads to conversion resolution issues,
    //  i can't narrow it down and gotta work on smth else right now,
    //   so TODO bisect this here and minimize a test.
    //
    // using fn nested(local: Local)
    // {
    //     return nested(local.index);
    // }

    fn isNested(target: Target)
    {
        return target.modid == -_current_fn.target.index;
    }

    fn isFnOrType(h: Helpers): bool
        !!(h.mask & (HM_Function | HM_Struct));


    //

    fn isRefArg(o: Overload): bool
        o.flags & F_ARG && o.kind == "var" && o.solved.type.is_ref;

    fn isRTL(o: Overload): bool
        !!(o.flags & F_OOE_RTL);

    fn isRTL_set(ref o: Overload, rtl: bool)
        if (rtl)    o.flags |=  F_OOE_RTL;
        else        o.flags &= ~F_OOE_RTL;


    // RemoteNode nonsense

    fn solved_set(target: Target, node: SolvedNode)
        target.GET_mut.solved = node;


    //

    fn SolvedNode(
        kind:       string,
        type:       Type,
        flags?:     i32,
        value?:     string,
        items?:     SolvedNode[],
        target?:    Target,
        helpers?:   Helpers)
    {
        return SolvedNode(
            :kind, :flags, :value,
            :items,
            :type, :target, token: _here,
            :helpers);
    }

    // TODO FIX /////////////////////////////////
    mut TODO_FIX_convert_args = [ SolvedNode(kind: "", type: Type()) ];
    /////////////////////////////////////////////


    //

    fn Lifetime_fromNative(sig: [Node], args: [SolvedNode], actual: Type): Lifetime
    {
        sig.len + FN_ARGS_BACK == args.len || BUG("sig.len != args.len");

        let ret = sig[sig.len + FN_RET_BACK];
        mut mutref = ret.kind == "call" && ret.items.len == 1 && ret.value == "&mut";

        mut res: Type;
        for (;;)
        {
            for (mut i = 0; i < args.len; i++)
            {
                let inArg = sig[i];
                let annot = inArg.items[LET_TYPE];
                if (annot.items.len == 1 && ((annot.kind == "call"
                    && (!mutref && annot.value == "&" || annot.value == "&mut"))
                     || !mutref && annot.kind == "arrlit"))
                {
                    res && fail("Ambiguous __native lifetime.");

                    res = args[i].target.type;
                    res.lifetime || fail("Missing arg lifetime.");
                }
            }

            // Try again without the mutref,
            //  currently we have a bunch of drama related to case-patterns,
            //   the mutref annots actually come in the branches, not the arg annots.
            if (!mutref || res.lifetime)
                break;

            mutref = false;
        }

        res.lifetime.uni0n.only.Region_asLocal || fail(
            "Non-single-local __native lifetime.");

        // TODO FIX UNIQUENESS adding a static lifetime to ref results
        //  that are not assignable from the source argument,
        //   this coincides with container derefs currently -
        //
        // We only want to avoid attempts to move from there for now.
        //
        if (!isAssignable(host: actual, res))
            return Lifetime_makeShared(res.lifetime);

        return res.lifetime;
    }

    fn Lifetime_test(lifetime: Lifetime, tempsOK!?: bool): Lifetime
    {
        if (SELF_TEST)
        {
            let current_fn  = _current_fn.target;
            let debug_2     = current_fn && GET(current_fn);
            if (debug_2) {}

            if !(lifetime.uni0n.len)
                BUG("Lifetime_test: no region set.");

            mut _last: Region;
            for (mut i = 0; i < lifetime.uni0n.len; i++)
            {
                let region  = lifetime.uni0n[i];
                {
                    !i || region <> _last > 0 || BUG("Lifetime_test: not a sorted set");
                    _last = region;
                }

                // TODO we shouldn't see these during solve anymore
                if (Region_isArgPosition(region))
                    continue;

                if (region.Region_isTemp)
                {
                    i == lifetime.uni0n.len - 1 && tempsOK || BUG("Lifetime_test: unexpected temporary.");
                    continue;
                }

                let index = region.Region_toLocal;
                if (index)
                {
                    let o = GET(nested(:index));
                    o.kind == "var" || BUG("Lifetime_test: local is not a var: " ~ o.kind ~ " " ~ o.name);
                }
            }
        }

        return lifetime;
    }

    fn Lifetime_fromBinding(target: Target, local_of!: i32): Lifetime
    {
        target.modid < 0 || target.modid < 0 || target.modid == module.modid || BUG("not from this module");

        // Globals?
        if (!local_of)
            return Lifetime_static();

        // Argument?
        let index       = target.index;
        let region      = Region_fromLocal(index);

        return Lifetime_test(Lifetime(uni0n: [ region ]));
    }

    fn Lifetime_replaceArgsAtCallsite(target: Target, argNodes: [SolvedNode]): Lifetime
    {
        mut keep:       Lifetime;
        mut replace:    Lifetime;

        let returned    = target.type.lifetime;
        for (mut i = 0; i < returned.uni0n.len; i++)
        {
            let region = returned.uni0n[i];
            if (region.Region_isStatic)
            {
                keep.uni0n ~= region;
                continue;
            }

            region.Region_isTemp && BUG("Lifetime_replaceArgsAtCallsite: found a temp lt in: " ~ target.type.lifetime.qWHAT);

            let argNode = argNodes[region.Region_toArgPosition];
            let argLt   = argNode.type.is_ref
                ? argNode.type.lifetime
                : Lifetime_temporary();

            replace     = Lifetime_union(replace, argLt || BUG("refarg without lifetime"));
        }

        return replace
             ? keep ? Lifetime_union(keep, replace)
                    : replace
             : returned;
    }

    using fn Region_GET(r: Region)
    {
        return GET(nested(Region_toLocal(r)));
    }

    fn qWHAT(l: Lifetime)
    {
        mut str = "";
        for (mut i = 0; i < l.uni0n.len; i++)
        {
            if (i)
                str ~= "|";

            let r = l.uni0n[i];
            if (r.Region_isStatic)
                str ~= "static";
            else if (r.Region_isTemp)
                str ~= "temp";
            else
                str ~= r.qWHAT();
        }

        return str;
    }


    //

    fn autoshadow(ref shadows: bool, local_of: i32, id: string)
    {
        if (!shadows && local_of && shouldAutoshadow(id))
            shadows = true;
    }

    fn shouldAutoshadow(id: string)
    {
        if (!OPTI_autoshadow)
            return false;

        _scope.items.each(_ss.items): |item, i|
            if (i >= _root_scope.items_len)
                if (item.id == id)
                    return false;

        return true;
    }

    fn Binding(id: string, mut type: Type, flags!: i32, ref shadows!: bool)
    {
        mut name = id;

        //
        let local_of = _current_fn.target.index;

        // Unique identifiers.
        if (_root_scope)
        {
            // LEAKY TEMPLATES, part 1:
            //  All locals are F_SHADOW - this is a usability thing really,
            //   otherwise you'd simply have to `shadow` everything manually.
            //
            // Actually turning this on for everything -
            //  it might optimize scope lookups all over the place.
            //
            autoshadow(:shadows, :local_of, :id);
        }

        // Reserve the slot.
        let target = Scope_create(_scope, kind: "var", :name, :flags, nest:local_of);

        // Setup the lifetime for references to this binding.
        ref overload = GET_mut(target);
        {
            let lifetime = Lifetime_fromBinding(target, :local_of);

            ///////////////////////////////////////////////////////////////
            // Throw away argument lifetime, union below will fix it up. //
            // SHALLOW LIFETIMES: Now we do this for all refs.           //
            // if (flags & F_ARG) /////////////////////////////////////////
            type.lifetime = Lifetime(); ///////////////////////////////////
            ///////////////////////////////////////////////////////////////

            overload.type = flags & F_MUT
                ? add_mutref(type, lifetime)
                : add_ref   (type, lifetime);
        }

        return target;
    }

    fn createTemplate(node: Node): Template
    {
        return Template(
            node,
            imports:   !_current_fn && _scope.imports,
            scope_memo: _current_fn && Scope_snap(_scope),
            scope_skip: _current_fn && _ss);
    }


    //

    fn createDefinit(mut type: Type): SolvedNode
    {
        if (type.is_ref)
            type.lifetime = Lifetime_static();

        // TODO FIX this is backwards, its not always practical -
        //  tryRetype just switches the type but doesn't switch from definit to int/real lit.
        //   what'd be more useful is to have int & real literals snap to definit instead of these two.
        //
        if (type.is_integral)
            return SolvedNode(kind: "int", :type, value: "0");

        if (type.is_floating_pt)
            return SolvedNode(kind: "real", :type, value: "0");

        if (type.is_boolean)
            return createBool(value: "false", :type);

        return SolvedNode(kind: "definit", :type);
    }

    fn trySolveDefinit(type: Type): Type
    {
        if (!type)
            return t_zeroes;

        return type_trySuper(t_zeroes, type);
    }

    fn solveDefinit(type: Type): SolvedNode
    {
        return createDefinit(
            trySolveDefinit(:type) || fail(
                "Cannot definit type: " ~ humanizeType(type)));
    }

    fn getModule(modid!: i32)
    {
        if (modid == module.modid)
            return module;

        return ctx.modules[modid];
    }

    fn trimmedName(shadow module: Module)
    {
        let fname = module.fname;

        mut start = 0;
        mut end   = fname.len;

        for (mut i = end; i --> 0; )
        {
            let c = fname[i];
            if (c == '/')
            {
                start = i + 1;
                break;
            }

            if (c == '.')
                end = i;
        }

        return fname[start, end];
    }

    fn humanizeType(type: Type)
    {
        mut result: string = type.isStruct
            ? lookupStruct(type).name
            : type.canon;

        if (type.quals)
            result ~= humanizeQuals(type);

        // NOT SAFE! nested here blows up on return types
        // type.lifetime.uni0n.each: |r|
        // {
        //     result ~= " ref:".qLT;
        //     result ~= r.Region_isTemp() ? "temp".qKW
        //             : r.Region_isStatic ? "static".qKW
        //                                 : nested(Region_asIndex(r)).qWHAT;
        // }

        return result;
    }

    fn qWHAT(n: SolvedNode)
    {
        mut src = n.kind.qKW;

        if (n.kind == "call" || n.kind == "let" || n.kind == "letdef")
            src ~= "(" ~ n.target.qWHAT ~ ")";
        else if (n.value)
            src ~= "(" ~ n.value.qID ~ ")";

        if (n.type)
            src ~= " -> " ~ humanizeType(n.type);

        if (n.items.len == 1)
            src ~= " { " ~ n.items.only.qWHAT ~ " }";
        else if (n.items.len > 0)
            src ~= " { " ~ n.items.len ~ " }";

        return src;
    }


    //

    fn solveTypeCast(node: Node): SolvedNode
    {
        let left   = node.items[0];
        let right  = node.items[1];

        // left -> right.
        let expect = evalTypeAnnot(right);
        mut actual = solveNode(left, expect);

        //
        if (isAssignable(host: expect, actual.type))
            return actual;

        let conv = tryConvert(actual, :expect, local_scope: true);
        if !(conv)
            fail("Cannot convert: " ~ expect.humanizeType
                           ~ " <- " ~ actual.humanizeType);

        applyConversion(actual, conv);
        return actual;
    }

    fn solveTypeAssert(node: Node): SolvedNode
    {
        mut typeParams: TypeParams;
        return createBool(evalTypePattern(node, typeParams));
    }


    //

    fn reorderByNumUsings(
        ref use_reorder: bool, ref reorder: i32[],
        host_args: Argument[], num_args: i32, num_usings!: i32)
    {
        reorder.clear();

        if (num_usings)
        {
            for (mut i = 0; i < host_args.len; i++)
            {
                let x = i - num_usings;
                reorder.push(x >= 0 && x < num_args ? x : -1);
            }
        }

        use_reorder = !!reorder;
    }

    fn reorderByArgIDs(
        ref use_reorder: bool, ref reorder: i32[],
        names: string[], mut optional: bitset::BitSet,
        host_args: Argument[], num_usings!: i32): bool
    {
        use_reorder = true;
        reorder.clear();

        //
        mut used   = 0;
        mut offset = num_usings;
        for (mut i = 0; i < host_args.len; i++)
        {
            mut idx = names.find(host_args[i].name);
            if (idx < 0)
            {
                for (shadow mut i = offset; i < names.len; i++)
                {
                    offset++;
                    if (!names[i])
                    {
                        idx = i;
                        break;
                    }
                }
            }
            else
            {
                used++;
                optional.rem(i);
            }

            reorder.push(idx);
        }

        // Fail if some name ended up unused.
        //  TODO FIX THIS MESS
        if (used != names.len)
        {
            for (mut i = 0; i < names.len; i++)
                if (!names[i])
                    used++;

            if (used + optional.popcount != names.len)
                return false;
        }

        // Drop trailing misses.
        while (reorder && reorder[reorder.len - 1] < 0)
            reorder.pop();

        // See if needed.
        if (reorder.len != names.len)
            return true;

        for (mut i = 0; i < reorder.len; i++)
            if (reorder[i] != i)
                return true;

        // Matches but no need for the reorder stuff.
        reorder.clear();
        use_reorder = false;

        return true;
    }

    fn findRestStart(ext: Extended)
    {
        for (mut i = ext.args.len; i --> 0; )
        {
            let arg = ext.args[i];
            if  (arg.flags & F_REST_ARG) return i;
            if !(arg.flags & F_IMPLICIT) break;
        }

        return ext.args.len;
    }

    fn tryMatch__mutargs(
        mut id: string,
        ref reorder: i32[],
        ref conversions: Target[][],
        ref error!: string,
        local_scope!?: bool,
        misc_scope!?: Scope,
        args?: [SolvedNode],
        flags!?: i32, target!?: Target): Target
    {
        let error_len0 = error.len;

        if (SELF_TEST)
            for (mut i = 0; i < args.len; i++)
                if (!args[i].kind)
                    BUG("Falsy arg.kind!");

        mut matchIdx: Target;

        fn countUsings()
        {
            shadow let scope = local_scope ? _scope : misc_scope;

            mut count = 0;
            if (scope.usings)
                scope.usings.each(local_scope && _ss.usings, |u| u ? count++ : BUG());

            return count;
        }

        mut minArity        = args.len;
        let numUsings       = countUsings();
        let explicitArity   = minArity;
        let maxArity        = explicitArity + numUsings;

        // Prep labelled args for remap.
        mut names: string[];
        mut optional: bitset::BitSet;
        if (flags & F_NAMED_ARGS)
        {
            mut some = false;

            for (mut i = 0; i < args.len; i++)
            {
                let arg = args[i];
                names.push(arg.kind == "argid"
                    ? { some = true; arg.value } || BUG()
                    : "");

                if (arg.flags & F_OPT_ARG)
                {
                    minArity--;
                    optional.add(i);
                }
            }

            some || BUG();
        }

        mut reusable_mangle: string;

        // Argument & `using` dependent lookup,
        //  basically we do everything we can to get rid of imports.
        //
        // THIS LOOKS WORSE THAN IT IS:
        //  We only pushback stuff when the modules are not imported and there's an actual match,
        //   and we could possibly further filter them by arity.
        //
        mut extra_items: Target[];
        if (local_scope && !target)
        {
            mut seen: bitset::BitSet;

            fn visitTypeImports(type: Type)
            {
                let visit = type.lookupTypeImports();
                for (mut i = -1; i < visit.len; i++)
                {
                    let modid = i >= 0 ? visit[i] : type.modidOfOrigin;
                    if (seen.has(modid))
                        continue;

                    // Lazy init -
                    //  we want to ignore self and all imports,
                    //   and everything we've already traversed.
                    if (!seen)
                    {
                        seen.add(0);
                        seen.add(module.modid);
                        _scope.imports.each(
                            local_scope && _ss.imports,
                                |shadow modid| seen.add(modid));
                    }

                    if (!seen.add_once(modid))
                        continue;

                    //
                    let items = ctx.modules[modid].out.solve.scope.items;
                    for (shadow mut i = 0; i < items.len; i++)
                        if (items[i].id == id)
                            extra_items.push(items[i].target);
                }
            }

            // Usings.
            if (numUsings)
                (local_scope ? _scope : misc_scope).usings.each(
                    local_scope && _ss.usings,
                        |u| visitTypeImports(GET(u).type));

            // Field access, method calls & operator calls.
            //  TODO no way to opt-out of this for operators currently,
            //   consider regular id-names for all ops, so we can freefn call them.
            if (flags & (F_ACCESS | F_METHOD | F_OPERATOR))
                for (mut i = 0; i < args.len; i++)
                    visitTypeImports(args[i].type);
        }

        // TODO the whole field_items thing is a mess,
        //  we really need a cleaner way to put these things up.
        let field_items = local_scope && (flags & F_ACCESS || !minArity)
            && minArity <= 1 && maxArity
            && _field_items;

        //
        mut alternate_ids: string[];

        // This got kinda messy.
        inline fn _SCOPE_ITEMS =
            local_scope
                ? flags & F_IMPLICIT ? _scope.implicits : _scope.items
                : misc_scope.items[0, misc_scope.pub_items];

        inline fn _SSKIP_ITEMS =
            local_scope &&
                (flags & F_IMPLICIT ? _ss.implicits : _ss.items);

        //
        for (;;)
        {
            mut scope_iterator: i32;
            mut overloadIdx: Target;

            //
            mut shadows: bool;
            :MATCH_FAIL while (overloadIdx =
                _SCOPE_ITEMS
                    .search(id, scope_iterator,
                        scope_skip: _SSKIP_ITEMS,
                        dont_search_just_return: target, :extra_items, :field_items, :shadows))
            {
                mut DEBUG_mustMatch = false;

                ///////////////////////////////////
                ref conversions_out = conversions;
                shadow mut conversions: Target[][];

                ref reorder_out = reorder;
                shadow mut reorder: i32[];

                shadow let args = args;

                mut TODO_FIX_skip_autocalls = false;
                ///////////////////////////////////

                :TEST_AGAIN while (true)
                {
                    let overload = GET(overloadIdx);

                    fn matchFail(inline err: string)
                    {
                        if (DEBUG_mustMatch || error)
                        {
                            shadow let err = overload.qWHAT ~ ": " ~ err;

                            if (DEBUG_mustMatch)
                                BUG("mustMatch.matchFail: " ~ err);
                            else
                                error ~= "\n\n\t" ~ err;
                        }

                        continue :MATCH_FAIL;
                    }

                    // Make sure we know what this is.
                    if (lazySolveStart(overloadIdx, overload))
                        continue :TEST_AGAIN;

                    ////////////////////////////////////////////
                    // Conversions / typename aliases.
                    let kind    = overload.kind;
                    let isType  = kind == "type";
                    if (minArity && isType && !target)
                    {
                        let alt = overload.type.canon;
                        if (alt != id) // e.g. i32
                            alternate_ids.push(alt);
                    }
                    ////////////////////////////////////////////

                    // Arity check.
                    let arity = overloadIdx.EXT;
                    let isZeroInit = isType && !explicitArity;
                    if (!isZeroInit && (arity.max < minArity || arity.min > maxArity))
                    {
                        fn str(min: i32, max: i32)
                            min != max  ? "[" ~ min ~ ", " ~ max ~ "]"
                                        : min.str;

                        matchFail("Wrong number of arguments: expects " ~ str(:arity.min, :arity.max)
                                ~ ", got " ~ str(minArity, maxArity) ~ ".");
                    }

                    // Reorder by argument names or number of implicit `using` args.
                    let host_args   = arity.args;
                    let num_usings  = !isZeroInit && arity.min > explicitArity
                                    && arity.min - explicitArity;

                    mut use_reorder = false;
                    if (!names)
                        reorderByNumUsings(:use_reorder, :reorder, host_args, args.len, :num_usings);
                    else if (!reorderByArgIDs(:use_reorder, :reorder, names, optional, host_args, :num_usings))
                        matchFail("Argument name mismatch [TODO REPORT]");

                    // Forbid optional argument ambiguities -
                    //  We should either have all optional args satisfied at the receiver or sender part,
                    //   we shouldn't allow dangling cables on both ends because that's super typo-prone.
                    if (optional && reorder)
                        if (reorder.len < args.len && reorder.len < arity.max)
                            matchFail("Optional argument ambiguity, not all optional arguments provided, and not all callsite arguments used. Cannot distinguish from a typo. [TODO LIST MISSING ARGS]");

                    fn disambig()
                    {
                        if (matchIdx)
                        {
                            fn GETfn(idx: i32) Target(modid: module.modid, index: idx);

                            fn fnName(idx: i32) idx
                                ? "`" ~ GETfn(idx).name ~ "`"
                                : "global scope";

                            let PREV        = matchIdx;
                            let NEXT        = overloadIdx;

                            let inner       = PREV.localOf;             // first to match is innermost scope
                            let outer       = NEXT.localOf;             //  what we're currently looking is upscope
                            let callsite    = _current_fn.target.index; //   as seen from where we currently are

                            if (SELF_TEST && PREV.kind != "field" /* the field_items connundrum, this is the easiest fix */)
                            {
                                mut _c = callsite;
                                while (_c > inner) _c = GETfn(_c).localOf;
                                _c == inner || BUG(
                                    "Leaking `" ~ id ~ "` between functions [inner/callsite]: "
                                        ~ inner.fnName ~ "::" ~ PREV.qWHAT
                                        ~ " is seen from " ~ callsite.fnName);

                                mut _i = inner;
                                while (_i > outer) _i = GETfn(_i).localOf;
                                _i == outer || BUG(
                                    "Leaking `" ~ id ~ "` between functions [inner/outer]: "
                                        ~ inner.fnName ~ "::" ~ PREV.qWHAT ~ " and "
                                        ~ outer.fnName ~ "::" ~ NEXT.qWHAT
                                        ~ " as seen from " ~ callsite.fnName);
                            }

                            fail("Ambiguous callsite, matches multiple items in scope:"
                                ~ "\n\n\t" ~ explainWhichFn(PREV, conversions_out) ~ " from " ~ inner.fnName ~ " and "
                                ~ "\n\n\t" ~ explainWhichFn(NEXT, conversions    ) ~ " from " ~ outer.fnName ~ ", as seen from " ~ callsite.fnName ~ ".");
                        }
                    }

                    mut REST_TYPE: Type;
                    mut REST_EXPECT: Type;
                    let REST_START = arity.findRestStart();

                    let N = (use_reorder ? reorder.len : args.len)
                        .max(!isZeroInit && arity.min);

                    if (REST_START < N)
                    {
                        let expect = host_args[REST_START].type;
                        if (expect)
                            REST_EXPECT = tryClear_sliceable(expect) || fail(
                                overloadIdx.name
                                    ~ ": Rest argument annotation is not an array: "
                                    ~ humanizeType(expect));
                    }

                    if (N)
                    {
                        reorder.len >= args.len || !reorder || optional || BUG("reorder < args.");

                        :ARG_OK
                        for (mut i = 0; i < N; i++)
                        {
                            let rest        = i >= REST_START;
                            let host_arg    = host_args[rest ? REST_START : i];
                            let expect      = rest ? REST_EXPECT : host_arg.type;

                            // TODO FIX!
                            if (TODO_FIX_skip_autocalls && rest)
                                continue :ARG_OK;

                            // Its either reorder or args, asserted above [^].
                            let callsiteIndex   = use_reorder   ? reorder[i]
                                                : i < args.len  ? i
                                                : /*using*/ -1;

                            if (callsiteIndex < 0)
                            {
                                // Argument may not be defaulted -
                                //  we might be supplying defaults via names
                                //   before we've actually exhausted
                                //    all the non-defaulted stuff.
                                if (host_arg.default || host_arg.flags & F_IMPLICIT)
                                    continue :ARG_OK;

                                // Usings - can't match on explicitly named arguments.
                                if !(host_arg.flags & F_MUSTNAME || flags & F_CONVERSION)
                                {
                                    // Can't proceed if we don't know what we're looking for.
                                    //  If we decide to not support more than a single using,
                                    //   we could simply assume it's a match here.
                                    //
                                    if (expect)
                                    {
                                        let conversion = tryConvert(:misc_scope, :local_scope, :expect);
                                        if (conversion)
                                        {
                                            conversions.grow_if_oob(i) = conversion;
                                            continue :ARG_OK;
                                        }
                                    }
                                }

                                matchFail("Cannot infer missing argument " ~ host_arg.qWHAT);
                            }

                            // Explicit argname requirements.
                            if (host_arg.flags & F_MUSTNAME)
                            {
                                if (names.len <= callsiteIndex || !names[callsiteIndex])
                                    matchFail("Argument must be :explicitly named " ~ host_arg.qWHAT);
                            }

                            // Autocall.
                            if (host_arg.autocall && !TODO_FIX_skip_autocalls)
                            {
                                mut autocall_args:          SolvedNode[];
                                mut autocall_reorder:       i32[];
                                mut autocall_conversions:   Target[][];

                                autocall_args.resize(1);
                                autocall_args[0] = args[callsiteIndex];

                                mut autocall_error = error
                                    && "Cannot match argument " ~ host_arg.qWHAT ~ " autocall " ~ host_arg.autocall.qCODE ~ ": ";

                                let t = tryMatch__mutargs(:misc_scope, :local_scope, id: host_arg.autocall, args: autocall_args, reorder: autocall_reorder, conversions: autocall_conversions, error: autocall_error);
                                if (!t)
                                    matchFail(autocall_error.replace("\t", "\t\t"));

                                if (autocall_conversions)
                                    conversions.grow_if_oob(i) ~= autocall_conversions.only;

                                conversions.grow_if_oob(i) ~= t;
                                autocall_reorder.len < 2 || BUG("autocall: reorder");
                            }

                            // Actual arg type.
                            let hasConv = conversions.len > i && conversions[i].len;
                            let actual = hasConv
                                ? GET(conversions[i].last).type
                                : args[callsiteIndex].type;

                            // Templates arguments.
                            if (!expect)
                            {
                                // TODO FIX Check that ref args are mutrefs,
                                //  otherwise we get mustMatch fails after a spec-ok.
                                if (host_arg.flags & F_REF && !actual.is_mutref)
                                    matchFail("Argument " ~ host_arg.qWHAT
                                            ~ " expects a mutref, got " ~ humanizeType(actual));

                                continue :ARG_OK;
                            }

                            if (isAssignableAsArgument(expect, actual || BUG("tryMatch: !actual")))
                                continue :ARG_OK;

                            /////////////////
                            // Literal fixup.
                            if (!hasConv)
                            {
                                let        arg = args[callsiteIndex];
                                shadow let arg = arg.kind == "argid"
                                    ? arg.items.only
                                    : arg;

                                let retype = tryRetyping(arg, expect);
                                if (retype && isAssignableAsArgument(expect, retype))
                                    continue :ARG_OK;
                            }
                            //        /LITFIX
                            /////////////////

                            // Go through conversions here.
                            if !(flags & F_CONVERSION)
                            {
                                let conversion = tryConvert(:misc_scope, :local_scope, :expect, :actual, retype: !hasConv && args[callsiteIndex]);
                                if (conversion)
                                {
                                    conversions.grow_if_oob(i) ~= conversion;
                                    continue :ARG_OK;
                                }
                            }

                            // Nope, args fail.
                            matchFail("Argument " ~ host_arg.qWHAT
                                    ~ " expects " ~ humanizeType(expect)
                                    ~ ", got "    ~ humanizeType(actual));
                        }
                    }

                    if (REST_START < N)
                    {
                        for (mut i = REST_START; i < N; i++)
                        {
                            let hasConv         = conversions.len > i && conversions[i].len;
                            let callsiteIndex   = use_reorder ? reorder[i] : i;
                            let actual          = hasConv
                                ? GET(conversions[i].last).type
                                : args[callsiteIndex].type;

                            REST_TYPE = i == REST_START
                                ? solveArrlit_itemType_init(head: actual)
                                : type_trySuper(REST_TYPE, actual)
                                    || matchFail("Rest arguments have no common supertype: "
                                                             ~ humanizeType(REST_TYPE)
                                                    ~ " <- " ~ humanizeType(actual));
                        }

                        REST_TYPE = solveArrlit_done(itemType: REST_TYPE);
                    }

                    // Specialize.
                    if (kind == "template")
                    {
                        mut cant_reuse: string;

                        shadow ref args_mangled =
                            (use_reorder || conversions
                                ? cant_reuse : reusable_mangle);

                        let specIdx = trySpecialize(
                            :overloadIdx, :args, :reorder, :use_reorder,
                            :conversions, :args_mangled,
                            :REST_START, :REST_TYPE);

                        if (specIdx.is_SPECFAIL)
                            matchFail("Could not specialize: " ~ _spec_errors[specIdx.index]);

                        // Repeat arity checks and such.
                        //
                        // TODO doesn't seem necessary anymore.
                        //  It's crazy to think that we'd specialize an inline
                        //   and end up not using it.
                        //
                        overloadIdx         = specIdx;
                        DEBUG_mustMatch     = true;

                        TODO_FIX_skip_autocalls = true;

                        continue :TEST_AGAIN;
                    }

                    // Forbid ambiguity.
                    disambig();

                    // Output conversions /////////////
                    swap(reorder,     reorder_out    );
                    swap(conversions, conversions_out);
                    ///////////////////////////////////

                    // Done!
                    matchIdx = overloadIdx;

                    // Arity 0 auto-shadows.
                    if (shadows)
                        break :MATCH_FAIL;

                    // Done here.
                    break :TEST_AGAIN;
                }
            }

            //////////////////////////////////
            // Conversions / typename aliases.
            if (!alternate_ids)
                break;

            id = alternate_ids.last;
            alternate_ids.pop();
            //////////////////////////////////
        }

        // Not defined msg.
        if (error && error.len == error_len0 && !matchIdx)
            error ~= id.qID ~ " is not defined here.";

        return matchIdx;
    }


    //

    fn couldRetype(node: SolvedNode): bool
    {
        return node.kind == "int"
            || node.kind == "real"
            || node.kind == "definit";
    }

    fn tryRetyping(node: SolvedNode, expect: Type): Type
    {
        if (node.is_arithmetic && expect.is_arithmetic)
        {
            if (node.kind == "int")
                return solveInt(node.value, expect);

            if (node.kind == "real")
                return solveNum(node.value, expect);
        }

        if (node.kind == "definit")
            return trySolveDefinit(expect);

        return [];
    }


    //

    fn explainConversion(shadow path: [Target])
    {
        mut res = "";
        for (mut i = 0; i < path.len; i++)
        {
            if (i) res ~= " -> ";

            let o = GET(path[i]);
            res ~= o.qWHAT;

            if (i < path.len - 1)
                res ~= ": " ~ humanizeType(o.type);
        }

        return res;
    }

    fn tryConvert(
        expect: Type, actual?: Type, retype?: SolvedNode,
        misc_scope!?: Scope, local_scope!: bool): Target[]
    {
        mut match:  Target[];
        mut path:   Target[];

        let has_converts    = (local_scope ? _scope : misc_scope).converts.len;

        ////////////////////////////////////
        mut arg0 = TODO_FIX_convert_args[0];

        mut TODO_FIX_reorder: i32[];
        mut TODO_FIX_conversions: Target[][];
        ////////////////////////////////////

        fn descend(from: Type, nullary!: bool, isStruct!: bool, root?: bool)
        {
            fn foreach(t: Target)
            {
                //////////////////////////////////////////////////
                mut arg0type0 = TODO_FIX_convert_args[0].type;

                if (!nullary)
                {
                    // Decidability [A]:
                    //
                    // Enforce strict ordering of conversion functions -
                    //  they can still solve out of order, but you can't use the syntax sugar
                    //   before the `using` declaration. Makes everything way simpler.
                    let here = _current_fn.target.index;
                    if (here && t.index > here && t.modid == module.modid && t.local_of != here)
                        return;

                    if (root && retype)
                        TODO_FIX_convert_args[0] = retype;
                    else
                        TODO_FIX_convert_args[0].type = from;
                }

                defer if (!nullary)
                {
                    if (root && retype)
                        TODO_FIX_convert_args[0] = arg0;
                    else
                        TODO_FIX_convert_args[0].type = arg0type0;
                }
                //////////////////////////////////////////////////

                mut error: string;
                mut candidate: Target;
                if (nullary || (candidate = tryMatch__mutargs(
                    target: t, :error,
                    id: "",
                    args: TODO_FIX_convert_args,
                    reorder: TODO_FIX_reorder,
                    conversions: TODO_FIX_conversions,
                    flags: F_CONVERSION)))
                {
                    shadow let t = nullary ? t : candidate;

                    let convert = GET(t);
                    convert.type || fail("No convert.type, perhaps a `using inline fn` without a return type annotation: `" ~ convert.qWHAT ~ "`.");

                    let convertType = convert.kind == "field"
                        ? add_refs(from: from || BUG(), to: convert.type)
                        : convert.type;

                    shadow let isStruct = convertType.isStruct;

                    if (convert.status & (SS_DID_START | SS_FINALIZED) == SS_DID_START)
                    {
                        // Decidability [B]:
                        //
                        // We ignore unsolved conversions:
                        //  this means you can't use a using fn recursively,
                        //   which solves the problem of unspecified return values,
                        //    because initially the t_never assigns to everything.
                    }
                    else if (isAssignableAsArgument(convertType, /*into*/host: expect))
                    {
                        // Actual is assignable to current `from` type,
                        //  this means we've got a conversion edge that works.
                        if (match)
                        {
                            mut suffix  = "\n\t\t" ~ explainConversion(match) ~ "\n\tand:"
                                        ~ "\n\t\t" ~ explainConversion(path ~ t);

                            if (actual)
                                fail("Conversion ambiguity, multiple ways to convert `"
                                    ~ humanizeType(actual) ~ "` into `"
                                    ~ humanizeType(expect) ~ "`: " ~ suffix);
                            else
                                fail("`using` ambiguity, multiple ways to obtain a `"
                                    ~ humanizeType(expect) ~ "` in this scope: " ~ suffix);
                        }

                        match = path ~ t;
                    }
                    else
                    {
                        let mightHaveConversion = isStruct || (local_scope ? _scope : misc_scope).converts;
                        if (mightHaveConversion)
                        {
                            // Forbid cyclic conversions.
                            //  Delaying the error check to speed up the general case.
                            if (path.len > 10)
                            {
                                for (mut i = path.len; i --> 0; )
                                {
                                    if (path[i] == t)
                                    {
                                        mut err = "Conversion loop:\n";

                                        for (shadow mut i = i; i < path.len; i++)
                                        {
                                            err ~= "\n\t    ";

                                            shadow let convert = GET(path[i]);
                                            err ~= convert.qWHAT ~ ": " ~ humanizeType(convertType) ~ " ->";
                                        }

                                        err ~= "\n\t        " ~ convert.qWHAT;
                                        fail(err);
                                    }
                                }
                            }

                            ///////////////////////////////
                            path.push(t); defer path.pop();
                            ///////////////////////////////
                            descend(convertType, nullary: false, :isStruct);
                            ///////////////////////////////
                        }
                    }
                }
            }

            // Usings.
            if (nullary)
            {
                (local_scope ? _scope : misc_scope)
                    .usings.each(local_scope && _ss.usings,
                        |u| foreach(u));
            }

            // On-struct stuff.
            else
            {
                if (isStruct)
                {
                    let inner = lookupStruct(from).converts;

                    // TODO no need to for the outer isAssignableAsArgument check.
                    // TODO can we split these into incoming and outgoing converts,
                    //       so we don't have to check anything at all?
                    //
                    for (mut i = 0; i < inner.len; i++)
                        foreach(inner[i]);
                }

                // Conversions.
                if (has_converts)
                    (local_scope ? _scope : misc_scope)
                        .converts.each(local_scope && _ss.converts,
                            fn foreach);
            }
        }

        // Go.
        descend(actual, nullary: !actual, :actual.isStruct, root: true);

        // We're done here.
        return match;
    }


    //

    fn match__mutargs(
        misc_scope: Scope, local_scope: bool,
        id: string, ref args: SolvedNode[],
        ref reorder: i32[],
        ref conversions: Target[][],
        flags: i32, target: Target): Target
    {
        mut error: string;

        let ret = tryMatch__mutargs(:misc_scope, :local_scope, :id, :args, :reorder, :conversions, :flags, :target, :error);
        if (ret)
            return ret;

        // Compose error message:
        //  separate pass, so we don't have to worry about unnecessary string concats.
        error = "Bad call to " ~ id.qID ~ ": ";

        let debug = tryMatch__mutargs(:misc_scope, :local_scope, :id, :args, :reorder, :conversions, :flags, :target, :error);
        if (debug)
            BUG("Did match on second pass: " ~ debug.qWHAT);

        fail(error);
    }

    fn explainWhichFn(overload: Target, conversions?: Target[][])
    {
        mut result = overload.qWHAT;

        if (overload.args)
        {
            result ~= "(";

            for (shadow mut i = 0; i < overload.args.len; i++)
            {
                let arg = overload.args[i];
                if (i)
                    result ~= ",";

                result ~= "\n\t    "
                        ~  arg.name.human.qID
                        ~ (arg.flags & F_MUSTNAME ? "!" : "")
                        ~ (arg.default ? "?: " : ": ")
                        ~ (arg.type ? humanizeType(arg.type) : "$");

                let c = conversions.len > i && conversions[i];
                if (c)
                    result ~= "\n\t        via " ~ explainConversion(c);
            }

            result ~= ")";
        }

        return result;
    }


    //

    fn solveNode(node: Node, type: Type = [], kills!?: i32): SolvedNode
    {
        HERE(node);

        let k = node.kind;

        if (k == "root")        return solveRoot(node);
        if (k == "block")       return solveBlock(node, :type, :kills);
        if (k == "argid")       return solveArgID(node, :type);

        if (k == "let")         return solveLet(node);
        if (k == "call")        return solveCall(node, :kills);
        if (k == "arrlit")      return solveArrlit(node, type);

        if (k == "if")          return solveIf(node, type);
        if (k == "or")          return solveOr(node, type);
        if (k == "and")         return solveAnd(node, type);

        if (k == "loop")        return solveLoop(node);
        if (k == "break")       return solveJump(node, kills);
        if (k == "return")      return solveJump(node, kills);
        if (k == "continue")    return solveJump(node, kills);

        if (k == "int")         return solveInt(node, type);
        if (k == "real")        return solveNum(node, type);
        if (k == "str")         return solveStr(node);
        if (k == "char")        return solveChar(node);
        if (k == "bool")        return createBool(:node.value);

        if (k == "definit")     return solveDefinit(type);

        if (k == "import")      return solveImport(node);
        if (k == "defer")       return solveDefer(node);
        if (k == "try")         return solveTryCatch(node);

        if (k == "typedef")     return solveTypedef(node);
        if (k == "typecast")    return solveTypeCast(node);
        if (k == "typeassert")  return solveTypeAssert(node);
        if (k == "typeparam")   return solveTypeParam(node);
        if (k == "addroffn")    return solveAddrOfFn(node);

        // Exotics.
        if (k == "forfieldsof") return solveForFieldsOf(node);
        if (k == "pragma")      return executeCompilerPragma(node);
        if (k == "void")        return createEmpty();

        if (unorderedClassify(k))
            return solveDeclExpr(node);

        //
        return fail("TODO: solveNode(" ~ k ~ ").");
    }

    fn solveDeclExpr(node: Node): SolvedNode
    {
        return solveNodes([ node ]).only;
    }

    fn unorderedClassify(kind: string): i32
    {
        if (kind == "fn")
            return 1;

        if (kind == "struct" || kind == "primitive" || kind == "enum" || kind == "flags")
            return 10;

        return 0;
    }

    fn unorderedPrep_A(node: Node): SolvedNode
    {
        let kind = node.kind;

        if (kind == "fn")
            return uPrepFn_A(node);

        if (kind == "struct" || kind == "primitive" || kind == "enum" || kind == "flags")
            return uPrepStruct(node);

        BUG("TODO: unorderedPrep_A(" ~ node.kind ~ ").");
    }

    fn unorderedPrep_B(node: Node, into: Target)
    {
        let k = node.kind;
        if (k == "fn")
            uPrepFn_B(into);
    }


    //

    fn _current_fn_eachArg_BACK(visit)
    {
        let sig = _current_fn.items;
        for (mut i = sig.len + FN_ARGS_BACK; i --> 0; )
        {
            let t = sig[i].target;
            if (t && t.flags & F_ARG)
                visit(t);
        }
    }

    fn _current_fn_eachArg_FWD(visit)
    {
        let sig = _current_fn.items;
        for (mut i = 0; i < sig.len + FN_ARGS_BACK; i++)
        {
            let t = sig[i].target;
            if (t && t.flags & F_ARG)
                visit(t, position?: i);
        }
    }

    fn propagateType(ref node: SolvedNode, slot: Type, relax_mask!: i32)
    {
        let k = node.kind;

        // Shortcutting lets, they source the slot from usage.
        if (k == "let" || k == "letdef")
        {
            // Addrofn & co.
            if (!node.target)
                return;

            return relaxBlockVar(node.target, :relax_mask);
        }

        ////////////////////////////
        let here0   = _here;
        _here       = node.token;
        defer _here = here0;
        ////////////////////////////

        //
        node.type.try_relax(:slot, :relax_mask);
        shadow let slot = node.type;

        //
        let LAST = node.items.len - 1;

        // Logic.
        if (k == "and")
        {
            let rest    = slot.is_mutref && CANNOT_definit_mutrefs
                        ? slot
                        : t_bool;

            for (mut i = node.items.len; i --> 0; )
                propagateType(node.items[i], :relax_mask,
                    i == LAST ? slot : rest);
        }
        else if (k == "or")
        {
            for (mut i = node.items.len; i --> 0; )
                propagateType(node.items[i], :relax_mask,
                    :slot);
        }
        else if (k == "if")
        {
            for (mut i = node.items.len; i --> 0; )
                propagateType(node.items[i], :relax_mask,
                    i != 0 ? slot : t_bool);
        }

        //
        else if (k == "call")
        {
            let t = node.target;
            if (t.kind == "field")
                return node.items.only.propagateType(slot, :relax_mask);

            if (t.kind == "var")
            {
                // This is the old relaxBlockVars callsite loop -
                //  Now we just collect usage while propagating types,
                //   this means we're automatically ignoring type annotations etc.
                //
                if (t.isNested)
                {
                    ref usage = _current_fn.var_usage.grow_if_oob(t.index);

                    if (!usage)
                        usage = slot;
                    else
                        usage = type_tryIntersect(usage, slot) || fail(
                            t.qWHAT ~ ": Usage intersection failure: `"
                                    ~ humanizeType(usage) ~ "` & `" ~ humanizeType(slot) ~ "`.");
                }

                return;
            }

            if (t.spec_of && t.type.is_ref)
            {
                // Template spec relaxer, this is nasty.
                //  Not sure what the ideal method to deal with this here would be,
                //   we're basically just going back and redoing things,
                //    and we don't have the original shit to work with.
                //
                mut relaxed: SolvedNode[];
                for (mut i = 0; i < node.items.len; i++)
                {
                    let orig = node.items[i];

                    // We'll only attempt to relax arguments whose lifetimes appear in the return value.
                    //  There's this other thing, perhaps we only need to relax a single such argument?
                    //
                    if (t.type.lifetime.uni0n.has(Region_fromArgPosition(i)))
                    {
                        mut type = orig.type;
                        if (type.try_relax(:slot, :relax_mask))
                        {
                            if (!relaxed)
                                relaxed = node.items.slice(0, i);

                            relaxed ~= SolvedNode("__relaxed", :type);
                            continue;
                        }
                    }

                    if (relaxed)
                        relaxed ~= orig;
                }

                if (relaxed)
                {
                    mut args_mangled: string;
                    let spec = trySpecialize(
                        t.spec_of, args: relaxed, :args_mangled, REST_START: relaxed.len);

                    if (!spec.is_SPECFAIL && !(spec == t))
                    {
                        checkAssignable(host: node.type, spec.type,
                            "Relaxed specialization does not return a subtype");

                        //////////////////////////
                        // TODO rewire callsite //
                        //////////////////////////

                        if (node.type.is_ref)
                            node.type.lifetime = Lifetime_test(
                                Lifetime_replaceArgsAtCallsite(spec, relaxed),
                                tempsOK: true);

                        node.target = spec;
                        makeNote(N_RelaxRespec);
                    }
                }
            }

            // Relax arguments.
            if (node.items)
            {
                let host_args   = node.target.args;
                let rtl         = node.target.isRTL;

                // Here we're visiting stuff in reverse order of execution -
                //  so RTL means visit left to right and vice versa, watch it.
                let N           = node.items.len;

                let start       = rtl ? 0 : N - 1;
                let end         = rtl ? N : 0 - 1;
                let incr        = rtl ? +1  :  -1;

                for (mut i = start; i != end; i += incr)
                    node.items[i].propagateType(host_args[i].type, :relax_mask);
            }
        }
        else if (k == "int" || k == "real" || k == "char" || k == "str" || k == "definit" || k == "bool")
        {
            //////////////
            // Nothing! //
            //////////////
        }
        else if (k == "typeparam" || k == "empty" || k == "fndef")
        {
            /////////////////////////
            // What do we do here? //
            /////////////////////////
        }
        else if (k == "copy" || k == "move")
        {
            propagateType(node.items.only, :relax_mask,
                slot: k == "copy"
                    ? make_copyable(slot)
                    : slot);

            node.items.only.is_ref || fail(
                "TODO: Relaxed a copy/move to a value, no point in keeping the outer node.");
        }
        else if (k == "arrlit")
        {
            let itemSlot = clear_sliceable(slot);

            for (mut i = 0; i < node.items.len; i++)
                propagateType(node.items[i], :relax_mask,
                    slot: itemSlot);
        }
        else if (k == "argid")
        {
            propagateType(node.items.only, :relax_mask, :slot);
        }
        else if (k == "jump")
        {
            let h = node.helpers;

            h.ret_actual || fail(
                "propagateType(jump): h.ret_actual not available.");

            propagateType(node.items.only, :relax_mask, h.ret_actual);
        }
        else if (k == "block")
        {
            let h = node.helpers;

            h.ret_actual.try_relax(:slot, :relax_mask);

            //
            mut isLast = true;
            for (mut i = node.items.len; i --> 0; )
            {
                shadow ref node = node.items[i];

                // Removing propagateType(defer) and handling here:
                //  this validates we don't get stray defers outside of blocks.
                shadow ref node = node.kind == "defer"
                    ? node.items.only
                    : node;

                propagateType(node, :relax_mask,
                    isLast ? { isLast = false; slot } : t_void);
            }

            // TODO FIX args need extra iteration here.
            if (h.target == _current_fn.target)
                _current_fn_eachArg_BACK: |t|
                    relaxBlockVar(t, :relax_mask);
        }
        else if (k == "loop")
        {
            fn init         = node.items[LOOP_INIT];
            fn pre_cond     = node.items[LOOP_COND];
            fn body         = node.items[LOOP_BODY];
            fn post_cond    = node.items[LOOP_POST_COND];
            fn post         = node.items[LOOP_POST];

            // Relax in reverse.
            if (post)       propagateType(post, t_void, :relax_mask);
            if (post_cond)  propagateType(post_cond, t_bool, :relax_mask);
            if (body)       propagateType(body, t_void, :relax_mask);
            if (pre_cond)   propagateType(pre_cond, t_bool, :relax_mask);
            if (init)       propagateType(init, t_void, :relax_mask);
        }
        else if (k == "try")
        {
            fn attempt      = node.items[0]; // TODO FIX the laxness due to rec solve
            fn error        = node.items[1]; // TODO FIX the laxness due to rec solve
            fn recover      = node.items[2];

            // Relax in reverse.
            propagateType(recover, t_void, :relax_mask);
            propagateType(error, t_string, :relax_mask);
            propagateType(attempt, t_void, :relax_mask);
        }
        else if (k == "root")
        {
            // Tries to relax global lets (there's nothing else to relax globally).
            //  Three problems with that:
            //
            //   - F_PUBS can't be relaxed.
            //
            //   - callsites contain garbage from resolved fns:
            //     - generally I think we should get rid of persistant callsites, just keep them around during fnsolve;
            //     - which will work automatically if we injected globals as args but that's crazy;
            //     - perhaps we should just keep a list of globals used which propagates up the solvestack.
            //
            //   - finally there's the problem with F_PUB templates:
            //     - they can see private stuff from module scope, so can't relax those either.
            //
            // propagateType(node.items, t_void, :relax_mask);
        }
        else if (k == "pragma")
        {
            // Noop - but do track variable use
            //  so we don't emit warnings
            //   and so we don't overrelax.
            //
            for (mut i = 0; i < node.items.len; i++)
                node.items[i].propagateType(node.items[i].type, :relax_mask);
        }
        else
        {
            fail("TODO: propagateType(" ~ k ~ ").");
        }
    }


    //

    fn solved(
        node: Node, type: Type, items: SolvedNode[] = [], target = Target)
            : SolvedNode
    {
        return SolvedNode(
            kind:  node.kind ,
            flags: node.flags,
            value: node.value,

            :items, :type, :target);
    }

    fn solveRoot(node: Node): SolvedNode
    {
        // Root vars & such.
        push(HelpersData());

        //
        let items = solveNodes(node.items, t_void);
        if (!items.last.is_never)
        {
            mut root = solved(node, t_void, items);
            runAllPasses(root);
            return root;
        }

        //
        _here = items.last.token;
        fail("Noreturn during static init: this program will never finish booting.");
    }

    fn solveBlock(node: Node, type!: Type, fnbody_of!?: i32, mask! = HM_CanBreak, kills!?: i32, id!?: string, locals_start!?: i32): SolvedNode
    {
        let nodes = node.kind == "block"  ? node.items : [ node ];
        shadow let id = id || node.kind == "block" && node.value;

        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        let helpers_idx = _helpers.len;
        push(HelpersData( :id, :mask, :kills,
            ret_expect:     type,
            target:         fnbody_of && Target(:module.modid, fnbody_of),
            local_of:       fnbody_of ? fnbody_of : _current_fn.target.index,
            locals_start:   fnbody_of ? +1 : locals_start || GET_next_local_index()));

        let expr        = !fnbody_of && !type.is_void;
        let items       = solveNodes(
            nodes,
            type_all:           t_void,
            type_last:          type,
            use_type_last:      expr,

            // Kills is +1 so that kills=0 means noone.
            kills: helpers_idx + 1);

        return solveBlock(:items, :helpers_idx, :expr, :mask, :fnbody_of);
    }

    fn solveBlock(items: SolvedNode[], helpers_idx!: i32, expr!: bool, mask!: i16, fnbody_of!: i32)
    {
        let h = _helpers[helpers_idx];

        // TODO clean this up, non-return ret-expects
        if !(mask & HM_CanReturn)
            h.ret_expect = [];

        // Block tail expressions.
        if (expr && items && !items.last.is_never)
                          /////////////////////// we dont seem to be hitting this check at all
                          ///////////////////////
        {
            // Pretend this is a jump, the jump node itself is never used
            //  but we just go through the stuff below
            //   to make it look like a regular return.
            //
            createJump(items.last, :h);
        }

        // This will work ideally in a reverse pass,
        //  going through all blocks in reverse and relaxing their returns.
        {
            // TODO FIX this looks like bullshit,
            //  there's gotta be a better way to do this.
            if (items.if_last.type.is_never)
            {
                if (!h.ret_actual)
                    reportReturnType(:h, t_never);
            }
            else if (fnbody_of)
            {
                // TODO FIX these apply to regular blocks as well,
                //  decide if you want fns to be like blocks or the other way round,
                //   but these ifs gotta go.
                if (h.ret_actual)
                    isAssignable(host: t_void, h.ret_actual) || fail(
                        "Non-void returning fn missing a final return.");
            }

            if (!h.ret_actual)
                reportReturnType(:h, t_void);
        }


        //

        mut block = createBlock(:items,
            type: h.ret_actual || BUG(),
            :h);

        if (fnbody_of)
        {
            // Don't run further passes if dirty -
            //  some of our AST might be broken,
            //   invalidated callsites and such,
            //    just finish up asap.
            //
            let status = Target(:module.modid, fnbody_of).status;
            if (!(status & SS_DIRTY) && !currentFn_mustBecomeInline())
                runAllPasses(block);
        }

        return block;
    }

    fn currentFn_mustBecomeInline()
    {
        return _current_fn.effects.far_jumps.len > 0 && "Contains non-local control flow.";
    }

    fn warn(token: TokenIdx, inline message: string)
    {
        _warnings.grow_if_oob(_current_fn.target.index) ||= Warning(:token, :message);
    }

    fn relaxBlockVar(t: Target, relax_mask!: i32)
    {
        let var = GET(t);

        //
        let usage = _current_fn.var_usage.unless_oob(t.index);
        if (!usage && relax_mask == RELAX_all)
        {
            if !(var.flags & F_LAX)
                warn(:t.solved.token, "Unused variable: " ~ var.name.qBAD ~ ": make it " ~ "lax".qKW ~ " if this is intentional.");

            GET_mut(t).flags |= F_UNUSED;
        }

        ref o = GET_mut(t);

        //////////////////////////////////////////////
        // TODO one of these two is redundant       //
        o.type.try_relax(slot: usage, :relax_mask); //
        //////////////////////////////////////////////

        // Either way, try to relax.

        {
            ref node = o.solved;

            node.type || BUG("relaxBlockVar: !var.solved.type, can`t propagateType");
            node.type.try_relax(slot: usage, :relax_mask);

            // Steal init expression for processing.
            if (node.items && node.items[LET_INIT])
            {
                mut init: SolvedNode;
                swap(init, node.items[LET_INIT]);

                init.propagateType(node.type, :relax_mask);

                shadow ref o    = GET_mut(t);
                shadow ref node = o.solved;

                // TODO FIX Codegen helper, this is for the `fu_STR& src = sources[i]` case.
                //  Ideally we should do without this, otherwise we can rerun the solveLet crap.
                if (node.type.is_ref && !(node.flags & F_ARG))
                    node.type.lifetime = init.type.lifetime;

                // Done, put it back.
                swap(init, node.items[LET_INIT]);
            }
        }

        // Lose the F_MUT annots on values that don't need them.
        shadow ref o = GET_mut(t);
        if (o.flags & F_MUT)
        {
            if (usage.is_mutref)
            {
                ref node = GET_mut(t).solved;
                let type = clear_refs(node.type);
                node.type = type;
            }
            else
            {
                o.flags &= ~F_MUT;
            }
        }

        // Decide on relaxable refs.
        shadow ref o = GET_mut(t);
        if (o.flags & F_RELAXABLE_REF)
        {
            let strip = F_RELAXABLE_REF | (!usage.is_mutref && F_REF);

            o.flags             &= ~strip;
            o.solved.flags      &= ~strip;
        }
    }

    fn createBlock(
        type: Type, mut items: SolvedNode[], h?: Helpers): SolvedNode
    {
        // TODO INVESTIGATE potential gcc bug
        //
        //  Replace the `fail` here with a throw and the !kind bug on gcc stops to repro.
        //   It's outright bizarre.
        //
        //  Happens for "inline"s, if the check is lifted in the outer fun it also doesn't repro.
        //   Potentially we want to try this out with another gcc version or something,
        //    its very, very fishy, and is only apparent in optimized builds.

        // Also notice with this here,
        //  there's barely any difference between the two things in cg output, all args are the same.
        for (mut x = 0; x < items.len; x++)
            if (!items[x].kind)
                throw("createBlock.before-flatten.items: no kind on item #" ~ x);

        if (_here && _helpers.len > 10000001)
        {
            // Comment out this line and gcc breaks under opti,
            //  something is getting reordered or otherwise broken,
            //   it's a heizenbug.
            //
            // I guess next part of the research is to
            //  start toggling optimization options one by one,
            //   I need to do this efficiently somehow.
            //
            throw("woot: " ~ _helpers.len);
        }

        //////////////////////////////////////////////////////////////////////
        //////////////////////////////////////////////////////////////////////
        if (OPTI_flatten_blocks) while (items.len)
        {
            let tail = items.last;
            if (tail.kind != "block" || tail.helpers && tail.helpers.mask & HM_LabelUsed)
                break;

            let unwrap = tail.items;
            items.pop();
            items ~= unwrap;
        }
        //////////////////////////////////////////////////////////////////////
        //////////////////////////////////////////////////////////////////////

        // Compact + stress test.
        for (mut i = items.len - 1; i --> 0; )
        {
            let k = items[i].kind;
            if (k == "empty" || k == "bool")
                items.splice(i, 1);
        }

        if (!(h.mask & (HM_LabelUsed | HM_KeepBlock)) && items.len == 1)
            return items.only;

        //
        return SolvedNode(
            kind: "block", :type, :items,
            helpers: h);
    }


    //

    fn solveInt(v: string, type: Type): Type
    {
        shadow let parse = intlit::Intlit(v);
        parse.error && fail(parse.error);

        if (type)
        {
            fn want(t: Type)
                type.canon == t.canon;

            if (!parse.unsigned)
            {
                if (want(t_f32) && parse.minsize_f <= 32) return t_f32;
                if (want(t_f64) && parse.minsize_f <= 64) return t_f64;

                if (want(t_i32) && parse.minsize_i <= 32) return t_i32;
                if (want(t_i64) && parse.minsize_i <= 64) return t_i64;
                if (want(t_i16) && parse.minsize_i <= 16) return t_i16;
                if (want(t_i8 ) && parse.minsize_i <= 8 ) return t_i8 ;
            }

            if (!parse.signed)
            {
                if (want(t_u32) && parse.minsize_u <= 32) return t_u32;
                if (want(t_u64) && parse.minsize_u <= 64) return t_u64;
                if (want(t_u16) && parse.minsize_u <= 16) return t_u16;
                if (want(t_u8 ) && parse.minsize_u <= 8 ) return t_u8 ;
            }
        }

        if (parse.unsigned)
        {
            if (parse.minsize_u <= 32) return t_u32;
            if (parse.minsize_u <= 64) return t_u64;
        }
        else
        {
            if (parse.minsize_i <= 32) return t_i32;
            if (parse.minsize_i <= 64) return t_i64;
        }

        return fail("Bad int literal.");
    }

    fn solveNum(v: string, type: Type): Type
    {
        // TODO `f` suffix
        if (v) {}

        if (type.canon == t_f32.canon) return t_f32;

        return t_f64;
    }


    //

    fn solveInt(node: Node, type: Type): SolvedNode
        solved(node,
             solveInt(node.value, type));

    fn solveNum(node: Node, type: Type): SolvedNode
        solved(node,
             solveNum(node.value, type));


    //

    fn solveChar(node: Node): SolvedNode
    {
        return solved(node, t_byte);
    }

    fn solveStr(node: Node): SolvedNode
    {
        if (!node.value)
            return createDefinit(
                add_ref(t_string, Lifetime_temporary));

        return solved(node, t_string);
    }

    fn createEmpty(kind = "empty", type = t_void, target?: Target): SolvedNode
    {
        return SolvedNode(:kind, :type, :target);
    }

    fn executeCompilerPragma(node: Node)
    {
        if (node.value != "break")
            return SolvedNode("pragma", :node.value,
                items: solveNodes(node.items), type: t_void);

        compilerBreak();
        return createEmpty();
    }


    //

    fn createBool(value: bool): SolvedNode
    {
        return createBool(value ? "true" : "false");
    }

    fn createBool(value: string, type = t_bool): SolvedNode
    {
        value == "true" || value == "false" || BUG();
        return SolvedNode(kind: "bool", :value, :type);
    }


    //

    fn createTypeParam(value: string): Node
    {
        return Node(kind: "typeparam",
            :value, token: _here || BUG());
    }

    fn X_addrofTarget(target: Target)
    {
        return Type(ValueType(quals: 0, canon: packAddrOfFn([ target ])));
    }


    //

    fn CompoundArgID_outerSplice(ref name: string): string
    {
        mut exclam = false;

        for (mut i = 0; i < name.len; i++)
        {
            let c = name[i];

            // Strip internal argument name.
            if (c == '!')
            {
                exclam && BUG("CompoundArgID: double bang in `" ~ name ~ "`.");
                exclam = true;

                let i0 = i++;
                for ( ; i < name.len; i++)
                    if (name[i] == '.')
                        break;

                name.splice(i0, i - i0);
                i = i0 - 1;
                continue;
            }

            // Extract autocall expression.
            if (c == '.')
            {
                let ret = name.slice(i + 1);
                name.shrink(i);
                return ret;
            }
        }

        if (!exclam)
            BUG("CompoundArgID: no `.` nor `!` in id `" ~ name ~ "`.");

        return [];
    }

    fn uPrepFn_A(node: Node): SolvedNode
    {
        let id          = node.value;
        let local_of    = _current_fn.target.index;
        let status      = SS_LAZY; // Actual template fns are eager.

        let target      = Scope_create(_scope,
            kind: "fn", name: "__prep__",
            :node.flags, :status);

        ref ext         = target.EXT_mut;
        ext.local_of    = local_of;

        ext.template    = createTemplate(node);
        ext.min         = 0x7fffffff.i32;
        ext.max         = 0;

        mut shadows     = !!(node.flags & F_SHADOW);
        autoshadow(:shadows, :local_of, :id);

        Scope_set(_scope, :target, :id, :shadows);

        // Experimental conversion functions.
        if (node.flags & F_CONVERSION)
            _scope.converts.push(target);

        return createFnDef(:target, type: X_addrofTarget(target));
    }

    fn uPrepFn_B(target: Target)
    {
        ref template = target.EXT_mut.template;
        if (template.scope_memo)
            template.scope_memo = Scope_snap(_scope);
    }

    fn createFnDef(type: Type, target: Target): SolvedNode
    {
        return SolvedNode(kind: "fndef", :type, :target);
    }


    //

    fn mangleArguments(args: [$T]): string
    {
        mut mangle = "";
        for (mut i = 0; i < args.len; i++)
        {
            if (i)
                mangle ~= ",";

            mangle ~= serializeType(args[i], debug: "mangle[$T]");
        }

        return mangle;
    }

    fn mangleArguments(
        args: [SolvedNode], reorder: [i32],
        use_reorder: bool, conversions: Target[][],
        REST_START: i32, REST_TYPE: Type): string
    {
        mut mangle = "";

        let REST_END = use_reorder ? reorder.len : args.len;
        let N = REST_END.min(REST_START);
        for (mut i = 0; i < N; i++)
        {
            if (i)
                mangle ~= ",";

            let callsiteIndex = use_reorder ? reorder[i] : i;

            if (conversions.len > i && conversions[i].len)
                mangle ~= serializeType(
                    GET(conversions[i].last).type, debug: "mangle.conv");

            else if (callsiteIndex >= 0 && callsiteIndex <= args.len)
                mangle ~= serializeType(
                    args[callsiteIndex].type, debug: "mangle.no-conv");
        }

        if (REST_START < REST_END)
        {
            if (REST_START)
                mangle ~= ",";

            mangle ~= serializeType(REST_TYPE, debug: "mangle[Nodes].rest");
        }

        return mangle;
    }


    //

    fn is_SPECFAIL(target: Target): bool
    {
        return target.modid == 2147483647;
    }

    fn trySpecialize(
        overloadIdx: Target, args: SolvedNode[], ref args_mangled: string,
        REST_START: i32, REST_TYPE?: Type,
        reorder?: [i32], use_reorder?: bool, conversions?: Target[][])
            : Target
    {
        args_mangled ||= mangleArguments(
                :args, :reorder, :use_reorder, :conversions,
                :REST_START, :REST_TYPE);

        // TODO memoize the whole mangle.
        //  Or use a hash here, perhaps nest them per template or smth.
        //   Also this prefix is nasty, unless we can reuse between modules.
        //
        // TODO perhaps reuse between modules?
        //  Would make the prefix stuff more meaningful.
        //
        let mangle = overloadIdx.modid ~ "#" ~ overloadIdx.index ~ " " ~ args_mangled;
        return _specs.map::get(mangle) || doTrySpecialize(
            :overloadIdx, args_in:args, :mangle,
            :reorder, :use_reorder, :conversions,
            :REST_START, :REST_TYPE)
                || BUG("doTrySpecialize returns empty target.");
    }


    //

    fn ScopeSkip_push(ref scope_skip: ScopeSkip[], start: i32, end: i32)
    {
        start <= end || BUG("ScopeSkip_push: bad args.");
        if (end == start)
            return;

        let last = scope_skip.if_last;
        last.end <= start || BUG("ScopeSkip_push: last.end > start.");

        // Opti - don't grow if possible, so we stay in small storage.
        if (scope_skip && last.end == start)
            scope_skip.last.end = end;
        else
            scope_skip ~= ScopeSkip(:start, :end);
    }

    fn ScopeSkip_setup(template: Template, scope0: ScopeMemo, isInline!?: bool)
    {
        if (_root_scope)
        {
            let start = template.scope_memo || _root_scope;
            _ss = template.scope_skip;

            ScopeSkip_push(_ss.items,       start: start.items_len,     end: scope0.items_len);

            ScopeSkip_push(_ss.implicits,

                // Not sure about this, the whole thing is a mess -
                //  not sure what's happening here and why this is needed,
                //   but it helps with the qSTACK/updateScope testcase thing.
                start: isInline && start.implicits_len > _current_fn.scope0.implicits_len
                    ? _current_fn.scope0.implicits_len
                    : start.implicits_len,

                end: isInline
                    ? _current_fn.scope0.implicits_len
                    :             scope0.implicits_len);

            ScopeSkip_push(_ss.imports,     start: start.imports_len,   end: scope0.imports_len);
            ScopeSkip_push(_ss.privates,    start: start.privates_len,  end: scope0.privates_len);
            ScopeSkip_push(_ss.usings,      start: start.usings_len,    end: scope0.usings_len);
            ScopeSkip_push(_ss.converts,    start: start.converts_len,  end: scope0.converts_len);
            ScopeSkip_push(_ss.helpers,     start: start.helpers_len,   end: scope0.helpers_len);
        }

        // We'll need the original imports in scope
        //  in order to solve type params & pattern match below.
        for (mut i = 0; i < template.imports.len; i++)
        {
            Scope_import(template.imports[i]);
            if (i == 0)
                Scope_import_privates(template.imports[i]);
        }
    }


    //

    fn doTrySpecialize(
        into?: Target,
        overloadIdx?: Target, args_in?: SolvedNode[],
        mut mangle?: string, reorder?: [i32], use_reorder?: bool, conversions?: Target[][],
        REST_START?: i32, REST_TYPE?: Type)
            : Target
    {
        mut args: Type[];
        if (use_reorder)
        {
            for (mut i = 0; i < reorder.len; i++)
            {
                let callsiteIndex = reorder[i];
                args.push(
                    callsiteIndex >= 0 && callsiteIndex < args_in.len
                        && args_in[callsiteIndex].type);
            }
        }
        else
        {
            for (mut i = 0; i < args_in.len; i++)
                args.push(args_in[i].type);
        }

        for (mut i = 0; i < conversions.len; i++)
        {
            let c = conversions[i];
            if (c)
                args[i] = GET(c.last).type;
        }

        if (REST_TYPE)
            args[REST_START] = REST_TYPE;

        //
        let SPECFAIL_RentrySafety =
            Target(modid: 2147483647, index: 0);

        //
        let mangle00 = mangle;

        //
        let original = overloadIdx || into || BUG();
        mut template = original.template;

        ////////////////////
        let here0   = _here;
        defer _here = here0;
        _here       = original.template.node.token;
        ////////////////////

        mut parent_idx = original.local_of;
        {
            // If we're taking a closure as an argument,
            //  we're becoming a closure ourselves of whatever that closure is closing over -
            //   so that e.g. lifetime reasoning can have an easier time etc.
            //
            // TODO all of these must form up a common shadowing group -
            //  So nothing by the same name should come in from outer scope,
            //   and yet none of these things shadow each other.
            //
            for (mut i = 0; i < args.len; i++)
            {
                let arg_t = args[i];
                if (type_isAddrOfFn(arg_t))
                {
                    unpackAddrOfFn(arg_t.canon, |target|
                    {
                        if (target.modid < 0 || target.modid == module.modid)
                        {
                            let local_of = target.localOf;
                            if (parent_idx < local_of)
                                parent_idx = local_of;
                        }
                    });
                }
            }
        }

        //
        let isInline = !!(template.node.flags & F_INLINE);

        fn setSpec(shadow mangle: string, target: Target, nx?: bool)
        {
            isInline && BUG("inline.setSpec");

            ref t = _specs.map::ref(mangle);

            fn id(shadow target)
                target.is_SPECFAIL  ? "SPEC_FAIL"
                                    : "`" ~ GET(target).name ~ "`";

            !t && nx || t.is_SPECFAIL && !nx || BUG(
                "About to screw up royally, replacing spec: "
                    ~ t.index ~ " with " ~ target.index
                        ~ ", mangle: " ~ mangle ~ ", that's: "
                        ~ t.id ~ " becoming " ~ target.id);

            t = target;
        }

        if (!into && !isInline)
            setSpec(mangle, SPECFAIL_RentrySafety, nx: true);

        // Scopes & scope skips.
        mut target: Target;

        {
            let scope0 = Scope_snap(_scope);
            let ss0 = _ss;
            let helpers_data0 = _helpers_data.len;

            defer {
                Scope_pop(_scope, scope0);
                _ss = ss0;

                _helpers_data.shrink(helpers_data0);
            }

            ScopeSkip_setup(:template, :scope0);

            //
            let items = template.node.items;
            ref n_fn = template.node;
            n_fn.kind == "fn" || BUG("n_fn not a `fn`.");

            // println("  doTrySpec " ~ n_fn.value);

            //
            mut error = "";
            mut remangle = false;
            mut typeParams: TypeParams;

            fn isNativeBody(n_body: Node)
                n_body.kind == "call" && n_body.value == "__native";

            if (!into)
            {
                let kind    = template.node.kind;
                let numArgs = kind == "fn" ? items.len + FN_ARGS_BACK
                            : fail("TODO numArgs for template:" ~ kind);

                /////////////////
                // Literal fixup.
                mut retypeIndices: i32[];

                // First off, solve type params.
                for (   mut pass_retype  = 0;
                            pass_retype == 0 || pass_retype == 1 && retypeIndices;
                            pass_retype++)
                {
                //        /LITFIX
                /////////////////

                    for (mut i = 0; i < numArgs; i++)
                    {
                        if (pass_retype)
                        {
                            // TODO fix, .try_shift instead.
                            if (!retypeIndices.has(i))
                                continue;
                        }

                        mut inType  = args.len > i && args[i];
                        let inValue = reorder
                            ? reorder.len > i && reorder[i] >= 0 && args_in[reorder[i]]
                            : args_in.len > i && args_in[i];

                        let argNode = items[i] || BUG();
                        let annot   = argNode.items[LET_TYPE];

                        // Use previously solved argument defaults
                        //  to let all type params solve normally.
                        let host_arg = original.args[i];

                        shadow let inValue = inValue || {
                            inType = host_arg.default.type;
                            host_arg.default
                        };

                        /////////////////
                        // Literal fixup.
                        if (couldRetype(inValue))
                        {
                            let paramType =
                                annot.kind == "typeparam"
                                    ? typeParams.map::ref(annot.value).matched
                                    : annot.kind == "call" && !annot.items
                                        && Scope_lookupType(annot);

                            // Ignore literals if possible.
                            if (paramType)
                            {
                                let retype = tryRetyping(inValue, paramType);
                                if (retype && retype.canon != inType.canon)
                                {
                                    inType = retype;
                                    if (args.len > i)
                                        args[i] = inType;

                                    remangle = true;
                                }
                            }

                            // Defer for second pass.
                            else if (!pass_retype)
                            {
                                retypeIndices.push(i);
                                continue;
                            }
                        }
                        //        /LITFIX
                        /////////////////

                        argNode.kind == "let"  || BUG();

                        //
                        if (inType)
                        {
                            // Enable conversions on fully typed arguments.
                            let exactType = host_arg.type;
                            if (exactType)
                            {
                                if (args.len > i)
                                    args[i] = exactType;

                                continue;
                            }

                            //
                            let argName = argNode.value || BUG();

                            // Same pattern - grabs a mutref.
                            ref argName_typeParam = typeParams.map::ref(argName);

                            // Values vs refs.
                            inType = add_ref(inType, Lifetime_temporary);

                            //
                            (argName_typeParam && fail(
                                "Type param name collision with argument " ~ argName.qID ~ "."))
                                    .matched = inType;

                            // Type check.
                            if (annot)
                            {
                                let argOk = trySolveTypeParams(annot, inType, typeParams);

                                if (!error && !argOk)
                                    error = "Cannot solve argument " ~ argName.qID ~ " pattern for " ~ humanizeType(inType);

                                if (error && !remangle)
                                    break;
                            }
                        }
                    }
                }

                /////////////////
                // Literal fixup.
                if (remangle && !isInline)
                {
                    // TODO FIX
                    let start = mangle.find(' ') + 1 || BUG();
                    mangle = mangle.slice(0, start) ~ mangleArguments(args);

                    if (mangle00 != mangle)
                    {
                        let preexisting = _specs.map::get(mangle);
                        if (preexisting)
                        {
                            setSpec(mangle00, preexisting);
                            return preexisting;
                        }

                        if (!into)
                            setSpec(mangle, SPECFAIL_RentrySafety, nx: true);
                    }
                }
                //        /LITFIX
                /////////////////

                fn SPECFAIL(reason: string)
                {
                    let index       = _spec_errors.len;
                    _spec_errors   ~= reason;

                    let spec        = Target(
                        modid: SPECFAIL_RentrySafety.modid, :index);

                    setSpec(mangle00, spec);
                    setSpec(mangle,   spec);

                    return spec;
                }

                // Match pattern arm here.
                if (error)
                    return SPECFAIL(error);

                // Pattern matching.
                let body = items[items.len + FN_BODY_BACK] || BUG();
                if (body.kind == "pattern")
                {
                    let undo = typeParams;
                    let branches = body.items;

                    mut did_match = false;
                    for (mut i = 0; i < branches.len; i++)
                    {
                        // Fails cond if any?
                        let cond = branches[i].items[0];
                        if (cond && !evalTypePattern(cond, typeParams))
                        {
                            typeParams = undo;
                            continue;
                        }

                        // Pass.
                        let cons = branches[i].items;
                        ref sig = n_fn.items;
                        {
                            let n_ret = cons[cons.len + FN_RET_BACK];
                            if (n_ret) sig[sig.len + FN_RET_BACK] = n_ret;

                            let n_body = cons[cons.len + FN_BODY_BACK];
                            sig[sig.len + FN_BODY_BACK] = n_body || BUG("doTrySpec: no case/body.");
                        }

                        did_match = true;
                        break;
                    }

                    // All branches mismatch?
                    //  Can't return, faking RAII here.
                    if (!did_match)
                        return SPECFAIL("No body pattern matched.");
                }

                // Native relaxer.
                //  We can't reason about the code of "native" fns,
                //   so we relax based on type assertions here.
                //
                let n_body = n_fn.items[n_fn.items.len + FN_BODY_BACK];
                if (n_body.isNativeBody)
                {
                    for (shadow mut i = 0; i < numArgs; i++)
                    {
                        let argNode = items[i] || BUG();
                        let id = argNode.value;

                        typeParams.map::if_ref(id): |tp|
                            tp.matched = tp.consumed // TODO failcase: || BUG("nope, aint gonna work");
                    }
                }
            }

            // Populate scope.
            let mangle0 = mangle;

            // Prep reject.
            target = into || Scope_create(_scope, status: SS_DID_START | SS_LAZY);
            target.EXT_mut.local_of = parent_idx;

            //
            let extra_items = into
                ? original.extra_items
                : (target.EXT_mut.extra_items = typeParams.intoScopeItems());

            /////////////////////////////////////
            // Reset anon counters //////////////
            if (!_current_fn_or_type) _anons = 0;
            /////////////////////////////////////

            //////////////////////////////////////////////////
            let current_fn_or_type0     = _current_fn_or_type;
            defer _current_fn_or_type   = current_fn_or_type0;
            _current_fn_or_type         = target;
            //////////////////////////////////////////////////
            let implicit _current_fnort = target;
            //////////////////////////////////////////////////

            // Go!
            {
                ref o = EXT_mut(target);

                if (o.revision++ > 0)
                {
                    o.locals.clear();

                    // This looks horrible but hope is
                    //  warnings array should be usually empty,
                    //   otherwise we'll likely emit an error on solved.
                    if (_warnings.len > target.index)
                        _warnings[target.index] = Warning();
                }
            }

            /////////////////////////////////////////////////////////////////////
            let TODO_FIX_convert_args0  = TODO_FIX_convert_args;
            TODO_FIX_convert_args[0]    = SolvedNode(kind: "__convert", type: Type());
            defer TODO_FIX_convert_args = TODO_FIX_convert_args0;
            /////////////////////////////////////////////////////////////////////

            mut out = CurrentFn(:scope0,
                solved(n_fn,
                    :target, type: X_addrofTarget(target)));

            let root_scope0 = _root_scope;
            if (!root_scope0)
                _root_scope = scope0;

            swap(_current_fn, out);

            defer {
                swap(_current_fn, out);
                _root_scope = root_scope0;
            }

            /////////////////////////////////
            fn outItems() _current_fn.items;

            let inItems = n_fn.items;
            outItems.resize(inItems.len);

            // Arg decls.
            _scope.items ~= extra_items;

            let isFirst     = !target.solved;
            let isTemplate  = template.node.flags & F_TEMPLATE;
            let isSpec      = isTemplate && (!into || !isFirst); // TODO FIX this looks really flaky
            let isUnspec    = isTemplate && !isSpec;

            let isPure      = template.node.flags & F_PURE;
            let isNovec     = template.node.flags & F_NOVEC;
            let isPureCtx   = template.node.flags & F_PURE_CTX;
            let isNoFlow    = template.node.flags & F_NOFLOW;

            for (mut i = 0; i < inItems.len + FN_ARGS_BACK; i++)
            {
                fn tryGetArgSpecType(id: string): Type
                {
                    let param = "$" ~ id;
                    for (shadow mut i = 0; i < extra_items.len; i++)
                    {
                        let m = extra_items[i];
                        if (m.id == param)
                        {
                            let o = GET(m.target);
                            o.kind == "type"/* && o.max == 0*/ || fail(
                                "tryGetArgSpecType: Not a typeparam: `"
                                    ~ o.kind ~ ":" ~ param ~ "(" ~ m.target.max ~ ")`.");

                            return o.type;
                        }
                    }

                    return Type;
                }

                let n_arg       = inItems[i];

                // TODO FIX Template prep: mock up free parameters.
                //          Super unclean but at least its contained here.
                if (isUnspec && (n_arg.flags & F_TEMPLATE || !n_arg.items[LET_TYPE]))
                {
                    let init = n_arg.items[LET_INIT]
                            && solveNode(n_arg.items[LET_INIT]);

                    outItems[i] = SolvedNode(
                        kind: "let", flags: n_arg.flags, value: n_arg.value,
                        type: Type(), items: [ [], init, ]);

                    continue;
                }

                let specType    = isSpec && tryGetArgSpecType(n_arg.value);
                let arg         = solveLet(n_arg, :specType);
                outItems[i]     = arg;
            }

            /////////////////////////////////////////////////////
            let n_ret   = !isUnspec && inItems[inItems.len + FN_RET_BACK];
            let n_body  = inItems[inItems.len + FN_BODY_BACK];

            // Builtin?
            n_body || BUG("solveFn: no body.");

            let isNative = n_body.isNativeBody;
            if (!isNative && !isUnspec)
                n_body.kind == "block" || BUG("solveFn: Body not a block: `" ~ n_body.kind ~ "`.");

            // Return type annot.
            let ret_expect = n_ret && evalTypeAnnot(n_ret);

            // Seed return value.
            mut ret_seed = n_ret    ? ret_expect || BUG("falsy ret_expect: " ~ n_fn.value)
                                    : t_never;

            if (ret_seed.lifetime)
            {
                ret_seed.lifetime = isNative
                    ? Lifetime_fromNative(inItems, _current_fn.items[0, _current_fn.items.len + FN_ARGS_BACK], ret_seed)
                    : Lifetime_static(); // we'll overpromise during prep
            }

            // Used twice, once to enable recursion before body, and once when done.
            fn updateScope(shadow out: CurrentFn, mut retval: Type, maybeLast!: bool)
            {
                _here = n_fn.token || BUG();

                ///////////////////////////////
                if (target.status & SS_DIRTY)
                {
                    // Some pass might not have ran,
                    //  so updating the signature might not be safe,
                    //   or might make it unstable.
                    //
                    // --------------------------------------------------------
                    // OPTIMIZABLE (about 10% slowdown from this):
                    //  It's OK to update the sig if:
                    //   - new retval is assignable to old retval.
                    //   - old arguments are assignable to new arguments.
                    // --------------------------------------------------------
                    //
                    GET_mut(target).status |= SS_UPDATED;
                    return;
                }
                ///////////////////////////////

                shadow let items = out.items;

                let N = items.len + FN_ARGS_BACK;
                mut min = 0;
                mut max = 0;

                let NativeHacks =
                    isNative && hacks::NativeHacks(target.name);

                shadow mut args: Argument[];
                for (mut i = 0; i < N; i++)
                {
                    let argNode = items[i];

                    argNode.kind == "letdef" || argNode.target
                        && BUG("Argnode is not letdef, but has a target: "
                                ~ argNode.target.qWHAT);

                    shadow let argNode = argNode.kind == "letdef"
                        ? argNode.target.solved
                        : argNode;

                    argNode.kind == "let" || BUG();

                    //
                    mut name        = argNode.value;
                    let autocall    = argNode.flags & F_COMPOUND_ID && CompoundArgID_outerSplice(name);
                    let isImplicit  = !!(argNode.flags & F_IMPLICIT);

                    // ARGUMENTS AT RISK ////////////////////////
                    let argTarget   = argNode.target;
                    let written_via = !isUnspec
                        && argNode.type.is_mutref
                        && (isNative || out.events.ever_written.has(argTarget.index));

                    mut soft_risk: bitset::BitSet;
                    mut hard_risk: bitset::BitSet;
                    if (written_via)
                    {
                        if (!isNative)
                        {
                            soft_risk.ArgsAtRisk_list(out.flow, position: i, out.flow.at_soft_risk);
                            hard_risk.ArgsAtRisk_list(out.flow, position: i, out.flow.at_hard_risk);

                            if (argNode.type.TODO_FIX_isArray)
                            {
                                ////////////////////////////////////////////////////////////////
                                // TODO FIX soft risk doesn't interop well
                                //  with conversions to slices -
                                //
                                // When an array binds to a slice arg, that caches the array's length -
                                //  Relocating the array via another arg looks like soft-risk to bck,
                                //   but, the way we cg, the view is left dangling.
                                ////////////////////////////////////////////////////////////////

                                mut soft = soft_risk;
                                soft.and_not_assign(hard_risk);

                                soft.each: |index: i32|
                                {
                                    let other = items[index].target.solved;
                                    if !(other.type.TODO_FIX_isArray)
                                        hard_risk.add(index);
                                }
                            }
                        }
                        else
                        {
                            // Natives: we can't see inside, assume everything restricted.
                            soft_risk.add_range(end: N);
                            soft_risk.rem(i);

                            if (!NativeHacks.soft_risk)
                                hard_risk = soft_risk;
                        }
                    }
                    /////////////////////////////////////////////

                    // Validate `pure` asserts.
                    if (isPure && written_via)
                        fail(target.qWHAT   ~ " is not pure, writes to argument " ~ name.human.qID ~ ":\n"
                            ~ qSTACK(:target, Region_fromLocal(argTarget.index),
                                        node: out.out));

                    if (isPureCtx && written_via && isImplicit)
                        fail(target.qWHAT   ~ " is not purectx, writes to implicit argument " ~ name.human.qID ~ ":\n"
                            ~ qSTACK(:target, Region_fromLocal(argTarget.index),
                                        node: out.out));

                    if (maybeLast && isNovec && !(argNode.type.is_trivial) && (argNode.type.is_rx_copy || argNode.type.is_rx_resize))
                        fail(target.qWHAT ~ " is not novec, argument " ~ name.human.qID ~ " is " ~ humanizeType(argNode.type));

                    //
                    let arg = Argument(
                        :name,
                        :autocall,
                        :argNode.flags | (written_via && F_WRITTEN_TO),
                        :argNode.type,
                        default: !isImplicit && argNode.items[LET_INIT],
                        local: argTarget.index,

                        // ARGUMENTS AT RISK //
                        :soft_risk, :hard_risk);

                    arg.type || isUnspec || BUG("updateScope: Unexpected untyped argument: `" ~ name ~ "`.");
                    args.push(arg);

                    if (!isImplicit)
                    {
                        if (max != 0x7fffffff.i32)
                            max++;
                        if (!arg.default)
                            min++;
                    }

                    if (arg.flags & F_REST_ARG)
                        max = 0x7fffffff.i32;

                    // Finally, replace arg target in retval
                    //  with the argument position.
                    if (retval.is_ref && argNode.is_ref)
                    {
                        let region      = Region_fromLocal(argTarget.index);
                        let idx         = retval.lifetime.uni0n.find(region);
                        if (idx >= 0)
                        {
                            retval.lifetime.uni0n.splice(idx, 1);
                            retval.lifetime.uni0n.set::add(Region_fromArgPosition(i));
                        }
                    }
                }

                // Unconditionally replacing the stuff.
                let overload    = GET(target);
                ref ext         = target.EXT_mut;

                mut change      = false;

                if (ext.callers)
                {
                    change = args.len != ext.args.len
                        || !(overload.type == retval);

                    if (!change) for (mut i = 0; i < args.len; i++)
                    {
                        let a = args[i];
                        let b = ext.args[i];
                        if !(a.name == b.name && a.type == b.type)
                        {
                            change = true;
                            break;
                        }
                    }
                }

                ext.min     = min;
                ext.max     = max;
                ext.args    = args;

                shadow ref overload = GET_mut(target);
                overload.type       = retval;

                if (isInline)
                    return;

                retval || BUG("updateScope: no return type.");
                if (retval.is_ref)
                    Lifetime_test(retval.lifetime);

                retval.lifetime.uni0n.each: |r|
                    r.Region_isArgPosition() || r.Region_isStatic() || BUG(
                        "updateScope: Non-static/non-arg leaked:\n\t" ~ r.qWHAT ~ "\n\n\tIn retval lifetime:\n\t" ~ retval.lifetime.qWHAT);

                overload.flags  = out.flags;

                // Not amazing but it is what it is,
                //  these are the only calls c++ guarantees order of eval for,
                //   and generally js, rust & co behave in the same manner, so why not.
                //
                // 16) Every overloaded operator obeys the sequencing rules of
                //      the built-in operator it overloads when called using operator notation.
                //
                // 20) In every simple assignment expression E1=E2\
                //      and every compound assignment expression E1@=E2,
                //       every value computation and side-effect of E2 is
                //        sequenced before every value computation and side effect of E1.
                {
                    let rtl = args.len == 2
                        && overload.flags & F_OPERATOR
                        && cpp::hasAssignment(overload.name);

                    overload.isRTL_set(rtl);
                }

                //
                if (change)
                    overload.status |= SS_UPDATED;

                //
                target.solved_set(!isUnspec && out);
            }

            // Enable recursion.
            if (isFirst)
            {
                updateScope(_current_fn, retval: isInline ? ret_expect : ret_seed, maybeLast: false);

                // Previously initScope:
                {
                    // Let's consider: hashing all fns,
                    //  including the module name and directory in the sighash,
                    //   and potentially extending the hashlen to 6 or 8 chars.
                    //
                    // Perhaps we should do this mangling in the codegen?
                    //
                    mut name = n_fn.value || fail("TODO anonymous fns");

                    mut sighash: string;
                    if (!isNative && !isInline && !isUnspec)
                    {
                        // "namespacing" via the sighash hashes.
                        let sourceModid             = template.node.token.modid;
                        shadow let shortModuleName  = sourceModid != module.modid
                            ? sourceModid && module.modid && getShortModuleName(ctx.modules[sourceModid].fname)
                            : shortModuleName;

                        let sig     = (target.local_of && target.index.str)
                                    ~ shortModuleName
                                    ~ mangleArguments(target.args);
                        if (sig)
                        {
                            sighash = tea::hash62(sig) || BUG();

                            // TODO FIX only doing the separate sighashes for operators -
                            //  get rid of this and make everything work the same,
                            //   which means no name postfixing and such.
                            //
                            if !(n_fn.flags & F_EXTERN ||
                                (n_fn.flags & F_OPERATOR && cpp::hasOperator(name)))
                            {
                                name ~= '_';
                                name ~= sighash[0, 8];

                                sighash = "";
                            }
                        }
                    }

                    fn HACK_nativeNameParts() // __native(id) or __native("include", id)
                    {
                        shadow mut name = "";
                        if (isNative && n_body.items)
                            for (mut i = 0; i < n_body.items.len; i++)
                                name ~= "\n" ~ n_body.items[i].value;

                        return name;
                    }

                    ref overload        = GET_mut(target);
                    overload.name       = HACK_nativeNameParts || name || BUG();
                    overload.sighash    = sighash;

                    overload.kind       = isUnspec      ? "template"
                                        : isNative      ? "__native"
                                        : isInline      ? "inline"
                                                        : "fn";

                    ref ext             = target.EXT_mut;
                    ext.template        = template;
                    ext.spec_of         = overloadIdx;
                }

                // setSpecs & co.
                if (!into && !isInline)
                {
                    let start   = mangle0.find(' ') + 1 || BUG();
                    mangle      = mangle0.slice(0, start)
                                ~ mangleArguments(target.args);

                    mut preexisting: Target;
                    let nx0 = mangle0 != mangle;
                    if (nx0)
                    {
                        preexisting = _specs.map::get(mangle);
                        setSpec(mangle0, preexisting || target);
                    }

                    let nx00 = mangle00 != mangle;
                    if (nx00 && mangle00 != mangle0)
                        setSpec(mangle00, preexisting || target);

                    if (preexisting)
                        return preexisting;

                    setSpec(mangle, target, nx: nx0 && nx00);
                }
            }

            mut didSetBody = false;

            // Regular fns again.
            :NOT_INLINE
            if (!isInline && !isUnspec)
            {
                // The usual.
                mut retval = ret_seed;
                if (!isNative)
                {
                    let s_body = solveBlock(
                        n_body, type: ret_expect,
                        fnbody_of: target.index,
                        id: n_fn.value,
                        mask: i16(HM_Function | HM_CanReturn | HM_LabelUsed | (n_fn.flags & F_LAMBDA && HM_Lambda)));

                    let mustBecomeInlineBecause = currentFn_mustBecomeInline;
                    if (mustBecomeInlineBecause)
                    {
                        isFirst || fail(
                            "Function wants to become inline on after first solve.");

                        isNoFlow && fail(
                            "Function is not noflow: " ~ mustBecomeInlineBecause.qBAD);

                        // Unfortunately we have to throw away
                        //  all this work and start over.
                        //
                        // Unless we make the inliner do something different,
                        //  just move all the newly solved stuff into the parent fn,
                        //   so that no effort is lost at this point.
                        //
                        ref o  = GET_mut(target);
                        o.kind = "inline";
                        o.type = ret_expect;

                        break :NOT_INLINE;
                    }

                    //
                    retval = s_body.helpers.ret_actual;
                    checkAssignable(host: retval, s_body.type, "reval after runAllPasses");

                    // MUT DURING SOLVE,
                    //  implicit args splice in
                    let idx_body = outItems.len + FN_BODY_BACK;
                    outItems[idx_body] = s_body || BUG("falsy body");
                    didSetBody = true;
                }

                //
                updateScope(_current_fn, :retval, maybeLast: true);
            }

            if (!didSetBody)
            {
                let o = GET(target);
                o.kind != "fn" || BUG(
                    "did not set body on " ~ o.qWHAT ~ ": " ~ humanizeType(o.type));
            }
        }

        // Go!
        lazySolveEnd(target);
        return target;
    }


    //

    fn intoScopeItems(typeParams: TypeParams): ScopeItem[]
    {
        mut res: ScopeItem[];

        typeParams.map::pairs(|id, tp|
        {
            let name = "$" ~ id;

            fn checkStruct(shadow type: Type)
            {
                // TODO FIX The thing is the type param might not be the naked value type,
                //  but e.g. a reference or something. It's muddy what we have right now.
                //   Consider getting rid of the $argname params, should obsolete this.
                //
                // See solveTypedef below.
                //
                let t = lookupStruct(type).target;
                return GET(t).type == type && t;
            }

            let type = tp.matched;
            let target = type.isStruct
                && checkStruct(type)
                || Scope_create(_scope,
                    kind: "type",
                    name: "$" ~ id, :type, flags: 0);

            Scope_set(res, name, :target, shadows: false);
        });

        return res;
    }


    //

    fn uPrepStruct(node: Node): SolvedNode
    {
        return __solveStruct(solve: false, :node);
    }

    fn __solveStruct(solve!: bool, node: Node, into!?: Target): SolvedNode
    {
        let origId  = node.value;
        let name    = origId || _current_fn.target && GET(_current_fn.target).name || "Anon";

        //
        mut out_target  = into;
        mut out_type: Type;
        if (out_target)
        {
            out_type    = out_target.type;
        }
        else
        {
            out_type    = initStruct(:name, :node.flags, :SELF_TEST);;
            out_target  = Scope_Typedef(_scope, id: origId, :name,
                type: out_type, :node.flags,
                status: SS_LAZY);

            out_target.EXT_mut.template = createTemplate(:node);
        }

        // Trying to push this down now.
        if (!solve)
            return createEmpty(target: out_target, type: out_type);

        //////////////////////////////////////////////////
        let current_fn_or_type0     = _current_fn_or_type;
        defer _current_fn_or_type   = current_fn_or_type0;
        _current_fn_or_type         = out_target;
        //////////////////////////////////////////////////
        let implicit _current_fnort = out_target;
        //////////////////////////////////////////////////

        GET_mut(out_target).status |= SS_DID_START;

        ///////////////////////////////////////////////
        let helpers0 = _helpers.len;
        let helpers_data0 = _helpers_data.len;
        defer {
            _helpers.shrink(helpers0);
            _helpers_data.shrink(helpers_data0);
        }

        push(HelpersData(mask: HM_Struct, target: out_target || BUG(
            "solveStruct: no out_target: `" ~ origId ~ "`.")));
        ///////////////////////////////////////////////

        // Struct fields only.
        mut structConverts: Target[];
        mut structImports:  i32[];
        mut flat_cnt:       i32;

        mut all_triv = true;

        // Struct members, pass 0.
        fn solveMember(shadow node: Node)
        {
            node.kind == "let" || BUG("solveStructMembers_1: " ~ node.kind);

            node.items[LET_INIT] &&
            node.items[LET_INIT].kind != "definit" &&
                fail("All structs must be zerofilled by default."
                    ~ " Please remove the initializer of struct member `" ~ node.value ~ "`.");

            // Can't continue/return back/fwd compat.
            return solveLetLike_dontTouchScope(node);
        }

        let items = node.items[STRUCT_MEMBERS].items;
        let members = items.map(fn solveMember);

        // (Re)poplate fields.
        {
            ref innerScope = lookupStruct_mut(out_type.canon).items;
            if (!innerScope && members)
            {
                // Dereferencing a struct does not require it
                //  to have any particular qualities.
                let args = [ Argument(name: "this",
                    type: despeculateStruct(out_type)) ];

                for (mut i = 0; i < members.len; i++)
                {
                    let id = items[i].value;

                    // `true` fields.
                    let isPredicate = items[i].flags & F_PREDICATE;

                    let target = Scope_create(
                        _scope, "field", name: id || BUG(),
                        flags: F_PUB | isPredicate);

                    ref ext     = EXT_mut(target);
                    ext.args    = args;
                    ext.min     = 1;
                    ext.max     = 1;

                    Scope_set(innerScope, :id, :target, shadows: false);
                }

                _field_items ~= innerScope;
            }

            // Update field types.
            innerScope.len == members.len || BUG(
                "solveStructMembers_3: field lens mismatch: " ~ innerScope.len ~ " vs " ~ members.len ~ "/" ~ items.len ~ ": `struct " ~ name ~ "`.");

            for (mut i = 0; i < innerScope.len; i++)
            {
                let item = innerScope[i];
                shadow let member = members[i];
                item.id == member.value || BUG("solveStructMembers_4: field id mismatch.");

                ref field = GET_mut(item.target);
                field.type = member.type;

                flat_cnt += tryLookupStruct(member.type).flat_cnt || 1;
                if (all_triv)
                    all_triv = member.type.is_trivial;

                if (member.flags & F_USING)
                {
                    structConverts.push(item.target);

                    let m = field.type.modidOfOrigin;
                    if (m && m != module.modid)
                        structImports.set::add(m);

                    structImports.set::add(field.type.lookupTypeImports());
                }
            }
        }

        // List imports in scope.
        _scope.imports.each(_ss.imports,
            |import| structImports.set::add(import));

        // Add a default constructor.
        {
            mut CHANGE = false;

            mut commonQuals = -1;
            for (mut i = 0; i < members.len; i++)
                commonQuals &= members[i].type.quals;

            let quals0 = out_type.quals;
            let quals1 = out_type.quals &= commonQuals;
            CHANGE   ||= quals0 != quals1;

            //
            {
                ref s       = lookupStruct_mut(out_type.canon);
                s.target    = out_target || BUG("No struct/out_target.");
                s.converts  = structConverts;
                s.imports   = structImports;

                let flat0   = s.flat_cnt;
                let triv0   = s.all_triv;

                s.flat_cnt  = flat_cnt;
                s.all_triv  = all_triv;

                CHANGE    ||= flat0 != flat_cnt || triv0 != all_triv;

                GET(s.target).status & SS_DID_START || BUG(
                    "Setting stuff but missing SS_DID_START.");
            }

            //
            let max = members.len;
            mut min = 0;
            mut args: Argument[];

            for (mut i = 0; i < members.len; i++)
            {
                let member = members[i];

                let arg = Argument(
                    name:       member.value || BUG(),
                    type:       member.type  || BUG(),
                    default:    member.items[LET_INIT],
                    flags:      member.flags & F_MUSTNAME);

                if (!arg.default)
                    min++;

                args.push(arg);
            }

            if (max && !min) min++;

            //
            ref ext         = EXT_mut(out_target);
            ext.min         = min;
            ext.max         = max;
            ext.args        = args;

            let mustUpdate  = CHANGE && ext.callers.len;

            //
            ref overload    = GET_mut(out_target);
            overload.type   = out_type;

            if (mustUpdate)
                overload.status |= SS_UPDATED;
        }

        //
        lazySolveEnd(out_target);

        // We're done here, return nothing.
        return SolvedNode();
    }


    //

    fn lazySolveStart(target: Target, overload: Overload): bool
    {
        // Isn't lazy-started?
        if (overload.status & (SS_DID_START | SS_LAZY) != SS_LAZY)
            return false;

        {
            ref o = GET_mut(target);
            o.status & (SS_FINALIZED | SS_DID_START | SS_DIRTY) && BUG("SS_DID_START: non-zero solver status: " ~ overload.status);
            o.status |= SS_DID_START;

            if (o.kind == "fn")
                doTrySpecialize(into: target);
            else if (o.kind == "type")
                __solveStruct(solve: true, :target.template.node, into: target);
            else
                BUG("lazySolveStart: kind is `" ~ o.kind ~ "`.");
        }

        // Expect changes.
        return true;
    }

    fn lazySolveEnd(t: Target): void
    {
        ref o = GET_mut(t);
        mut reopen: i32[];

        let parent = t.local_of;
        if (o.status & SS_UPDATED)
        {
            o.status &= ~SS_UPDATED;

            let callers = t.callers;

            :NEXT_USER
            for (mut i = 0; i < callers.len; i++)
            {
                mut index = callers[i];

                :GO_UP
                for (;;)
                {
                    shadow let t = Target(:module.modid, :index);
                    shadow ref o = GET_mut(t);

                    // If not started or dirty, means someone else will take care of us here.
                    if (o.status & (SS_DID_START | SS_DIRTY) != SS_DID_START)
                        continue :NEXT_USER;

                    // If still solving somewhere up our callstack, just flag as dirty.
                    if !(o.status & SS_FINALIZED)
                    {
                        o.status |= SS_DIRTY;
                        continue :NEXT_USER;
                    }

                    // Climb up until sibling (or self) -
                    //  this is A->B->C being invalidated by A->D:
                    //   can't just reopen C here, because we don't have B in scope,
                    //    so we have to invalidate B.
                    let up = t.local_of;
                    if (up != parent) // !sibling
                    {
                        up > parent || BUG("lazySolveEnd: about to climb up the wrong tree.");
                        index = up;
                        continue :GO_UP;
                    }

                    // Finally, a finalized, non-local of self,
                    //  gotta reopen & resolve now.
                    makeNote(o.kind == "type" ? N_TypeReopen : N_FnReopen);

                    o.status &= ~(SS_DID_START | SS_DIRTY | SS_FINALIZED);
                    reopen ~= index;

                    continue :NEXT_USER;
                }
            }
        }

        //
        shadow ref o = GET_mut(t);

        if !(o.status & SS_DIRTY)
        {
            o.status |= SS_FINALIZED;
        }
        else
        {
            o.status & SS_FINALIZED && BUG("Stray SS_FINALIZED.");
            o.status &= ~(SS_DID_START | SS_DIRTY);
            makeNote(o.kind == "type" ? N_TypeResolve : N_FnResolve);
        }

        //
        for (mut i = 0; i < reopen.len; i++)
        {
            shadow let t = Target(:module.modid, index: reopen[i]);
            lazySolveStart(t, GET(t));
        }
    }

    fn detectRecursion(target: Target): void
    {
        let overload = GET(target);
        if (overload.status & (SS_FINALIZED | SS_LAZY) != SS_LAZY)
            return;

        // TODO FIX Incorrect: fns can use other fns as type annots.
        //  We need to somehow track who depends on others for type info,
        //   and who depends on others for actual compute.
        let note    = overload.kind == "type" ? N_TypeRecursion : N_FnRecursion;
        let status  = overload.kind == "type" ? SS_TYPE_RECUR   : SS_FN_RECUR;

        for (mut i = _helpers.len; i --> 0; )
        {
            let h = _helpers[i];
            if !(h.isFnOrType)
                continue;

            h.mask & HM_Lambda && BUG("Recursive lambda, what happened here?");
            GET_mut(h.target).status |= status;
            makeNote(note);

            if (h.target == target)
                return;
        }

        BUG("detectRecursion: no _helpers entry for `" ~ overload.name ~ " (" ~ overload.status ~ ")`.");
    }


    //////////////////////////////////////////////////////////

    fn Lifetime_each(lifetime, visit, locals_start!?: i32)
    {
        for (mut i = lifetime.uni0n.len; i --> 0; )
        {
            let r = lifetime.uni0n[i];
            if (r.index < locals_start)
                break;

            if (r.Region_isTemp)
                continue;

            ref o = GET_mut(nested(r.Region_toLocal()));
            visit(:o, i?: i, lifetime?: lifetime);
        }
    }

    fn Lifetime_climbType(o: Overload)
    {
        o.kind == "var" || BUG("Lifetime_climbType: not a `var`: " ~ o.qWHAT);

        let node = o.solved;

        return node.is_ref
            && node.items
            && node.items[LET_INIT].type;
    }

    fn Lifetime_unwind(mut lifetime: Lifetime, locals_start!?: i32): Lifetime
    {
        Lifetime_each(:lifetime, :locals_start, visit: |o, i, shadow lifetime|
        {
            let init = o.Lifetime_climbType;
            if !(init.is_ref)
                continue;

            init.lifetime.uni0n.len || BUG();
            lifetime.uni0n.splice(i, 1);

            let N0      = lifetime.uni0n.len;
            lifetime    = Lifetime_union(lifetime, init.lifetime);
            let N1      = lifetime.uni0n.len;

            i += N1 - N0;
        });

        return lifetime;
    }

    fn Lifetime_unwind_noStatic(mut lifetime: Lifetime)
    {
        if (lifetime.uni0n.if_first.Region_isStatic)
            lifetime.uni0n.shift();

        return Lifetime_unwind(lifetime);
    }

    fn Lifetime_slotsUp2(lifetime: Lifetime, locals_start!: i32): i32[]
    {
        let unwound = Lifetime_unwind(lifetime, :locals_start).uni0n;

        mut result: i32[];
        for (mut i = 0; i < unwound.len; i++)
        {
            let r = unwound[i];
            if (r.index >= locals_start)
                result ~= r.index;
        }

        return result;
    }

    fn Lifetime_F_MOVED_FROM(lifetime: Lifetime)
    {
        Lifetime_each(:lifetime, visit: |o|
        {
            if (o.flags & F_MOVED_FROM)
                continue;

            o.flags |= F_MOVED_FROM;

            // println("MOVED FROM " ~ o.name ~ ": " ~ o.type.humanizeType);

            let init = o.Lifetime_climbType;
            if (init.is_ref)
                Lifetime_F_MOVED_FROM(init.lifetime);
        });
    }

    fn Lifetime_allowsMutrefReturn(lifetime: Lifetime, locals_start!?: i32): bool
    {
        Lifetime_each(:lifetime, :locals_start, visit: |o|
        {
            o.type.is_mutref || BUG(
                "Checking for mutref-return-ok found non-mutref: " ~ o.qWHAT);

            if (o.kind == "var" && !(o.flags & F_REF))
                return false;

            let init = o.Lifetime_climbType;
            if (!Lifetime_allowsMutrefReturn(init.lifetime, :locals_start))
                return false;
        });

        return true;
    }

    //////////////////////////////////////////////////////////

    // Note - as soon as we re-assign the return value,
    //  we want to re-iterate all the return statements,
    //   because that can change our copy/move decision.

    fn superType(reason: string, a: Type, b: Type, id?: string)
    {
        return type_trySuper(a, b) || fail(
            (id && "`" ~ id.human ~ "`: ")
            ~ reason
            ~ "No common supertype: `"
            ~ humanizeType(a) ~ "` | `" ~ humanizeType(b) ~ "`.");
    }

    fn intersectionType(reason: string, a: Type, b: Type, id?: string)
    {
        return type_tryIntersect(a, b) || fail(
            (id && "`" ~ id.human ~ "`: ")
            ~ reason
            ~ "Cannot intersect a common subtype: `"
            ~ humanizeType(a) ~ "` & `" ~ humanizeType(b) ~ "`.");
    }

    fn Lifetime_vs(lifetime: Lifetime, locals_start!?: i32)
    {
        mut neg = false;
        mut pos = false;

        let r = lifetime.uni0n;
        for (mut i = 0; i < r.len && !(pos && neg); i++)
        {
            shadow let r = r[i];
            if (Region_toLocal(r) < locals_start)
                neg = true;
            else if (Region_isTemp(r))
                pos = true;
            else if (Region_GET(r).isRefArg)
                neg = true;
            else
                pos = true;
        }

        return neg == pos ? 0 : neg ? -1 : +1;
    }

    fn solveJump(node: Node, kills: i32): SolvedNode
    {
        let helpers_idx = node.kind == "return"
            ? Scope_lookupReturn(node.value, lambdaOK: !!(node.flags & F_SINGLE_STMT))
            : Scope_lookupLabel (node.value, cont: node.kind == "continue");

        return solveJump(:helpers_idx, :node.items, :kills);
    }

    fn solveJump(mut helpers_idx!: i32, items: [Node], kills: i32): SolvedNode
    {
        fn h = _helpers[helpers_idx];

        //
        let type = h.ret_actual || h.ret_expect;

        // Deal with expression first, might noop the jump.
        mut expr = !items ? createEmpty() : solveNode(
            items.only, :type,

            // Kills is +1 so that kills=0 means noone.
            kills: helpers_idx + 1);

        // Dead code elim.
        if (expr.type.is_never)
            return expr;

        // Detect & shim non-local jumps.
        if (h.local_of != _current_fn.target.index)
        {
            _current_fn.effects.far_jumps.set::add(h.local_of);

            // The fn will solve again as inline,
            //  return a shim here that looks jumpy.
            return createEmpty(kind: "__far_jump", type: t_never);
        }

        // This kinda does it for return non-expression.
        let redundant = kills == helpers_idx + 1;
        if (redundant && expr.type.is_void)
            return expr;

        // In { a { b { c }}}, c kills b kills a.
        while (h.kills)
            helpers_idx = h.kills - 1;

        // TODO FIX see how functions are special,
        //  if we could get rid of the compulsory returns this would clean up nicely.
        if (redundant && !(h.mask & HM_Function))
            return expr;

        // Lazy labels.
        h.mask |= HM_LabelUsed;

        //
        return createJump(:h, expr);
    }

    fn createJump(expr: SolvedNode, h: Helpers)
    {
        let jump = SolvedNode("jump", type: t_never,
            items: expr && [ expr ], helpers: h);

        // NOW, IMPORTANTLY:
        //  If we're about to return a mutref, make sure it doesn't go through an F_MUT.
        //   There's a bit of a conflict of interest here with F_REFs and templates,
        //    we can also start with non-F_REF but keep in mind that this worsens
        //     the problem of const-vs-mut templates, so the rules are a bit blurry here.
        //      We might be better off with explicit consts than explicit vars,
        //       or perhaps allow ref vars to bind to constants.
        //
        let type = expr.type.is_mutref && !expr.type.lifetime.Lifetime_allowsMutrefReturn(:h.locals_start)
            ? clear_mutref(expr.type)
            :              expr.type;

        // TEMP ////////////////////////////////////////////////////////
        // I'm postponing work on lengthening temporary lifetimes -
        //  same principle as locals but i need extra stuff i dont have,
        //   so lets try to get it right without this first.
        shadow let type = type.is_ref2temp
            ? clear_refs(type)
            :            type;
        ////////////////////////////////////////////////////////////////

        reportReturnType(:h, type);

        return jump;
    }

    fn reportReturnType(h!: Helpers, type: Type)
    {
        // Regular block expects are best-effort type inference hints,
        //  whereas fn expects are explicit type annotations that must be enforced.
        if (h.ret_expect)
            checkAssignable(host: h.ret_expect, type,
                "Actual return type does not match annotation");

        h.ret_actual = h.ret_actual
            ? superType("Subsequent return: ", h.ret_actual, type)
            : type;

        h.ret_actual || BUG("Can't be null past this point.");
    }


    //////////////////////////////////////////////////////////

    fn checkAssignable(
        host: Type, guest: Type, err: string,
        id?: string, sep?: string, asArgument!?: bool)
    {
        isAssignable(:asArgument,
            :host   || BUG("Bad host type."),
            :guest  || BUG("Bad guest type."))
                    || fail(err ~ (id && " `" ~ id ~ "`") ~ ": "
                                ~ host .humanizeType() ~ (sep || " <- ")
                                ~ guest.humanizeType());
    }


    // Loops.

    fn Scope_lookupReturn(id: string, lambdaOK: bool): i32
    {
        _helpers.reveach(_ss.helpers, |item, i|
        {
            if !(item.mask & HM_CanReturn)
                continue;
            if (item.mask & HM_Lambda && !lambdaOK)
                continue;
            if (id && item.id != id)
                continue;

            return i;
        });

        fail("No return `" ~ id ~ "` in scope.");
    }

    fn Scope_lookupLabel(id: string, cont!: bool): i32
    {
        mut CONTINUE_BELOW: i32;

        _helpers.reveach(_ss.helpers, |item, ref i|
        {
            // Continue into first return when possible,
            //  this comparison works because of the scope skips.
            if (i < CONTINUE_BELOW - 1)
                i++;

            if !(item.mask & HM_CanBreak)
            {
                if (!CONTINUE_BELOW)
                {
                    if (id || !(item.mask & HM_Lambda))
                        continue;

                    // Lambda break & continue.
                    if !(cont)
                    {
                        CONTINUE_BELOW = i;
                        continue;
                    }
                }

                return i;
            }

            if (!CONTINUE_BELOW)
            {
                if !(id ? item.id == id : item.mask & HM_Anon != 0)
                    continue;

                if (cont)
                {
                    i++;
                    i < _helpers.len || fail("Cannot continue to label `" ~ id ~ "` from here, did you mean to `break`?");
                }
            }

            return i;
        });

        fail("No label `" ~ id ~ "` in scope.");
    }

    fn solveArgID(node: Node, type: Type): SolvedNode
    {
        let expr = solveNode(node.items.only, :type);
        return solved(node, [ expr ], :expr.type);
    }

    fn solveLoop(node: Node): SolvedNode
    {
        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        // TODO really consider getting rid of this,
        //  ideally we'll only have labels on blocks -
        //   the continues-map-to-inner-block thing.
        let brk_idx     = _helpers.len;
        push(HelpersData(
            id:             node.value,
            mask:           HM_Anon | HM_CanBreak,
            local_of:       _current_fn.target.index,
            locals_start:   GET_next_local_index(),
            ret_actual:     t_void));

        let n_init      = node.items[LOOP_INIT];
        let n_pre_cond  = node.items[LOOP_COND];
        let n_body      = node.items[LOOP_BODY];
        let n_post_cond = node.items[LOOP_POST_COND];
        let n_post      = node.items[LOOP_POST];

        let init        = n_init      && solveLetStatement(n_init);
        if (init.type.is_never)
        {
            makeNote(N_DeadLoopInit);
            return init;
        }

        let pre_cond    = n_pre_cond  && solveNode(n_pre_cond,  t_bool);    // TODO deadcode noloop
        let body        = n_body      && solveBlock(n_body, type: t_void);  // TODO deadcode noloop
        let post_cond   = n_post_cond && solveNode(n_post_cond, t_bool);    // TODO deadcode noloop
        let post        = n_post      && solveNode(n_post,      t_void);    // TODO deadcode noloop

        // Control flow.
        let h           = _helpers[brk_idx];
        let type        = !pre_cond && !post_cond && !(h.mask & HM_LabelUsed)
                            ? t_never
                            : t_void;

        return SolvedNode(
            kind: "loop", :type,
            items: [ init, pre_cond, body, post_cond, post ],
            helpers: h);
    }


    // Exotic loops.

    fn solveForFieldsOf(node: Node): SolvedNode
    {
        fn astReplace(shadow node: Node, mutate): Node
        {
            fn walk(shadow ref node: Node)
            {
                for (mut i = 0; i < node.items.len; i++)
                    walk(node.items[i]);

                mutate(node);
            }

            shadow mut node = node;
            walk(node);
            return node;
        }

        let placeholder     = node.value;
        let body_template   = node.items[1];
        let fields_of       = evalTypeAnnot(node.items[0]);
        fields_of.isStruct || fail("[for fieldname]: This is not a struct: `" ~ humanizeType(fields_of) ~ "`.");

        let fields          = lookupStruct(fields_of).items;

        mut items_ast: Node[];
        for (mut i = 0; i < fields.len; i++)
        {
            let field = fields[i];
            if (GET(field.target).kind == "field")
            {
                items_ast ~= astReplace(body_template, |ref item: Node|
                {
                    if (item.value == placeholder)
                    {
                        if (item.items.len == 1 && item.kind == "call")
                        {
                            // TODO field access syntax disables any kind of scope lookup but fields,
                            //  otherwise we risk miscellaneous stuff randomly breaking templates for no good reason.
                            //
                            // if (item.flags & F_ACCESS)
                            //     item.flags |= F_NOSCOPE;
                            //
                            item.value = field.id;
                        }
                        else if (item.kind == "str")
                        {
                            // String literals, potentially useful for serialization.
                            item.value = field.id;
                        }
                    }
                });
            }
        }

        // Control flow & deadcode elim.
        //  TODO break & continue.
        let items = solveNodes(items_ast);
        let type  = items.last.type.is_never ? t_never : t_void;

        return createBlock(type, items);
    }


    //

    fn solveLetLike_dontTouchScope(
        node: Node, specType!?: Type): SolvedNode
    {
        let n_annot = node.items[LET_TYPE];
        let annot   = n_annot && n_annot.kind != "typeunion" && evalTypeAnnot(n_annot);

        // When we're specializing with a mutref, but there's no explicit mutref annot,
        //  we allow relaxing the F_REF so that e.g. bck can resolve by temp-copy.
        mut flags   = node.flags;

        if (specType.is_mutref && !(flags & F_REF || annot.is_mutref))
            flags  |= F_RELAXABLE_REF;

        shadow let annot = specType || annot;

        shadow let annot =
            annot && node.flags & F_REF
                ? add_mutref(annot, Lifetime_temporary)
                : annot;

        let n_init  = node.items[LET_INIT];
        let init    = n_init && solveNode(n_init, annot);

        // Drop defaults that don't match current spec types,
        //  this will effectively make the args non-defaulted.
        shadow let init = specType && init.type && !isAssignableAsArgument(host: specType, init.type)
            ? SolvedNode
            : init;

        return solveLetLike_dontTouchScope(
            node.value, :flags,
            :annot, :init);
    }

    fn solveLetLike_dontTouchScope(
        id: string, mut flags: i32,
        init!: SolvedNode,
        annot!?: Type): SolvedNode
    {
        annot || init.type || fail(
            "Variable declarations without type annotations must be initialized: `" ~ id ~ "`.");

        if (annot && init.type)
            checkAssignable(host: annot, init.type, asArgument: !!(flags & F_ARG),
                "Type annotation does not match init expression",
                    id, "=");

        // Lose refs to temporaries.
        let t_init = init.type;

        shadow let t_init = t_init.is_ref2temp
            ? clear_refs(t_init)
            : t_init;

        // Dead code elim.
        if (!(flags & F_ARG) && t_init.is_never)
        {
            makeNote(N_DeadLet);
            return init;
        }

        // Trying to unify &muts and refs.
        if (annot.is_mutref)
            flags |= F_REF;

        if (flags & F_REF)
        {
            t_init.is_mutref    || t_init.is_never && annot
                                || !init && flags & F_ARG || fail(
                "`ref` variables must be initialized to a mutable reference: `" ~ id ~ "`"
                    ~ (t_init ? " = " ~ humanizeType(t_init) : "."));
        }

        //
        mut t_let   = annot && (flags & F_ARG || !t_init)
                        ? annot
                        : t_init.is_mutref && !(flags & F_REF)
                            ? clear_mutref(t_init)
                            : t_init;

        // Add a temp lifetime to non F_MUT args -
        //  currently all args are currentlypassed by ref.
        if (flags & F_ARG && !(flags & F_MUT))
            t_let = add_ref(t_let, Lifetime_temporary);

        // TODO clean this up, annots not needed.
        //  We could move init out of here?
        //   So we can edit out of order maybe?
        return SolvedNode(
            kind: "let", value: id, :flags,
            type: t_let, items: [ SolvedNode, init ]);
    }

    fn solveLet(node: Node, specType!?: Type): SolvedNode
    {
        mut out = solveLetLike_dontTouchScope(node, :specType);
        let id  = out.value;
        return solveLet(:out, :id);
    }

    fn solveLet(ref out!: SolvedNode, id!: string): SolvedNode
    {
        // Dead code elim.
        if (out.kind != "let")
        {
            out.type.is_never || BUG(
                "solveLet: results in a `" ~ out.kind ~ ": " ~ id ~ "`.");

            return out;
        }

        mut shadows     = !!(out.flags & F_SHADOW);
        let isArg       = out.flags & F_ARG;

        // AUTOCALL ////////////////////////////////////////////////////
        mut cleanID     = "";

        if (out.flags & F_COMPOUND_ID)
        {
            isArg || BUG("solveLet: F_COMPOUND_ID on a non-F_ARG.");

            let start   = id.find('!') + 1;
            let end     = id.find('.', start: start > 0 ? start : 0);

            cleanID     = id.slice(
                start > 0 ? start : 0,
                end   > 0 ? end   : id.len);

            cleanID && cleanID.len < id.len || BUG("solveLet: F_COMPOUND_ID bad cleanID.");
        }

        shadow let id   = cleanID || id;
        ////////////////////////////////////////////////////////////////

        if (out.type.type_isAddrOfFn)
        {
            // Shadowing & addroffns are broken,
            //  we'll just get rid of addroffns,
            //   it was a bad idea.
            //
            shadow let shadows = true;

            unpackAddrOfFn(out.type.canon, |target|
                Scope_set(_scope.items, :id, :target, :shadows));
        }
        else
        {
            ////////////////////////////////////////////////////////////////
            // TODO we need this to happen at a much later stage.
            //  Can we keep this var here and then just codegen it
            //   as a ref to the original?
            //
            if (OPTI_dedupe_vars && !isArg && !(out.flags & (F_PUB|F_IMPLICIT|F_MUT)))
            {
                let init = out.items[LET_INIT];
                if (init.kind == "call" && !init.items)
                {
                    let target  = init.target;
                    let other   = GET(target);

                    if (other.kind == "var")
                    {
                        if (isAssignable(host: other.type, out.type))
                        {
                            // println("VARFOLD " ~ id ~ ": " ~ humanizeType(out.type)
                            //                    ~ " := " ~ other.name ~ ": " ~ humanizeType(other.type));

                            Scope_set(_scope, :id, :target, :shadows);
                            if (out.flags & F_USING)
                                _scope.usings.push(target);

                            out = createEmpty();
                            return out;
                        }
                    }
                }
            }
            ////////////////////////////////////////////////////////////////

            let target = out.target = Binding(:id, :out.flags, :out.type, :shadows);
            target.solved_set(out);

            // List.
            Scope_set(_scope, :id, :target, :shadows);

            if (out.flags & F_IMPLICIT)
                Scope_set(_scope.implicits, :id, :target, :shadows);

            if (out.flags & F_USING)
                _scope.usings.push(target);

            //
            return createLetDef(:target);
        }

        // TODO FIX: these are the addrofn target-less lets,
        //  which aren't runtime arguments, we need them cleaned up during spec
        //   so we don't have to deal with them all over the place like this
        //
        if (out.flags & F_ARG)
            return out;

        return createEmpty();
    }

    fn createLetDef(target: Target)
    {
        return SolvedNode(kind: "letdef", :target, type: []);
    }

    fn createLet(id: string, flags: i32, init: SolvedNode)
    {
        mut out = solveLetLike_dontTouchScope(:flags, :id, :init);
        return solveLet(:out, :id);
    }


    //

    fn solveTypedef(node: Node): SolvedNode
    {
        let annot = evalTypeAnnot(node.items.only);

        // TODO FIX see the typeparams stuff, its the same mess.
        //  The original typedef is setup to work as a constructor, which the Scope_Typedef here won't do.
        //   Perhaps this is fine but we only want to do it if the annot is exactly the same as the original,
        //    or perhaps if the original is assignable to this annot or something?
        //
        if (annot.isStruct)
            Scope_set(_scope, node.value, lookupStruct(annot).target, shadows: false);
        else
            Scope_Typedef(_scope, node.value, annot, node.flags);

        return createEmpty();
    }

    fn solveLetStatement(node: Node): SolvedNode
    {
        node.kind == "let" || BUG("Expected a `let` statement, got: `" ~ node.kind ~ "`.");
        return solveNode(node, t_void);
    }

    fn solveTryCatch(node: Node): SolvedNode
    {
        node.items.len == 3 || BUG();

        /////////////////////////////////
        let scope0  = Scope_snap(_scope);
        /////////////////////////////////

        let try     = solveNode(node.items[0], t_void);

        ///////////////////////////////////////
        Scope_pop(_scope, scope0);
        shadow let scope0 = Scope_snap(_scope);
        ///////////////////////////////////////

        let err     = solveLetStatement(node.items[1]);
        let catch   = solveNode(node.items[2], t_void);

        //////////////////////////
        Scope_pop(_scope, scope0);
        //////////////////////////

        err.kind == "letdef" && isAssignableAsArgument(
            host: err.target.solved.type, t_string) || fail(
                "catch: exceptions are strings,"
                    ~ " consider dropping the annotation.");

        let type    = try.type.is_never && catch.type.is_never
                        ? t_never
                        : t_void;

        return solved(node, type, [ try, err, catch ]);
    }

    fn findModule(fuzimport: string): &Module
    {
        let fname = resolveFile_x(fuzimport);

        let modules = ctx.modules;
        for (mut i = 1; i < modules.len; i++)
        {
            let m = modules[i];
            if (m.fname == fname)
                return m;
        }

        fail("Cannot locate: " ~ fname);
    }

    fn solveImport(node: Node): SolvedNode
    {
        let m = findModule(fuzimport: node.value);
        Scope_import(m.modid);

        //
        return createEmpty();
    }

    fn solveDefer(node: Node): SolvedNode
    {
        ////////////////////////////////////////////
        // TODO unless defer:ok, must be noexcept //
        ////////////////////////////////////////////

        let item = solveNode(node.items.only, t_void);
        return solved(node, t_void, [ item ]);
    }


    // TODO we have to get rid of this.

    fn Scope_lookupType(mut id: string, flags: i32 = 0): Type
    {
        mut scope_iterator: i32;
        mut overloadIdx: Target;
        mut shadows: bool;

        let qualified = flags & F_COMPOUND_ID;
        let scope = qualified
            ? dequalify_andGetScope(id)
            : _scope;

        while (overloadIdx =
            scope.items.search(id, scope_iterator,
                scope_skip: !qualified && _ss.items, :shadows))
        {
            let maybe = GET(overloadIdx);
            if (maybe.kind == "type")
                return maybe.type || BUG();
        }

        return fail("No type `" ~ id ~ "` in scope.");
    }

    fn Scope_lookupType(annot: Node): Type
    {
        return Scope_lookupType(annot.value, :annot.flags);
    }


    //

    fn evalTypeParam(id: string, typeParams?: TypeParams): Type
    {
        return typeParams.map::get(id).matched || Scope_lookupType(
                            "$" ~ (id || fail("Falsy type param id.")))
                                      || fail("No type param `$" ~ id ~ "` in scope.");
    }

    fn solveTypeParam(node: Node): SolvedNode
    {
        return solved(node, evalTypeParam(node.value));
    }

    fn solveAddrOfFn(node: Node): SolvedNode
    {
        let id = node.value;
        let result = solveAddrOfFn(:id, :node.flags);

        let type = Type(ValueType(quals: 0, canon: packAddrOfFn(result)));
        return createEmpty(:type);
    }

    fn solveAddrOfFn(id: string, flags = 0): Target[]
    {
        mut shadow = false;
        mut result: Target[];

        // Visit local scope.
        fn visitScope(items: [ScopeItem])
        {
            mut scope_iterator: i32;
            mut target: Target;
            mut shadows: bool;
            while (!shadow && (target = items.search(
                :id, :scope_iterator, scope_skip: _ss.items, :shadows)))
            {
                // Can't shadow here -
                //  shadowing works per signature,
                //   we can't just shadow everything by the same name in scope.
                result.unshift(target);
            }
        }

        visitScope(_scope.items);

        // TODO FIX:
        //  emit a regular lambda instead.
        if (flags & F_ACCESS)
        {
            // Iterate all visible types, this is slow.
            //  Alternatively we could just unwrap all of these things in
            //   module root scope but that'd slow everything else down.
            fn visitTypes(shadow module: Module)
                module.out.types.each(
                    |struct| visitScope(struct.items));

            // From this module ...
            visitTypes(module);

            // ... and all visible imports.
            _scope.imports.each(_ss.imports,
                |import| visitTypes(ctx.modules[import]));
        }

        //
        return result || fail("No `fn " ~ id ~ "` in scope.");
    }


    //

    fn evalTypeAnnot(node: Node, typeParams?: TypeParams): Type
    {
        // Each T() call should invalidate the results from previous T() calls -
        //  for some reason that's not what's happening here,
        //   and we're happily using the refs.
        //
        fn T(i: i32 = 0)
            evalTypeAnnot(node.items[i], typeParams);

        if (node.kind == "call")
        {
            let items = node.items;
            if (items.len == 1)
            {
                if (node.value == "&")
                    return add_ref(T, Lifetime_temporary);

                if (node.value == "&mut")
                    return add_mutref(T, Lifetime_temporary);

                if (node.value == "[]")
                    return createArray(T);
            }

            // TODO RESEARCH:
            //
            // Falling through to the solveNode() below slows down the compiler by 20% -
            //  it's completely insane, we don't call this that often,
            //   and there's just an extra if/else cascade there.
            //
            return solveCall(node).type;
        }
        else if (node.kind == "typeparam")
        {
            return evalTypeParam(node.value, typeParams);
        }
        else if (node.kind == "arrlit" && node.items.len == 1)
        {
            // Slice.
            return createSlice(T, Lifetime_temporary);
        }

        return solveNode(node).type;
    }

    fn trySolveTypeParams(
        node: Node, mut type: Type, ref typeParams: TypeParams): bool
    {
        if (node.kind == "call")
        {
            let items = node.items;
            if !(items.len)
            {
                // TODO FIX any: should just-work with an `any` type when we get it,
                //  alternatively use an `_` as a special purpose notation here.
                if (node.value == "any")
                    return true;
            }

            :UNARY
            if (items.len == 1)
            {
                mut t   = node.value == "&"    ? tryClear_ref(type)
                        : node.value == "&mut" ? tryClear_mutref(type)
                        : node.value == "[]"   ? tryClear_array(type)
                        : { break :UNARY; };

                if (!t)
                    return false;

                return trySolveTypeParams(
                    items[0] || BUG(), t, typeParams);
            }
        }
        else if (node.kind == "typeparam")
        {
            let id = node.value || BUG();

            // What is happening here?
            // This is crazy, no?
            ref _param = typeParams.map::ref(id);
            if (_param)
            {
                let union = type_trySuper(_param.matched, type, :DONT_match_zeroes);
                if (!union)
                    return false;

                type = union;
            }

            // TODO not here:
            //  we want to clear everything non-canonical from
            //   type params AFTER we solve & match the args,
            //    during the matching it shouldn't be necessary.
            //
            // After the match we need this to e.g. lift `non_zero`
            //  from integral results, etc.
            //
            shadow let type = relax_typeParam(type);

            _param.matched = relax_typeParam(type);

            return true;
        }
        else if (node.kind == "arrlit" && node.items.len == 1)
        {
            // Slice.
            let t = tryClear_sliceable(type);
            return t && trySolveTypeParams(
                node.items[0] || BUG(), t, typeParams);
        }
        else if (node.kind == "typeunion")
        {
            mut undo = typeParams;
            for (mut i = 0; i < node.items.len; i++)
            {
                if (trySolveTypeParams(node.items[i], :type, :typeParams))
                    return true;

                typeParams = undo;
            }

            return false;
        }

        // Everything else is a regular type annotation.
        return isAssignable(
            evalTypeAnnot(node), type, :DONT_match_zeroes);
    }

    fn evalTypePattern(node: Node, ref typeParams: TypeParams): bool
    {
        if (node.kind == "and")
        {
            for (mut i = 0; i < node.items.len; i++)
                if (!evalTypePattern(node.items[i], typeParams))
                    return false;

            return true;
        }
        else if (node.kind == "or")
        {
            mut undo = typeParams;
            for (mut i = 0; i < node.items.len; i++)
            {
                if (evalTypePattern(node.items[i], typeParams))
                    return true;

                typeParams = undo;
            }

            return false;
        }
        else if (node.kind == "typeassert")
        {
            let left  = node.items[0] || BUG();
            let right = node.items[1] || BUG();

            // We'll have to figure out the type tag nonsense at some point.
            //  Perhaps when we have an `any` type,
            //   we could subtype it with the desired quals.
            if (left.kind  == "typeparam" && right.kind == "typetag")
                return type_has(
                    evalTypeParam(left.value, typeParams),
                    right.value || fail("Falsy type tag."));
            else
            {
                let actual = evalTypeAnnot(left, typeParams);

                let ok = trySolveTypeParams(
                    type: actual, node: right,
                        :typeParams);

                ////////////////////////////////////
                // NATIVE RELAXER                 //
                // TODO dont bother unless native //
                if (ok && left.kind == "typeparam")
                {
                    let expect = evalTypeAnnot(right, :typeParams);

                    let id = left.value;
                    ref tp = typeParams.map::ref(id);

                    tp.consumed = tp.consumed
                        ? type_tryIntersect(tp.consumed, expect) || fail("typeassert intersect fail.")
                        : expect;
                }
                // TODO dont bother unless native //
                // NATIVE RELAXER                 //
                ////////////////////////////////////

                return ok;
            }
        }
        else if (node.kind == "call")
        {
            let fn = node.value;
            if (node.items.len == 1)
            {
                if (fn == "!")
                    return !evalTypePattern(node.items[0], typeParams);
            }
        }

        return fail("TODO evalTypePattern fallthrough: "
                    ~ node.kind ~ "(" ~ node.items.len ~ ")");
    }

    fn type_has(type: Type, tag: string)
    {
        if (tag == "trivial")
            return type.is_trivial;

        if (tag == "copy")
            return type.is_rx_copy;

        if (tag == "arithmetic")
            return type.is_arithmetic;

        if (tag == "primitive")
            return type.is_primitive;

        if (tag == "bitfield")
            return type.is_bitfield;

        if (tag == "integral")
            return type.is_integral;

        if (tag == "unsigned")
            return type.is_unsigned;

        if (tag == "floating_point")
            return type.is_floating_pt;

        if (tag == "mutref")
            return type.is_mutref;

        return BUG("Unknown type tag: `" ~ tag ~ "`.");
    }


    //

    fn createRead(id: string): Node
    {
        return Node(
            kind:   "call",
            value:  id,
            token:  (_here || BUG()));
    }

    fn dequalify_andGetScope(ref id: string): &Scope
    {
        let split = id.find('\t');
        split >= 0 || BUG();

        let fname = id.slice(0, split);
        id        = id.slice(split + 1);

        let other = findModule(fuzimport: fname);
        if (other.modid != module.modid)
            return other.out.solve.scope;

        fail("Qualified " ~ id.qBAD ~ ":: access current module.");
    }

    fn solveCall(node: Node, target!?: Target, kills!?: i32): SolvedNode
    {
        // Dead code elim.
        mut args = solveNodes(node.items);
        if (args.if_last.type.is_never)
            return deadCall(args);

        //
        mut id = node.value;
        if (!id) target || BUG();

        // Qualified?
        let qualified = node.flags & F_COMPOUND_ID;
        let misc_scope = qualified && dequalify_andGetScope(id);

        //
        mut reorder: i32[];
        mut conversions: Target[][];
        let callTargIdx = match__mutargs(
            :misc_scope, local_scope: !qualified,
            :id, :args, :reorder, :conversions, :node.flags, :target);

        //
        return CallerNode(node.value, callTargIdx, args, :kills, :reorder, :conversions);
    }

    fn deadCall(args: SolvedNode[]): SolvedNode
    {
        // TODO FIX deadCall order of eval is kinda broken -
        //  a dead default arg will respect LTR but not RTL order of eval,
        //   a dead arg pre-match won't respect any order at all.
        //
        // This would be kinda solved if we decide that order of eval
        //  is as written at each callsite, and not dependent on the target fn,
        //   and we'll enforce RTL for assignments just because that's what's written,
        //    e.g. if invoked as a regular fn it'd be LTR.
        //
        makeNote(N_DeadCall);
        return createBlock(t_never, args);
    }


    // I feel this should be a fncall instead of this here.
    //  It's varargs - so is it a template or what?

    fn solveArrlit(node: Node, type: Type): SolvedNode
    {
        mut itemType = type && tryClear_sliceable(type);

        // Default constructor calls.
        if (!itemType && type.isStruct)
            return solveCall(node,
                target: lookupStruct(type).target);

        // Dead code elim.
        mut args = solveNodes(node.items, itemType);  // TODO FIX retype here, Or maybe this should really just go through trymatch.
        if (args.if_last.type.is_never)
        {
            makeNote(N_DeadArrlit);
            return createBlock(t_never, args);
        }

        //
        if !(node.flags & F_NAMED_ARGS)
            return createArrlit(args, itemType);

        fail("TODO: solveArrlit: tryMatch by [ argnames: ... ] without function name.");
    }

    fn solveArrlit_itemType_init(head!: Type)
    {
        // Super trivial, just don't want to hardcode this here.
        return clear_refs(head) || BUG();
    }

    fn solveArrlit_itemType(items: [SolvedNode], mut itemType?: Type, mut start = 0)
    {
        // Init.
        if (!itemType)
        {
            if (start == items.len)
                return fail("Cannot infer empty arraylit.");

            itemType = solveArrlit_itemType_init(head: items[start++].type);
        }
        else if (itemType.is_ref)
        {
            fail("Array items cannot be refs. TODO Why an error? Should this not just clear_refs?");
        }

        // Rest is simple inter.
        for (mut i = start; i < items.len; i++)
            itemType = superType("Array literal: ", itemType, items[i].type);

        return itemType;
    }

    fn solveArrlit_done(itemType!: Type)
    {
        return createArray(itemType);
    }

    fn createArrlit(mut items: SolvedNode[], itemType?: Type)
    {
        shadow let itemType = solveArrlit_itemType(items, itemType);

        return SolvedNode("arrlit", :items, type: solveArrlit_done(:itemType));
    }


    //

    fn createLet(id: string, type: Type, flags: i32, ref shadows!: bool)
    {
        let target  = Binding(id, type, :flags, :shadows);
        let ret     = SolvedNode(
            kind: "let", :flags,
            value: target.name, :target.type, :target);

        target.solved_set(ret);
        return target;
    }

    fn injectImplicitArg(id: string, type: Type, becauseOf!: Target): Target
    {
        if (!_current_fn.items || _current_fn.out.flags & F_EXTERN)
        {
            // SKETCH EFFECTS //////////////////////////////////////////////
            if (type.isStruct)
            {
                let s = lookupStruct(type);
                if (s.target.flags & F_EFFECT)
                    return s.target;
            }
            // SKETCH EFFECTS //////////////////////////////////////////////

            fail("No implicit " ~ id.qBAD ~ " in scope, needed to call " ~ becauseOf.qWHAT ~ ".");
        }

        // Reuse existing or add new argnode.
        for (mut i = 0; i < _current_fn.items.len + FN_ARGS_BACK; i++)
        {
            ref arg     = _current_fn.items[i];
            let target  = arg.target;

            shadow ref arg = arg.kind == "letdef"
                ? target.GET_mut.solved
                : arg;

            if (arg.value == id)
            {
                mut super = intersectionType(
                    :id, "Implicit argument collision: ",
                    add_ref(type, arg.type.lifetime), arg.type);

                //////////////////////////////////////////////////////////
                // TODO FIX just let the stuff below rerun?             //
                //  Here we're monkey patching, this is just not good.  //
                arg.type                = super;                        //
                target.GET_mut.type     = super;                        //
                //////////////////////////////////////////////////////////

                return target || BUG();
            }
        }

        // We'll be adding a new thing here.
        mut shadows: bool;
        mut flags = F_IMPLICIT | F_ARG;

        if (type.is_mutref)
            flags |= F_REF | F_RELAXABLE_REF;

        let newArgTarget    = createLet(id, type, :flags, :shadows);
        let newArgIdx       = _current_fn.items.len + FN_ARGS_BACK;
        let newLetDef       = createLetDef(newArgTarget);

        _current_fn.items.insert(newArgIdx, newLetDef);

        return newArgTarget;
    }

    fn bindImplicitArg(name: string, type: Type, becauseOf!: Target): SolvedNode
    {
        let id = name;

        // CLOSURE-ID-HACK
        {
            let using _ = hacks::tryParseClosureID(:id);
            if (target.isLocal && target.localOf == _current_fn.target.index)
            {
                revision == _current_fn.target.revision || fail(
                    "ClosureID.revision mismatch: " ~ target.qWHAT
                        ~ "\n\tCaptured at: " ~ revision
                        ~ "\n\tCurrent rev: " ~ _current_fn.target.revision);

                target.kind == "var" || BUG(
                    "ClosureID.target is not a var: " ~ target.qWHAT);

                return CallerNode("__closure", target);
            }
        }
        // CLOSURE-ID-HACK

        mut error: string;
        mut reorder: i32[];
        mut conversions: Target[][];
        let target = tryMatch__mutargs(local_scope: true, :id, :reorder, :conversions, flags: F_IMPLICIT, :error)
            || injectImplicitArg(:id, :type, :becauseOf)
            || BUG();

        let o = GET(target);
        o.flags & F_IMPLICIT || fail(
            "Matching a non-implicit item in scope: `" ~ name ~ "`, binds to call to `" ~ GET(becauseOf).name ~ "`.");

        checkAssignable(host: type, o.type, "Implicit `" ~ name ~ "` type mismatch", asArgument: true);

        return CallerNode("__implicit", :target, :reorder, :conversions);
    }


    //

    fn convertToSuperType(topic: string, ref a: SolvedNode, ref b: SolvedNode): Type
    {
        {
            let super = type_trySuper(a, b);
            if (super)
                return super;
        }

        :TRY_RETYPE
        {
            let aRetype = tryRetyping(a, b.type);
            let bRetype = tryRetyping(b, a.type);

            if (aRetype)
            {
                if (bRetype)
                    fail(topic ~ ": Type ambiguity, literals can be retyped both ways: "
                        ~ a.humanizeType ~ " <-> "
                        ~ b.humanizeType);

                let super = type_trySuper(aRetype, b);
                if (super)
                {
                    applyRetype(a, aRetype);
                    return super;
                }
            }

            if (bRetype)
            {
                let super = type_trySuper(bRetype, a);
                if (super)
                {
                    applyRetype(b, bRetype);
                    return super;
                }
            }
        }

        :TRY_CONVERT
        {
            let aConv = tryConvert(a, expect: b.type, local_scope: true);
            let bConv = tryConvert(b, expect: a.type, local_scope: true);

            if (aConv)
            {
                if (bConv)
                    fail(topic ~ ": Type ambiguity, conversions exist both ways: "
                        ~ a.humanizeType ~ " <-> "
                        ~ b.humanizeType);

                applyConversion(a, aConv);
                return b.type;
            }

            if (bConv)
            {
                applyConversion(b, bConv);
                return a.type;
            }
        }

        fail(topic ~ ": No common supertype: "
            ~ a.humanizeType ~ " <-> "
            ~ b.humanizeType);
    }

    fn solveIf(node: Node, mut type: Type): SolvedNode
    {
        mut cond    = solveNode(node.items[0], t_bool);

        // Static eval - first pass on static ifs,
        //  immediately discard one of the branches.
        if (cond.kind == "bool")
            return solveNode(node.items[cond.value == "true" ? 1 : 2], :type);

        // Dead code elim.
        if (cond.type.is_never)
        {
            makeNote(N_DeadIfCond);
            return cond;
        }

        fn if_A_and_NEVER_then_B_else_C()
        {
            // The same as if-A-then-NEVER-else-C,
            //  which means we drop the cons immediately.
            makeNote(N_DeadIfCons);
            return cond.popAndOr();
        }

        // `a && THROWS ? b : c` is the same as `a ? THROWS : c`
        mut cons    = cond.kind == "and" && cond.items.last.type.is_never
            ? if_A_and_NEVER_then_B_else_C
            : solveBlock(node.items[1], :type);

        mut alt     = solveBlock(node.items[2], :type);

        if (!type.is_void)
            type = convertToSuperType("if/else", cons, alt);

        // Control flow.
        if (cons.type.is_never && alt.type.is_never)
            type = t_never;

        return solved(node, type || BUG(), [ cond, cons, alt ]);
    }


    //////////////////////////////////////////////////
    // Logic                  .                     //
    //////////////////////////////////////////////////

    fn solveOr(node: Node, mut type: Type): SolvedNode
    {
        mut items = solveNodes(node.items,
            type_last: type,
            use_type_last: true,
            static_eval_brk: "true",
            type_all: type.is_void ? t_bool : type);

        if (items.len < 2)
            return items.only;

        // Statement mode.
        if (type.is_void)
            type = t_bool;

        // Unless this is an explicit bool context:
        if !(type == t_bool)
        {
            mut sumType: Type;
            mut hasNever = false;

            // Sum types, ignoring never.
            for (mut i = items.len; i --> 0; )
            {
                ref item = items[i];
                if (item.type.is_never)
                {
                    hasNever = true;
                    continue;
                }

                // a && b || never: b can be mutref!
                let andLast = hasNever
                    && item.kind == "and"
                    && item.items && item.items[item.items.len - 1];

                let itemType = andLast && !andLast.type.is_never
                    ? (item.type = andLast.type)
                    :  item.type;

                //
                if (sumType)
                {
                    sumType = type_trySuper(sumType, itemType);
                    if (!sumType)
                        break;
                }
                else
                {
                    sumType = itemType;
                }
            }

            if (!sumType)
                type = t_bool;
            else
                type = sumType;
        }

        return solved(node, type, items);
    }

    fn solveAnd(node: Node, mut type: Type): SolvedNode
    {
        let items = solveNodes(node.items,
            type_last: type,
            use_type_last: true,
            static_eval_brk: "false",
            type_all: type.is_void ? t_bool : type);

        if (items.len < 2)
            return items.only;

        // Statement mode.
        if (type.is_void)
            type = t_bool;

        // Unless this is an explicit bool context:
        if !(type == t_bool)
        {
            mut sumType: Type;

            // Last item type wins -
            //  unless it's never, which we can safely ignore.
            for (mut i = items.len; i --> 0; )
            {
                let item = items[i];
                if (item.type.is_never)
                    continue;

                if (sumType)
                {
                    sumType = type_trySuper(sumType, item.type);
                    if (!sumType.is_ref)
                        break;
                }
                else
                {
                    type    = item.type;
                    sumType = item.type;

                    // Stop summing up if we've got zeroinit -
                    //  it gets lost in the type union.
                    if (type.is_zeroes)
                        break;
                }
            }

            if (!sumType.is_ref)
            {
                // We'll use the type of the last operand,
                //  and generate a falsy default for the rest.
                if (type.is_ref)
                {
                    // We can generate falsy values and refs,
                    //  but not mutrefs - can't allocate
                    //   a static mut and expect it to remain falsy.
                    if (CANNOT_definit_mutrefs)
                        type = clear_mutref(type);

                    // Default zerofills are static.
                    type.lifetime = Lifetime_makeShared(type.lifetime);
                }
            }
            else
            {
                type = sumType;
            }
        }

        // Because values remain values and refs remain refs,
        //  there's no copying/moving involved in an && chain.
        return solved(node, type, items);
    }

    fn popAndOr(ref node: SolvedNode)
    {
        let N   = node.items.len;
        let pop = node.items[N - 1];

        if (N > 2) {
            node.items.pop();
        }
        else {
            let head = node.items[0];
            node = head;
        }

        return pop;
    }


    //

    fn addr(using token: TokenIdx)
    {
        let using t = token._token;

        if (modid != module.modid)
            return _fname ~ "@" ~ line ~ ":" ~ col;

        return line ~ ":" ~ col;
    }

    fn addr_and_snippet(using token: TokenIdx)
    {
        return token.addr ~ ":\n\n" ~ formatCodeSnippet(token);
    }


    //

    fn SLOW_traverse(node: SolvedNode, visit)
    {
        mut stack = [ node ];

        fn TODO_FIX_pop(arr: $T[])
        {
            mut item: $T; ////////////////////
            swap(item, arr[arr.len - 1]); //// we need a nice pop()
            arr.pop(); ///////////////////////  so lame we dont have it
            return item;
        }

        while (stack)
        {
            shadow let node = stack.TODO_FIX_pop();

            // INDIRECTION !!!!
            shadow let node = node.kind == "letdef"
                ? node.target.solved
                : node;
            // INDIRECTION !!!!

            visit(node);

            for (mut i = node.items.len; i --> 0; )
                stack ~= node.items[i];
        }
    }

    fn qSTACK(target: Target, position!: i32, seen!?: Target[])
    {
        return qSTACK(:target, Region_fromLocal(target.args[position].local), :seen);
    }

    fn qSTACK(target: Target, region: Region, seen!?: Target[])
    {
        //////////////////////////////////////////////////
        let implicit _current_fnort = target;
        //////////////////////////////////////////////////

        return qSTACK(target, target.solved, :region, :seen);
    }

    fn qSTACK(target: Target, node: SolvedNode, region: Region, seen!?: Target[])
    {
        mut src = "\n            ";

        let rec = seen.has(target);
        if (rec)
            src ~= "recursively ";

        :SEARCH
        SLOW_traverse(node): |callsite|
        {
            if (callsite.kind != "call")
                continue;

            let host_args = callsite.target.args;
            for (shadow mut i = 0; i < host_args.len; i++)
            {
                let host_arg = host_args[i];
                if !(host_arg.flags & F_WRITTEN_TO)
                    continue;

                let arg = callsite.items[i];
                if !(Lifetime_unwind(arg.type.lifetime).uni0n.has(region))
                    continue;

                src ~= "via " ~ callsite.target.qWHAT ~ " at ";
                src ~= callsite.token.addr_and_snippet;
                if (!rec && seen.len < 8)
                    src ~= qSTACK(callsite.target, position: i, seen: seen ~ target);

                break :SEARCH;
            }
        }

        return src;
    }


    //

    fn applyRetype(ref arg: SolvedNode, retype: Type)
    {
        arg.type = retype;
    }

    fn applyConversion(ref arg: SolvedNode, conversion: Target[])
    {
        for (mut i = 0; i < conversion.len; i++)
        {
            let t = conversion[i];
            if (t.min || t.max && arg)
            {
                arg = CallerNode("__using.a", t, [ arg ]);
                continue;
            }

            i && fail("Bad conversion chain, non-leading nullary: `" ~ t.name ~ "`.");
            arg && fail("Bad conversion chain, about to throw away an argnode.");
            arg = CallerNode("__using.b", t);
        }
    }

    fn CallerNode(
        debug: string,
        mut target: Target, mut args: SolvedNode[] = [], kills!?: i32, reorder?: i32[], conversions?: Target[][])
            : SolvedNode
    {
        // Do reorder.
        if (reorder)
        {
            // TODO FIX this can be done in place, a neat little algo with swaps
            mut args_out: SolvedNode[]; args_out.resize(reorder.len);

            for (mut i = 0; i < reorder.len; i++)
            {
                let idx = reorder[i];
                if (idx >= 0)
                    args_out[i] = args[idx];
            }

            args = args_out;
        }

        // `using` codegen.
        for (mut argIdx = 0; argIdx < conversions.len; argIdx++)
        {
            let conversion = conversions[argIdx];
            applyConversion(args[argIdx], :conversion);
        }

        // Rest params.
        let REST_START = target.findRestStart();
        if (REST_START < args.len)
        {
            mut rest: SolvedNode[];
            rest.resize(args.len - REST_START);

            for (mut i = args.len; i --> REST_START; )
            {
                swap(rest[i - REST_START], args[i]);
                if (i > REST_START)
                    args.splice(i, 1);
                else
                    args[i] = createArrlit(rest);
            }
        }

        // This was previously part of tryMatch,
        //  but we can just as easily do it here.
        let isZeroInit = target.kind == "type" && !args.len;
        if (!isZeroInit)
        {
            // Defaults & implicit argument injection.
            mut host_args = target.args;
            args.resize(host_args.len);
            for (mut i = 0; i < args.len; i++)
            {
                if (!args[i])
                {
                    let host_arg = host_args[i];

                    args[i] = host_arg.default ||
                    {
                        host_arg.flags & F_IMPLICIT || fail(
                            "tryMatch: about to implicit-bind a non-implicit argument: `"
                                ~ host_arg.name ~ ": " ~ humanizeType(host_arg.type) ~ "`.");

                        bindImplicitArg(:host_arg.name,
                                        :host_arg.type, becauseOf: target)
                    };

                    // This can result in a dead call too.
                    if (args[i].is_never)
                    {
                        args.shrink(i + 1);
                        return deadCall(args);
                    }
                }
            }
        }

        mut type = target.type;

        // HACK -
        //  TBD how we make this stuff work in real life.
        //   OR alternatively, do this for arrays too.
        if (target.kind == "field")
        {
            type = add_refs(from: args.only.type || BUG(), to: target.type);
        }

        // So we're turning closeovers into implicit arguments -
        //  previously we tracked them separately but we're making everything more samey.
        else if (target.kind == "var")
        {
            // INLINE ARGUMENTS ////////////////////////////////////////////
            if (target.flags & F_INLINE)
                return target.solved.items[LET_INIT];
            // INLINE ARGUMENTS ////////////////////////////////////////////

            //
            type.lifetime.uni0n.len == 1 || BUG(
                "CallerNode: var " ~ target.name ~ " type.lifetime.len != 1");

            if (target.isLocal &&
                target.localOf != _current_fn.target.index)
            {
                // CLOSURE-ID-HACK
                // TODO perhaps forbid ClosureIDs here, and hunt down the source of the problem -
                //  complicated close-over schemes do this but its really confusing so not exactly sure why,
                //   there's a good test for it.
                let clID = hacks::tryParseClosureID(id: target.name)
                        || hacks::ClosureID(:target, target.parent.revision || BUG(
                            "ClosureID: about to serialize at rev 0: "
                                ~ target.qWHAT));

                target = injectImplicitArg(
                    id:     clID.serialize(),
                    type:   target.type, becauseOf: target);
                // CLOSURE-ID-HACK

                type = GET(target).type || BUG("CallerNode: !type on var " ~ target.name);
            }
        }

        // Funcs & co.
        else
        {
            // Tag copies and moves.
            if (args)
            {
                let host_args = target.args || BUG("CallerNode: no host args: " ~ target.qWHAT);
                host_args.len >= args.len || BUG("CallerNode: host_arg.len mismatch: " ~ target.qWHAT);

                for (mut i0 = 0; i0 < args.len; i0++)
                {
                    let host_arg = host_args[i0];

                    /////////////////
                    // Literal fixup.

                    // Drop argids at this point, not useful.
                    ref arg = args[i0];
                    if (arg.kind == "argid")
                        arg = arg.items.only;

                    let expect = host_arg.type;
                    {
                        let retype = tryRetyping(arg, expect);
                        if (retype && isAssignableAsArgument(expect, retype))
                            applyRetype(arg, retype);
                    }
                    //        /LITFIX
                    /////////////////
                }
                /////////////////////////////////////////////////////////////////////////////////
            }

            // Inliner.
            if (target.kind == "inline")
            {
                let scope0 = Scope_snap(_scope);
                let ss0 = _ss;

                defer {
                    Scope_pop(_scope, scope0);
                    _ss = ss0;
                }

                let template    = target.template;

                ScopeSkip_setup(:template, :scope0, isInline: true);
                _scope.items ~= target.extra_items;

                //
                let n_fn        = template.node;
                let n_body      = n_fn.items.last;
                let ret_expect  = target.type;
                let host_args   = target.args;

                mut arg_defs: SolvedNode[];
                host_args.len == args.len || BUG("inline: arglen mismatch");

                let locals_start = args && GET_next_local_index();
                for (mut i = 0; i < args.len; i++)
                {
                    let slot = host_args[i];
                    arg_defs ~= createLet(id: slot.name, init: args[i], // TODO__ORIGINAL_ANNOT_OR_TYPE
                        :slot.flags &~ (F_ARG | F_COMPOUND_ID)); // As if not an arg + no autocall.

                    // INLINE ARGUMENTS ////////////////////////////////////////////
                    if (slot.flags & F_INLINE)
                        arg_defs.pop();
                    // INLINE ARGUMENTS ////////////////////////////////////////////
                }

                mut s_body = solveBlock(
                    n_body, type: ret_expect,
                    mask: i16(HM_CanReturn | (n_fn.flags & F_LAMBDA && HM_Lambda) | (arg_defs && HM_KeepBlock)),
                    id: n_fn.value,
                    :kills,
                    :locals_start);

                s_body.kind || BUG("inline: no s_body.kind");
                s_body.items.splice(0, 0, arg_defs);

                return s_body;
            }

            // Not relevant for inline fns.
            if (args && type.is_ref)
                type.lifetime = Lifetime_test(
                    Lifetime_replaceArgsAtCallsite(target, args),
                    tempsOK: true);
        }

        //
        let callsite = SolvedNode(
            "call", flags: 0, value: debug,
                    :type, args, :target);

        // Track deps.
        if (target.modid < 0 || target.modid == module.modid)
        {
            let k = target.kind;

            // Tracking call graph & type annotations.
            if (k == "fn" || k == "type")
            {
                EXT_mut(target).callers.set::add(_current_fn_or_type.index);
                detectRecursion(target);
            }
        }

        return callsite;
    }

    fn definitWrap(ref node: SolvedNode, slot: Type)
    {
        slot.is_mutref && CANNOT_definit_mutrefs && BUG(
            "Trying to definitWrap a mutref.");

        if (node.kind == "definit")
            node.type = slot.is_ref
                ? slot.clear_refs.add_ref(Lifetime_static)
                : slot;
        else
            node = createBlock(type: slot, [
                node,
                createDefinit(type: slot),
            ]);
    }

    fn maybeCopyOrMove(ref node: SolvedNode, slot: Type, isArgument! = false, isReturn! = false): void
    {
        if (slot.canon != node.canon && !node.is_never)
        {
            if (node.type.is_zeroes && !(slot.is_mutref && CANNOT_definit_mutrefs))
            {
                definitWrap(node, slot);
                return;
            }
            else
            {
                BUG("Considering copy or move for incompatible types: "
                    ~ humanizeType(slot) ~ " <- "
                    ~ humanizeType(node));
            }
        }

        // No copy needed when the slot is a reference.
        if (slot.is_ref)
        {
            // TODO move this to codegen
            if (node.type.is_trivial)
            {
                // Except if we're talking a fnarg,
                //  in which case we're better off binding a temporary,
                //   else we risk cache missing on the useless global defval.
                //
                // We only do it for trivial types because
                //  we don't want to add a destructor call here.
                //
                if (node.kind == "definit" && isArgument)
                    node.type = clear_refs(node.type);
            }

            return;
        }

        // Also, no copy needed when the expression is a value.
        if (!node.type.is_ref)
            return;

        // Definits can just as well emit values.
        if (node.kind == "definit")
        {
            node.type = clear_refs(node.type);
            return;
        }

        // Getting messier by the minute.
        if (node.is_zeroes)
        {
            definitWrap(node, slot);
            return;
        }

        // Copy or move.
        let canMove = isReturn && node.type.lifetime.Lifetime_unwind()
                                                    .Lifetime_vs() > 0;

        node = canMove ? createMove(node) : createCopy(node);
    }

    fn createCopy(node: SolvedNode): SolvedNode
    {
        if (!node.type.is_rx_copy)
            fail("Needs an explicit STEAL or CLONE: " ~ humanizeType(node.type));

        if (!node.type.is_trivial)
        {
            USE_nontriv_autocopy || fail("Non-trivial implicit copy.");
            makeNote(N_NonTrivAutoCopy);
        }

        return SolvedNode(
            kind:   "copy",
            items:  [ node ],
            type:   clear_refs(node.type));
    }

    fn createMove(node: SolvedNode): SolvedNode
    {
        // C++ codegen uses the F_MOVED_FROM flag
        //  to remove `const` annotations on locals & refs to locals.
        //
        Lifetime_F_MOVED_FROM(node.type.lifetime);

        return SolvedNode(
            kind:   "move",
            items:  [ node ],
            type:   clear_refs(node.type));
    }


    //

    fn solveNodes(
        nodes: Node[],
        type_all?: Type,
        type_last!?: Type,
        use_type_last!?: bool,
        static_eval_brk!?: string, // OR breaks on "true", AND breaks on "false"
        kills!?: i32): SolvedNode[]
    {
        mut result: SolvedNode[];

        ////////////////////
        let here0   = _here;
        defer _here = here0;
        ////////////////////

        for (mut i = 0; i < nodes.len; i++)
        {
            let node = nodes[i];
            if (!node)
                continue;

            // Regular solve.
            let unorderedClass = unorderedClassify(node.kind);
            if (!unorderedClass)
            {
                HERE(node);

                let last            = i == nodes.len - 1;
                let type            = last && use_type_last ? type_last : type_all;
                shadow let kills    = last && kills;

                //
                let solved = solveNode(:node, :type, :kills);

                result ~= solved;

                // Dead code elim.
                if (solved.type.is_never)
                {
                    if (i < nodes.len - 1)
                        makeNote(N_DeadCode);

                    break;
                }

                // Static eval.
                if (static_eval_brk && solved.kind == "bool")
                {
                    if (solved.value == static_eval_brk)
                        break;

                    if (i < nodes.len - 1)
                        result.pop();
                }

                continue;
            }

            // Unordered solve -
            //  batches multiple potentially recursive declarations,
            //   so we can expose them all in scope prior to solving types.

            // This allows us to have groups of mutually recursive types & functions,
            //  without risking stuff depending on constants & variables
            //   introduced halfway through.
            let i0 = i;
            mut i1 = nodes.len;

            let offset = result.len - i0;

            // First pass, expose stuff in scope
            //  without doing type checking when possible.
            for (shadow mut i = i0; i < nodes.len; i++)
            {
                shadow let node = nodes[i] || BUG("solveNodes, prep-a: falsy node");
                if (unorderedClassify(node.kind) != unorderedClass)
                {
                    i1 = i;
                    break;
                }

                HERE(node);
                result ~= unorderedPrep_A(node);
            }

            // Later we'll continue from group end.
            i1 > i0 || BUG();
            i = i1 - 1; // <- loop++

            // Second prep pass, limit access to scope
            //  of all newly generated entries to what we have right now.
            //
            for (shadow mut i = i0; i < i1; i++)
            {
                shadow let node = nodes[i] || BUG("solveNodes, prep-b: falsy node");
                HERE(node);
                unorderedPrep_B(:node, result[i + offset].target);
            }

            // TODO REMOVE, solve all.
            mut repeat = true;
            while (repeat)
            {
                repeat = false;

                for (shadow mut i = i0; i < i1; i++)
                {
                    shadow let node = nodes[i] || BUG("solveNodes, solve: falsy node");
                    HERE(node);

                    // TODO do this while listing exports instead, expect trouble with prelude.
                    let into = result[i + offset].target;
                    if (lazySolveStart(into, GET(into)))
                        repeat = true;
                }
            }
        }

        //
        return result;
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //
    // Borrow checker, runs. after relaxer, but before AAR (ideally) -
    //  This means everything solved, fully relaxed, a lot of mutrefs now refs, etc.

    fn PASS_borrowCheck(ref root: SolvedNode)
    {
        // Now bck does two passes:
        //
        //  - AAR = false:  this is the fn-local first bck pass.
        //  - AAR = true:   this is the second ARGUMENTS AT RISK pass.
        //
        mut AAR = false;

        fn AAR_cannotFail(reason: string)
        {
            if (AAR)    BUG("AAR PASS is trying to emit an error:\n\n\t" ~ reason);
            else        fail(reason);
        }

        shadow let fail = fn AAR_cannotFail;


        //

        fn RESOLVE_byAAR(read!: i32, write!: i32, trySoft!: bool)
        {
            AAR || BUG();

            read != write || BUG("RESOLVE_byAAR: read == write");

            // Soft vs hard risk -
            //  Non-direct reads from arguments put the argument at hard risk.
            if (!trySoft || !nested(read).acceptsSoftRisk)
                if (!_current_fn.flow.at_hard_risk.grow_if_oob(write).set::add(read))
                    return true; // Done this already.

            // So, on first add -
            if (!_current_fn.flow.at_soft_risk.grow_if_oob(write).set::add(read))
                return true; // Done this already.

            // Shake [1] - decomp write parents on first add.
            let ascendWrites = ||
            {
                let parents = _current_fn.flow.arg_parents.unless_oob(write);
                if (parents)
                {
                    for (mut i = 0; i < parents.len; i++)
                    {
                        let parent = parents[i];

                        // Here's the smart ascent thing -
                        //  A write through some parent binding
                        //   can't invalidate the same binding's read.
                        //
                        // This is a bit crazy, I think it wouldn't be necessary
                        //  if we could remove the invalidation edges on the go.
                        //
                        if (parent != read)
                            RESOLVE_byAAR(:read, write: parent, :trySoft);
                    }

                    return true; // AAR always succeeds.
                }
            };

            // Shake [2] - decomp read parents on first add.
            let ascendReads = ||
            {
                let parents = _current_fn.flow.arg_parents.unless_oob(read);
                if (parents)
                {
                    for (mut i = 0; i < parents.len; i++)
                    {
                        let parent = parents[i];

                        // TODO failcase without this if, suite doesn't catch items
                        if (parent != write)
                            RESOLVE_byAAR(:write, read: parent, trySoft: false);
                    }

                    return true; // AAR always succeeds.
                }
            };

            // Climb one way or the other.
            let firstTry_to_ascendWrites = write > read;
            for (mut i = 0; i < 2; i++)
                if (!i == firstTry_to_ascendWrites) // if (!0 == true or !1 == false)
                    ascendWrites();
                else
                    ascendReads();

            //
            return true; // AAR always succeeds.
        }

        fn RESOLVE_byAAR(write!: i32, reads!: Region[], trySoft!: bool)
        {
            for (mut r = 0; r < reads.len; r++)
            {
                let read = Region_asLocal(reads[r]);
                if (read && read != write)
                    RESOLVE_byAAR(:read, :write, :trySoft);
            }

            return true;
        }


        //

        using fn RWEvent(write: WriteID)
            _current_fn.events.writes[write.id - 1];

        using fn RWEvent(read: ReadID)
            _current_fn.events.reads[read.id - 1];

        fn RESOLVE_byAAR(writes!: WriteID[], read!: i32, trySoft!: bool)
        {
            for (mut i = 0; i < writes.len; i++)
                RESOLVE_byAAR(write: writes[i].rw_target, :read, :trySoft);

            return true;
        }


        // Converting lets into vals:

        fn RESOLVE_byMutvar(target: Target)
        {
            return target.modid == -_current_fn.target.index
                && RESOLVE_byMutvar(target.index);
        }

        fn RESOLVE_byMutvar(target: i32)
        {
            AAR && BUG();

            let t = nested(target);
            ref o = GET_mut(t);

            if (!o.acceptsTempCopies)
                return false;

            o.type.is_mutref && BUG(
                o.qWHAT ~ ": Not F_REF but type.is_mutref"
                        ~ " in RESOLVE_byMutvar: is this a problem?");

            o.kind == "var"                 || BUG("RESOLVE_byMutvar: Not a variable.");
            o.type.lifetime.uni0n.len == 1  || BUG("RESOLVE_byMutvar: lt.len != 1"  );

            if (!o.type.is_rx_copy)
                return false;

            if !(o.flags & F_MUT)
            {
                o.flags  |= F_MUT;
                let t_let = clear_refs(o.type);

                o.solved.type = t_let;
            }

            return true;
        }


        // Inserting a temporary.

        fn RESOLVE_byTempCopy(ref callsite: SolvedNode, position: i32)
        {
            AAR && BUG();

            fn RESOLVE_byTempCopy(ref node: SolvedNode, slot: Type)
            {
                // Reconstruct a maybe-copyable value type -
                //  slot is a ref which may not need q_rx_copy.
                shadow let slot = slot.clear_refs().make_copyable();

                // TODO FIX How do we defer this copy?
                //  MCOM needs to pick up something.
                maybeCopyOrMove(:node, slot);
                return true;
            }

            // Back here.
            let target      = callsite.target;
            let host_args   = target.args;
            let host_arg    = host_args[position];
            let arg         = callsite.items[position];

            // No go if arg is nocopy.
            if (!arg.is_rx_copy)
                return false;

            // Try to introduce a copy on an intermediate variable.
            //  This should help with closures and stuff.
            if (arg.kind == "call" && RESOLVE_byMutvar(arg.target))
                return true;

            // We don't allow this on implicit arguments, which includes closures.
            //  Implicitly copying implicit arguments is a bit much (TODO not sure, is it?).
            if (!host_arg.acceptsTempCopies)
                return false;

            // Re: m_and_c_cant_alias_002 test:
            //  We don't want to return a reference to the temporary,
            //   so for now we just forbid this.
            let argLt       = Region_fromArgPosition(:position);
            let isReturned  = target.type.lifetime.uni0n.has(argLt);
            if (isReturned)
                return false;

            return RESOLVE_byTempCopy(
                node: callsite.items[position],
                slot:      host_args[position].type);
        }


        //

        fn acceptsTempCopies(arg: Argument)
        {
            return !(arg.flags & (F_IMPLICIT | F_REF));
        }

        fn acceptsTempCopies(o: Overload)
        {
            return   o.kind == "var"
                && !(o.flags & (F_IMPLICIT | F_REF))
                &&  !o.type.is_mutref;
        }

        fn acceptsSoftRisk(arg: Argument)
        {
            return !arg.acceptsTempCopies();
        }

        fn acceptsSoftRisk(o: Overload)
        {
            return o.flags & F_ARG && !o.acceptsTempCopies();
        }

        fn isInvalidatedBy(read: Region[], write: Region[])
        {
            shadow let read = read.view(i32);

            write.each: |w.Region_asLocal|
                if (w && flow.invalidates.unless_oob(w).set::has_inter(read))
                    return true;

            return false;
        }

        fn softRiskSafe(arg: SolvedNode)
        {
            // TODO FIX this is idiotic, the problem is that
            //  when we have value with lt'x, we don't know if
            //   - this points directly to the bytes of x
            //   - or is some kind of computed thing,
            //      e.g. ptr to rellocatable mem or smth.
            //
            // This is the major complication to getting disjoint stuff working,
            //  it's kinda easy for vars but what do we do with arg exprs here,
            //   it's that we don't really have any way to tell what's what.
            //
            return arg.kind == "call" && arg.target.kind == "var";
        }


        //

        fn SLOW_find(test, miss): SolvedNode
        {
            mut result: SolvedNode;

            SLOW_traverse(root): |node|
                if (test(:node))
                    result = node;

            return result;
        }

        fn SLOW_findByReadID(read: ReadID)
            SLOW_find(|node| node.reads0 < read.id && node.reads1 >= read.id,
                          || BUG("Cannot find ReadID(" ~ read.id ~ ")."));

        fn SLOW_findByWriteID(write: WriteID)
            SLOW_find(|node| node.writes0 < write.id && node.writes1 >= write.id,
                          || BUG("Cannot find WriteID(" ~ write.id ~ ")."));


        //

        fn RWEvent_stack(write: WriteID)
        {
            let node = SLOW_findByWriteID(write);
            if (node.kind != "call")
                return "\n\tVia " ~ node.kind.qKW;

            mut stack: string;
            {
                let uni0n = nested(write.rw_target).type.lifetime.uni0n;
                if (uni0n) for (mut i = 0; i < node.items.len; i++)
                {
                    let arg = node.items[i];
                    if (arg.lifetime.uni0n.set::inter(uni0n))
                    {
                        let host_arg = node.target.args[i];
                        if (host_arg.flags & F_WRITTEN_TO)
                        {
                            stack = qSTACK(node.target, position: i);
                            break;
                        }
                    }
                }
            }

            let o = GET(node.target);
            return node.token.addr_and_snippet ~ "\n\tAt call to " ~ o.name.qID ~ stack;
        }

        fn bck_name(shadow target: i32)
        {
            return GET(nested(target)).name.human;
        }


        // Reads.

        fn flow         = _current_fn.flow;
        fn events       = _current_fn.events;

        fn bck_trackRead(callsite: SolvedNode)
        {
            if (!callsite.type.is_ref || !_current_fn.target.index)
                return;

            _here           = callsite.token;

            let regions     = callsite.type.lifetime.uni0n;
            let loop_start  = _current_fn.loop_start;

            // Writes invalidate subsequent reads.
            for (mut i = 0; i < regions.len; i++)
            {
                let target = Region_asLocal(regions[i]);
                if (!target)
                    continue;

                // println("bck_trackRead " ~ target ~ " " ~ callsite.value);

                if (events.invalidated_by.len > target)
                {
                    let u = events.invalidated_by[target];
                    if (u)
                    {
                        if (AAR ? !RESOLVE_byAAR(read: target, writes: u, trySoft: true)
                                : !RESOLVE_byMutvar(target))
                        {
                            fail("Cannot access"
                                ~ " " ~            target.bck_name.qBAD ~ ", reference invalidated by write to"
                                ~ " " ~ u.first.rw_target.bck_name.qBAD ~ " at "
                                ~ RWEvent_stack(u.first));
                        }

                        if (OPTI_bck)
                            events.invalidated_by[target] = [];
                    }
                }

                // Order of eval.
                //  OPTIMIZABLE we don't need the read nodeidx here,
                //   we only need the target int.
                //
                events.reads ~= RWEvent(target);
                let readID = ReadID(events.reads.len);

                // Track reads in a loop.
                if (loop_start && target < loop_start)
                    events.used_in_a_loop.grow_if_oob(target) ||= readID;
            }
        }


        // Writes.

        fn bck_trackWrites(callsite: SolvedNode, regions: Region[], positions!: i32[])
        {
            _here           = callsite.token;

            //
            for (mut i = 0; i < regions.len; i++)
            {
                let target      = Region_asLocal(regions[i]);
                if (!target)
                    continue;

                let position    = positions[i];

                // println("bck_trackWrite " ~ target ~ " " ~ callsite.value);

                let invalidates = flow.invalidates.unless_oob(target);

                // Writes in a loop invalidate preceding reads.
                if (events.used_in_a_loop) for (shadow mut i = 0; i < invalidates.len; i++)
                {
                    let read    = invalidates[i];
                    let readID  = events.used_in_a_loop.unless_oob(read);
                    if (readID)
                    {
                        if (AAR)
                            RESOLVE_byAAR(:read, write: target, trySoft: true);
                        else
                            RESOLVE_byMutvar(read) || fail(
                                "Write to " ~ target.bck_name.qBAD
                                ~ " at call to " ~ callsite.target.qWHAT
                                ~ " invalidates the use of " ~ read.bck_name.qBAD ~ " at "
                                ~ SLOW_findByReadID(readID).token.addr_and_snippet
                                ~ "\n\t... on next loop iteration.\n\n\tWritten"
                                ~ qSTACK(callsite.target, :position)); // TODO loop starts at x:x!
                    }
                }

                // Order of eval.
                events.writes ~= RWEvent(target);
                let writeID = WriteID(events.writes.len);

                // Track writes, easy.
                for (shadow mut i = 0; i < invalidates.len; i++)
                {
                    ref set = events.invalidated_by.grow_if_oob(invalidates[i]);
                    if (!OPTI_bck || AAR || !set)
                        set ~= writeID;
                }

                // ARGUMENTS AT RISK ////////////////////////
                fn tagWritten(shadow target: i32)
                    if (events.ever_written.add_once(target))
                        flow.parents.unless_oob(target).each(fn tagWritten);

                tagWritten(target);
                /////////////////////////////////////////////
            }
        }

        fn bck_trackInit(target: Target)
        {
            let index   = target.index;

            // TODO FIX addrofn emits target=0 lets,
            //  this is stupid, no need for such garbage to stay in the ast.
            if (!index)
                return;

            // println("bck_trackInit " ~ target.index ~ " " ~ target.name);

            // Clear invalidation event -
            //  we mistakenly collect these for writes to vars we depend on before init event.
            //   But this same technique can also be used for ref reassignment later on.
            //
            // NOT EXPECTING THIS RIGHT NOW //////////////////////////
            events.invalidated_by.unless_oob(index) && BUG();       //
            // if (events.invalidated_by.unless_oob(index))         //
            //     events.invalidated_by[index] = WriteID();        //
            //////////////////////////////////////////////////////////

            // The GET_next_local_index() thing doesn't work with LATE_BCK,
            //  but this kinda fixes it.
            if (_current_fn.loop_start > index)
                _current_fn.loop_start = index;
        }


        //

        fn bck_let(ref node: SolvedNode)
        {
            // Solve init expr.
            bck_nodes(node.items);

            // Track references.
            if (node.is_ref)
            {
                node.flags & F_ARG && BUG("bck_let: Found an argument!");

                let init = node.items[LET_INIT];
                init.type.is_ref || BUG("What!");

                Reference_trackLocalRef(_current_fn.flow,
                    left:  node.target.index,
                    right: init.type.lifetime);
            }

            // De-invalidate after init expr,
            //  could be invalidated by the init expr, for example:
            //   let c = a = b;
            //
            bck_trackInit(node.target);
        }


        //

        fn bck_call(ref callsite: SolvedNode)
        {
            fn target   = callsite.target;
            fn args     = callsite.items;

            if (args)
            {
                let host_args = target.args;

                // Unless c++ guarantees some order of eval,
                //  we'll keep track of reads and writes,
                //   we add sequencing tags last thing here.
                //
                let ooe_read0   = _current_fn.events.reads.len;
                let ooe_write0  = _current_fn.events.writes.len;

                mut ooe_reads:  i32[];
                mut ooe_writes: i32[];

                let ooe_isRTL   = target.isRTL;

                ///////////////////////////////////////////////
                let ooe_START   = ooe_isRTL ? args.len -1 : 0;
                {
                    shadow lax mut ooe_read0  = ooe_read0;
                    shadow lax mut ooe_write0 = ooe_write0;

                    for (mut ooe_i = 0; ooe_i < args.len; ooe_i++)
                    {
                        bck_node(args[ooe_isRTL ? ooe_START - ooe_i : ooe_i]);

                        let r1 = _current_fn.events.reads.len;
                        let w1 = _current_fn.events.writes.len;

                        if (r1 > ooe_read0)  ooe_reads .grow_oob(ooe_i, fill: ooe_read0) = r1;
                        if (w1 > ooe_write0) ooe_writes.grow_oob(ooe_i, fill: ooe_write0) = w1;

                        ooe_read0 = r1;
                        ooe_write0 = w1;
                    }
                }
                ///////////////////////////////////////////////

                // BORROWCK ////////////////
                mut bck_writes: Region[];
                mut bck_positions: i32[];

                mut mutref_first    = -1;
                mut mutref_last     = -1;
                mut ref_first       = -1;
                mut ref_last        = -1;

                //
                mut bck_unwound: Lifetime[];

                mut arg_first       = -1;
                mut arg_last        = -1;
                ////////////////////////////


                for (mut i0 = 0; i0 < args.len; i0++)
                {
                    let host_arg0   = host_args[i0];
                    let expect      = host_arg0.type;

                    // BORROWCK: multiple mutrefs error,
                    //  this is the only thing we can't workaround by copying.
                    if (expect.is_ref)
                    {
                        // Lazy init unwound lifetimes.
                        if !(bck_unwound)
                        {
                            if (mutref_first >= 0 || ref_first >= 0 && expect.is_mutref)
                            {
                                bck_unwound.resize(args.len);
                                for (shadow mut i0 = ref_first; i0 <= ref_last; i0++)
                                {
                                    let unwound = bck_unwound[i0] = Lifetime_unwind_noStatic(args[i0].type.lifetime);

                                    // Locate first and last callsite arguments
                                    //  that refer to caller arguments,
                                    //   so we can later on loop over them faster.
                                    //
                                    // TODO: args at risk: ignore closures & implicits,
                                    //  they are disjoint by definition.
                                    //   But are they? You can totally have
                                    //    an implicit ref a = implicit b.
                                    //
                                    // TODO: args at risk: ignore non-aliasable types.
                                    //
                                    for (mut i = 0; i < unwound.uni0n.len; i++)
                                    {
                                        if (unwound.uni0n[i].Region_asLocal)
                                        {
                                            arg_first   = arg_first < 0 ? i0 : arg_first;
                                            arg_last    = i0;
                                            continue;
                                        }
                                    }
                                }
                            }
                        }

                        // Validate aliasing.
                        if (bck_unwound)
                        {
                            let arg0     = args[i0];
                            let shallow0 = arg0.type.lifetime;
                            let unwound0 = bck_unwound[i0] = Lifetime_unwind_noStatic(shallow0);

                            // Keep track of caller arguments.
                            for (mut i = 0; i < unwound0.uni0n.len; i++)
                            {
                                if (unwound0.uni0n[i].Region_asLocal)
                                {
                                    arg_first   = arg_first < 0 ? i0 : arg_first;
                                    arg_last    = i0;
                                    continue;
                                }
                            }

                            //
                            fn validate(i1: i32)
                            {
                                let host_arg1 = host_args[i1];

                                // Can the fn handle aliasing here?
                                if (!host_arg0.soft_risk.has(i1) && !host_arg1.soft_risk.has(i0))
                                    return;

                                let arg1     = args[i1];
                                let shallow1 = arg1.type.lifetime;

                                // A note on something that's non-obvious -
                                //  the AAR stuff here DOESNT CARE ABOUT ALIASING -
                                //   we've already dealt with aliasing by the time this runs.
                                //
                                // Also the invalidates/invalidators AAR stuff doesn't affect parenting,
                                //  so we don't get intersections in unwound0 and unwound1.
                                //
                                if (AAR)
                                {
                                    if (i0 >= arg_first && i0 <= arg_last &&
                                        i1 >= arg_first && i1 <= arg_last)
                                    {
                                        for (mut r0 = 0; r0 < shallow0.uni0n.len; r0++)
                                        {
                                            let region0 = Region_asLocal(shallow0.uni0n[r0]);
                                            if (region0)
                                            {
                                                for (mut r1 = 0; r1 < shallow1.uni0n.len; r1++)
                                                {
                                                    let region1 = Region_asLocal(shallow1.uni0n[r1]);
                                                    if (region1 && region0 != region1)
                                                    {
                                                        if (host_arg0.is_mutref)
                                                            RESOLVE_byAAR(write: region0, read: region1,
                                                                trySoft: !host_arg0.hard_risk.has(i1));

                                                        if (host_arg1.is_mutref)
                                                            RESOLVE_byAAR(read: region0, write: region1,
                                                                trySoft: !host_arg1.hard_risk.has(i0));
                                                    }
                                                }
                                            }
                                        }
                                    }

                                    // AAR ends here, inters are not relevant, etc.
                                    return;
                                }

                                // Do we see any aliasing here?
                                let unwound1 = bck_unwound[i1];

                                let inter = Lifetime_inter(unwound0, unwound1);
                                if !(inter)
                                    return;

                                // Soft risk check -
                                //  If neither is listed as a hard risk,
                                //   and neither invalidates the other, then we should be good.
                                if (!host_arg0.hard_risk.has(i1) &&
                                    !host_arg1.hard_risk.has(i0))
                                {
                                    if ((!host_arg0.soft_risk.has(i1) || arg1.softRiskSafe && !shallow1.uni0n.isInvalidatedBy(write: shallow0.uni0n)) &&
                                        (!host_arg1.soft_risk.has(i0) || arg0.softRiskSafe && !shallow0.uni0n.isInvalidatedBy(write: shallow1.uni0n)))
                                    {
                                        // Soft risk ok -
                                        //  this is the new thing, further relaxing the bck.
                                        return makeNote(N_BckSoftRisk);
                                    }
                                }

                                // Try to resolve by injecting a copy -
                                {
                                    mut which = -1;

                                    // It's either or, there's no case
                                    //  where you can copy either (at least one is a ref).
                                    if !(host_arg0.is_mutref)
                                        which = i0;
                                    else if !(host_arg1.is_mutref)
                                        which = i1;

                                    if (which >= 0)
                                    {
                                        if (RESOLVE_byTempCopy(:callsite, which))
                                            return;
                                    }
                                }

                                // BORROWCK Error message.
                                if !(options.dev & options::DEV_DisableBCK)
                                {
                                    mut err = target.qWHAT;

                                    err ~= host_args.len == 2 && target.flags & F_OPERATOR
                                        ?   ": Both operands alias:\n"
                                        :   ": Arguments " ~ host_arg0.name.human.qBAD
                                            ~      " and " ~ host_arg1.name.human.qBAD
                                            ~      " (args #" ~ i0 ~ " and #" ~ i1 ~ ") both alias:\n";

                                    for (shadow mut i = 0; i < inter.uni0n.len; i++)
                                    {
                                        let o = inter.uni0n[i];

                                        err ~=   "\n                ";
                                        err ~= o.qWHAT;
                                    }

                                    _here = args[i0].token;
                                    fail(err);
                                }
                            }

                            // If we have a mutref, go over all refs.
                            if (expect.is_mutref) {
                                for (mut i = ref_first; i <= ref_last; i++)
                                    if (host_args[i].is_ref)
                                        validate(i);
                            }

                            // Else we only care about mutrefs here.
                            else {
                                for (mut i = mutref_first; i <= mutref_last; i++)
                                    if (host_args[i].is_mutref)
                                        validate(i);
                            }
                        }

                        // Track the two lists.
                        {
                            if (ref_first < 0)
                                ref_first = i0;

                            ref_last = i0;
                        }

                        if (expect.is_mutref)
                        {
                            if (mutref_first < 0)
                                mutref_first = i0;

                            mutref_last = i0;

                            // We'll batch all writes together in a bit.
                            if (host_arg0.flags & F_WRITTEN_TO)
                            {
                                let arg0 = args[i0];

                                host_arg0.is_mutref || BUG(host_arg0.name.human.qID ~ ": host_arg0.written but !host_arg0.is_mutref");
                                arg0.is_mutref      || BUG(host_arg0.name.human.qID ~ ": host_arg0.written but !arg.is_mutref");

                                bck_writes.set::add(arg0.lifetime.uni0n,
                                    extras: bck_positions, extra: i0);
                            }
                        }
                    }
                }

                // BORROWCK /////////////////////////////////////////////////////
                // Track all writes at once, not important for reads,
                //  but tracking args one by one would prevent args-at-risk.
                if (bck_writes)
                {
                    bck_positions.len == bck_writes.len || BUG("bck_position.len is off");
                    bck_trackWrites(:callsite, bck_writes, positions: bck_positions);
                }
                /////////////////////////////////////////////////////////////////

                mut MUSTSEQ_mask = 0;

                // We've injected copies and such,
                //  so now all that's left is to add some explicit sequencing.
                {
                    shadow mut ooe_write0 = ooe_write0;

                    for (mut ooe_iw = 0; ooe_iw < ooe_writes.len; ooe_iw++)
                    {
                        let ooe_write1 = ooe_writes[ooe_iw];
                        if (ooe_write1 == ooe_write0)
                            continue;

                        //
                        for (mut w = ooe_write0; w < ooe_write1; w++)
                        {
                            let writeID = WriteID(w + 1);
                            let write   = RWEvent(writeID).rw_target;

                            // RTL indexing is reversed, so 0 always means first.
                            let iw_evalsFirst = ooe_iw == 0;

                            let just_the_write = [ Region_fromLocal(write) ];

                            mut written_and_invalidated: Region[];
                            if (!iw_evalsFirst)
                            {
                                written_and_invalidated = just_the_write;

                                // Deep expansion only useful on non-first arg,
                                //  we only use it for preceding args in OOE.
                                //
                                let invalidates = flow.invalidates.unless_oob(write);
                                written_and_invalidated.set::add(invalidates.view(Region));
                            }

                            ////////////////////////////////////////////////////
                            // TODO we need written to be the full set        //
                            //  of written which is a superset of invalidated //
                            ////////////////////////////////////////////////////

                            // Check remaining arguments.
                            shadow mut ooe_read0 = ooe_read0;

                            for (mut ooe_ir = 0; ooe_ir < ooe_reads.len; ooe_ir++)
                            {
                                let ooe_read1 = ooe_reads[ooe_ir];

                                if (ooe_ir != ooe_iw)
                                {
                                    let ooe_ir_evalsBefore_iw = ooe_ir < ooe_iw;

                                    let written = ooe_ir_evalsBefore_iw
                                        ? written_and_invalidated
                                        : just_the_write;

                                    written || BUG();

                                    for (mut r = ooe_read0; r < ooe_read1; r++)
                                    {
                                        let read    = _current_fn.events.reads[r];
                                        let regions = read.rw_target.nested.type.lifetime.uni0n;

                                        // TODO: set::has_inter,
                                        //  how can this optimization work automatically?
                                        //   !!set::inter -> set::has_inter?
                                        if !(regions.set::has_inter(written))
                                            continue;

                                        // At this point, we've detected an order-of-eval issue.
                                        //  It's either just that, in which case F_MUSTSEQ is fine,
                                        //   or it might be that an arg invalidates a previously evaluated arg
                                        //    (if you imagine that each arg is a let arg0 = xxx, let arg1 = yyy),
                                        //     in which case we'll have to resolve-by-copy.

                                        // Now this is important:
                                        //  If this argument ooe-precedes the writes,
                                        //   we need to check the writes don't garble it's value.
                                        //
                                        // This is not about invalidation -
                                        //  in ++x + ++x nothing gets invalidated,
                                        //   yet you want the first ++x arg to bind to the value of its init,
                                        //    just like any other var, and not get thrashed by the other arg.
                                        //
                                        // If needed, we'll inject a write,
                                        //  if not possible, we'll error out.

                                        // DANGER ZONE:
                                        //
                                        //  RTL methods have these indices flipped,
                                        //   here we index in ORDER OF EVALUATION, not order in AST.
                                        //
                                        //  Wonder if we shouldn't just order things correctly
                                        //   in the AST and avoid this altogether?
                                        //
                                        shadow let r = ooe_isRTL ? ooe_START - ooe_ir : ooe_ir;
                                        shadow let w = ooe_isRTL ? ooe_START - ooe_iw : ooe_iw;

                                        if (ooe_ir_evalsBefore_iw)
                                        {
                                            let arg     = args[r];
                                            let bound   = arg.type.lifetime.uni0n;
                                            let inter   = bound.set::inter(written);
                                            if (inter)
                                            {
                                                // We'll have to inject a copy here.
                                                if (AAR ? !RESOLVE_byAAR(:write, reads: inter, trySoft: true)
                                                        : !RESOLVE_byTempCopy(:callsite, r))
                                                {
                                                    _here = callsite.token;

                                                    fail("At call to " ~ target.qWHAT ~ ", argument binding "
                                                        ~ host_args[r].name.human.qBAD ~ " (arg #" ~ r ~ ") at "
                                                        ~ arg.token.addr_and_snippet
                                                        ~ "\n\t... invalidated by subsequent write to "
                                                        ~ just_the_write.first.qWHAT ~ " upon evaluation of argument "
                                                        ~ host_args[w].name.human.qBAD ~ " (arg #" ~ w ~ ") at "
                                                        ~ RWEvent_stack(writeID));
                                                }
                                            }
                                        }

                                        // TODO FIX: have codegen disregard the mask
                                        //  when cpp guarantees the order - it's call-syntax related.
                                        //
                                        if !(ooe_isRTL)
                                        {
                                            // Flag the arg that needs to eval first for explicit sequencing.
                                            //  This mask thing is kinda stupid, calls with more than 32 args
                                            //   could needlessly sequence some of their args,
                                            //    but it's safe.
                                            //
                                            let mustSeq = ooe_ir_evalsBefore_iw ? r : w;
                                            MUSTSEQ_mask |= 1 << (mustSeq & 31);
                                            makeNote(N_BckMustSeq);
                                        }

                                        break;
                                    }
                                }

                                ooe_read0 = ooe_read1;
                            }
                        }

                        ooe_write0 = ooe_write1;
                    }
                }

                // The sequencing fingerprint, just in case.
                ref helpers = callsite.helpers;
                !helpers || AAR || BUG("MUSTSEQ_mask: helpers already contain something");
                helpers = Helpers(MUSTSEQ_mask | helpers.index);
            }

            //
            else if (target.kind == "var")
            {
                bck_trackRead(callsite);
            }
        }


        //

        fn bck_loop(ref node: SolvedNode)
        {
            ref items = node.items;

            bck_node(items[0]);

            // BORROWCK ////////////////////////////////////////////////////////////
            let loop_start0                     = _current_fn.loop_start;
            let loop_start                      = GET_next_local_index(); // TODO FIX patched up in bck_let but doesn't work
            let events0                         = _current_fn.events.used_in_a_loop;

            _current_fn.loop_start              = loop_start;
            defer _current_fn.loop_start        = loop_start0;
            ////////////////////////////////////////////////////////////////////////

            for (mut i = 1; i < items.len; i++)
                bck_node(items[i]);

            // BORROWCK ////////////////////////////////////////////////////////////
            _current_fn.events.used_in_a_loop   = events0;
            ////////////////////////////////////////////////////////////////////////
        }

        fn bck_if(ref node: SolvedNode)
        {
            ref items = node.items;

            // Cond.
            bck_node(items[0]);

            // Cons //////////////////////////////////////////////
            let e_Restore_AfterCond     = _current_fn.events.snap;
            //////////////////////////////////////////////////////

            bck_node(items[1]);

            // Alt ///////////////////////////////////////////////
            let e_Merge_AfterCons       = _current_fn.events.snap;
            _current_fn.events.snap     = e_Restore_AfterCond;
            //////////////////////////////////////////////////////

            bck_node(items[2]);

            // Done //////////////////////////////////////////////
            _current_fn.events   .Events_merge(e_Merge_AfterCons);
            //////////////////////////////////////////////////////
        }

        fn bck_block(ref node: SolvedNode)
        {
            mut defers: SolvedNode[];

            // Regular items forward.
            ref items = node.items;
            for (mut i = 0; i < items.len; i++)
            {
                shadow ref node = items[i];
                if (node.kind == "defer")
                    defers ~= node.items.only;
                else
                    bck_node(node);
            }

            // Defers in reverse.
            for (mut i = defers.len; i --> 0; )
                bck_node(defers[i]);
        }


        // Borrow check router.

        fn bck_nodes(ref items: SolvedNode[])
            for (mut i = 0; i < items.len; i++)
                bck_node(items[i]);

        fn bck_node(ref node: SolvedNode)
        {
            let k = node.kind;

            ////////////////////////////////////////////
            mut rwr: RWRanges;
            rwr.reads0 = _current_fn.events.reads.len;
            rwr.writes0 = _current_fn.events.writes.len;
            ////////////////////////////////////////////

            if (k == "call")
            {
                // This is the only place where reads & writes actually happen.
                bck_call(node);
            }
            else if (k == "loop")
            {
                // The extra stuff we need to check backward jumps.
                bck_loop(node);
            }
            else if (k == "letdef")
            {
                // INDIRECTION !!!!
                swap(GET_mut(node.target).solved, node);
                bck_node(node);
                swap(GET_mut(node.target).solved, node);
            }
            else if (k == "let")
            {
                // Variable initialization.
                bck_let(node);
            }
            else if (k == "if")
            {
                // Isolate cons from alt and combine effects on exit.
                bck_if(node);
            }
            else if (k == "block")
            {
                // TODO If broken-from, hide effects and append to jumped-to.
                bck_block(node);
            }
            else if (k == "root"
                  || k == "and"  || k == "or"
                  || k == "jump"
                  || k == "try"

                  || k == "copy" || k == "move" // TODO shouldn't occur before bck
                  || k == "arrlit")             // TODO get rid of arrlits
            {
                // The default - descend recursively.
                bck_nodes(node.items);
            }
            else if (k == "pragma")
            {
                // Noop.
            }
            else if (node.items)
            {
                fail("TODO: bck_node(non-empty " ~ k ~ ").");
            }

            ////////////////////////////////////////////
            rwr.reads1 = _current_fn.events.reads.len;
            rwr.writes1 = _current_fn.events.writes.len;
            if (rwr.reads1 > rwr.reads0 || rwr.writes1 > rwr.writes0)
                node.rwr = rwr;
            ////////////////////////////////////////////
        }

        // This feels like its no longer relevant -

        _current_fn_eachArg_FWD: |target, position|
            Reference_trackArgument(flow, target.index, :position);


        // BCK PASS 1: Local analysis & resolve-by-copy.

        bck_node(root);


        // BCK PASS 2: ARGUMENTS AT RISK
        //
        // Previously we had a separate AAR thing going,
        //  now we're trying to piggy back on the regular bck stuff as much as possible,
        //   and only handle things differently when we would otherwise emit an error.
        //
        :SOLVE_AAR
        {
            mut consts: i32[];
            mut refs:   i32[];

            // We only need to seed invalidations from mutref arguments.
            {
                mut last = 0;
                _current_fn_eachArg_FWD: |target|
                {
                    target.modid == -_current_fn.target.index || BUG();
                    last < (last = target.index) || BUG();

                    if (target.solved.type.is_mutref)
                        refs    ~= target.index;
                    else if (target.solved.type.is_ref)
                        consts  ~= target.index;
                }
            }

            if !(refs)
                break :SOLVE_AAR;

            // Setup the AAR invalidation matrix -
            //  we assume that each ref argument invalidates EVERY other argument.
            //
            // As bck runs, instead of raising errors when this causes issues,
            //  we take note that the args can't alias for things to work,
            //   and this becomes our hard_risks/soft_risks solution.
            //
            shadow ref flow = _current_fn.flow;

            // Reset these, here we use them for the speculative aliasing.
            flow.invalidates.clear();

            for (mut i = 0; i < refs.len; i++)
            {
                let target = refs[i];

                // First, ref -> const relationships, cheaper setup.
                if (consts)
                    flow.invalidates.grow_if_oob(target) = consts;

                // Finally set up the ref <-> ref relationships,
                //  which are symmetric.
                //
                shadow mut refs = refs;
                refs.set::rem(target);

                if (refs)
                    flow.invalidates.grow_if_oob(target).set::add(refs);
            }

            // Go.
            {
                AAR = true;
                _current_fn.events = Events();
                bck_node(root);
            }
        }
    }



    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn test_CallSignature(callsite: SolvedNode, debug: string)
    {
        let host_args = callsite.target.args;
        let args      = callsite.items;

        // Zero init.
        if (args.len == 0 && callsite.target.kind == "type")
            return;

        fn err(reason: string)
            BUG(debug ~ " " ~ callsite.target.qWHAT ~ ": " ~ reason);

        host_args.len == args.len || err(
            "host_args.len (" ~ host_args.len ~ ") != args.len (" ~ args.len ~ "):"
                ~ "\n\t\t" ~ mangleArguments(args)
                ~ "\n\t\t" ~ explainWhichFn(callsite.target));

        for (mut i = 0; i < host_args.len; i++)
        {
            let host_arg = host_args[i];
            let arg      = args[i];

            isAssignableAsArgument(host: host_arg.type, arg.type)
                || err("Arg #" ~ i ~ ", " ~ host_arg.name.human.qID
                        ~ " not assignable to host_arg: "
                        ~ humanizeType(host_arg.type) ~ " <- "
                        ~ humanizeType(     arg.type));
        }
    }

    fn test_Statements(block: SolvedNode, debug: string)
    {
        let items = block.items;
        for (mut i = 0; i < items.len; i++)
        {
            let n = items[i];
            n.kind || BUG(debug ~ ": No .kind on item[" ~ i ~ "].");
        }
    }


    // AST validation router.

    fn test_nodes(nodes: SolvedNode[], debug: string)
        for (mut i = 0; i < nodes.len; i++)
            test_node(nodes[i], debug ~ "[" ~ i ~ "]");

    fn test_node(node: SolvedNode, mut debug: string)
    {
        debug ~= "/" ~ node.kind;
        if (node.value)
            debug ~= "[" ~ node.value ~ "]";

        test_nodes(node.items, :debug); _here = node.token;

        // General invariants.
        !node.is_ref == !node.lifetime || BUG(
            debug ~ ": !!ref != !!lt: " ~ humanizeType(node.type));

        //
        let k = node.kind;
        if (k == "call")
            return test_CallSignature(node, :debug);

        if (k == "let")
        {
            node.items.len == 2 || BUG("let.items.len: " ~ node.items.len);
            node.items[0] && BUG("let.items[0] not empty: " ~ node.items[0].kind);
            return;
        }

        if (k == "block" || k == "and" || k == "or" || k == "if")
        {
            if (k == "and" || k == "or")
                node.items.len > 1 || BUG(debug ~ ".len: " ~ node.items.len);

            if (k == "if")
                node.items.len == 3 || BUG(debug ~ ".len: " ~ node.items.len);

            return test_Statements(node, :debug);
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn mcom_BlockReturns_CopyOrMoveDecision(h: Helpers)
    {
        if (!h.ret_actual.is_ref)
            return;

        // If the jump is a return-current-fn:
        //  We cannot promote var lifetimes past this fn
        //   (we actually can but its more complicated and not necessary)
        //    BUT we dont have to worry about retval users,
        //     so just change the retval to reflect the current var/ref situation.
        //
        if (h.mask & HM_Function)
        {
            let unwind = Lifetime_unwind(h.ret_actual.lifetime);
            if (Lifetime_vs(unwind, :h.locals_start) < 0)
                h.ret_actual.lifetime = unwind;
            else
                reportReturnType(:h, clear_refs(h.ret_actual));
        }
        // Otherwise, we can extend local LTs,
        //  so that's what we're gonna do for now.
        //   We need to figure out how to determine if LT-extend is better/worse than cpy/mov -
        //    depends on what you do with the result, if you later cpy, the mov would have been better,
        //     if you just use as ref, LT-extend is better.
        //
        else
        {
            Lifetime_slotsUp2(:h.ret_actual.lifetime, :h.locals_start).each: |index|
            {
                ref o = GET_mut(nested(index));
                if !(o.flags & F_ARG)
                    o.flags |= F_HOIST;
            }
        }
    }


    // Maybe-copy-or-move router.

    fn mcom_node(ref node: SolvedNode)
    {
        let k = node.kind;
        let t = node.type;

        if (k == "block")
        {
            // We need this before mcom -
            //  and without the .returns listing, this is as late as we can do this.
            if (node.helpers)
                mcom_BlockReturns_CopyOrMoveDecision(
                    node.helpers);
        }

        // Children.
        ref items = node.items;
        for (mut i = 0; i < items.len; i++)
            mcom_node(items[i]);

        ///////////////////
        _here = node.token;
        ///////////////////

        if (k == "call")
        {
            let target = node.target;
            if (target.kind != "field")
            {
                let host_args = target.args;
                for (mut i = 0; i < items.len; i++)
                    maybeCopyOrMove(items[i], host_args[i].type, isArgument: true);
            }
        }
        else if (k == "block" || k == "jump")
        {
            let h = node.helpers;
            if (h.ret_actual && !h.ret_actual.is_void && !h.ret_actual.is_never)
                maybeCopyOrMove(node.items.last, h.ret_actual, isReturn: true);
        }
        else if (k == "letdef")
        {
            // INDIRECTION !!!!
            swap(GET_mut(node.target).solved, node);
            mcom_node(node);
            swap(GET_mut(node.target).solved, node);
        }
        else if (k == "let")
        {
            if (node.items)
            {
                ref init = node.items[LET_INIT];
                if (init)
                    maybeCopyOrMove(init, node.type);
            }
        }
        else if (k == "if")
        {
            if !(t.is_void)
            {
                maybeCopyOrMove(items[1], t);
                maybeCopyOrMove(items[2], t);
            }
        }
        else if (k == "or")
        {
            if !(t == t_bool)
                for (mut i = 0; i < items.len; i++)
                    maybeCopyOrMove(items[i], t);
        }
        else if (k == "arrlit")
        {
            shadow let t = clear_sliceable(t);

            for (mut i = 0; i < items.len; i++)
                maybeCopyOrMove(items[i], t);
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn runAllPasses(ref node: SolvedNode)
    {
        ///////////////////////////////
        if (SELF_TEST) test_node(node, "PASS.0 ");
        ///////////////////////////////

        _current_fn.var_usage = [];
        propagateType(node, node.type, relax_mask: RELAX_before_bck);

        ///////////////////////////////
        if (SELF_TEST) test_node(node, "PASS.0.relax ");
        ///////////////////////////////

        PASS_borrowCheck(node);

        ///////////////////////////////
        if (SELF_TEST) test_node(node, "PASS.1 ");
        ///////////////////////////////

        mcom_node(node);

        ///////////////////////////////
        if (SELF_TEST) test_node(node, "PASS.2 ");
        ///////////////////////////////

        _current_fn.var_usage = [];
        propagateType(node, node.type, relax_mask: RELAX_all);

        ///////////////////////////////
        if (SELF_TEST) test_node(node, "PASS.2.relax ");
        ///////////////////////////////
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn compilerBreak()
    {
        mut debug = "\nCompiler break:";

        // Print all locals.
        if (_current_fn.target)
        {
            let t  = _current_fn.target;
            debug ~= "\n    Current fn: " ~ t.qWHAT() ~ " at (" ~ t.modid ~ ", " ~ t.index ~ "):";

            let locals = t.locals;
            for (mut i = 0; i < locals.len; i++)
            {
                let item = locals[i];
                debug ~= "\n        " ~ item.qWHAT();
            }
        }

        if (debug)
            println(debug);

        //
        debug::break();
    }


    //

    fn Scope_observeDefects(items: ScopeItem[])
    {
        mut hasLets         = false;
        mut hasPubTemplates = false;

        mut privates: Target[];

        for (mut i = 0; i < items.len; i++)
        {
            let t = items[i].target;
            if (t.modid != module.modid)
                continue;

            let o = GET(t);
            if (o.kind == "var")
            {
                hasLets = true;
                if !(o.flags & F_PUB)
                    privates ~= t;
            }
            else if (o.kind == "fn")
            {
                if !(o.flags & F_PUB)
                    privates ~= t;
            }
            else if (o.kind == "template")
            {
                if (o.flags & F_PUB)
                    hasPubTemplates = true;
            }
        }

        // Note if we need to orchestrate c++ static init order.
        //  OPTIMIZABLE: not every let needs static init,
        //   flag constexpr stuff here instead of in codegen.
        if (hasLets)
            makeNote(N_SD_HasStaticInit);

        // Ensuring public templates have access
        //  to private stuff across translation units.
        if (privates && hasPubTemplates)
        {
            makeNote(N_SD_ExternPrivates);

            // F_PUB all privates so they get externed by codegen,
            //  so public templates can access them from other translation units.
            for (mut i = 0; i < privates.len; i++)
            {
                ref o = GET_mut(privates[i]);
                o.flags |= F_EXTERN;
            }
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    // Import prelude / inject builtins.
    if (module.modid)
    {
        // Ensure can't reimport self.
        _scope.imports ~= module.modid;

        // Load prelude.
        _Scope_import__forceCopy(0);
    }
    else
    {
        // Pre-populate prelude with primitive types and such.
        _scope = listGlobals();
    }

    // Solve.
    {
        // println("\n----------------------------\n");

        let implicit _current_fnort = Target(:module.modid, 0);

        let root = solveNode(parse);

        _current_fn.out && BUG("non-empty _current_fn.");

        _helpers_data[0] && BUG("non-empty _helpers_data[0].");

        // println("TOTAL OVERLOADS " ~ module.fname ~ ": " ~ _scope.overloads.len);

        // Global deoptis so it can all work.
        Scope_observeDefects(_scope.items);

        // TODO suppressing & opting out of warnings.
        for (mut i = 0; i < _warnings.len; i++)
        {
            let w = _warnings[i];
            if (w.token)
            {
                _here = w.token;
                fail(w.message);
            }
        }

        // Exports.
        return SolverOutput(
            root:  root,
            scope: Scope_exports(_scope, :module.modid, _field_items),
            notes: _notes);
    }
}
