import ansi;
import helpers;
import flags;
import scope;
import context;
import types;
import quals;
import structs;
import effects;
import lifetime;
import module;
import fail;


//

let OPTI_autoshadow         = true;
let OPTI_dedupe_vars        = true;
let OPTI_bck                = true;
let OPTI_unlist_callers     = true;
let OPTI_moves_inside_fns   = true;


//

let RESOLVE_report          = false;
let TRACE_enable            = false;


// When you have an if (a -> $T) somewhere,
//  it's just not very useful for -> to match on default-anything,
//   so let's define `->` to be the `is` operator.
//
// We have the `=>` as the `as` operator,
//  we need a counterpart for an `assigns to` operator,
//   which can naturally fit zeroes.
//
let DONT_match_zeroes       = true;

let MOVE_from_temp          = true;

let TODO_FIX_static_ZSTs    = true;



///////////////////////////////////////
///////////////////////////////////////
///////////////////////////////////////
///////////////////////////////////////
////////
////////
////////
////////     Solver.

pub fn solve(
    implicit ctx: Context,
    implicit ref module: Module,
    implicit options: options::Options): SolverOutput
{
    let implicit mut _here: TokenIdx;

    PROFILE(.UnaccountedFor, reset: true);


    //

    lax mut TRACE_out       = TRACE_enable ? string : void;
    lax mut TRACE_indent    = TRACE_enable ? string : void;

    lax fn TRACE_BRACKET(inline msg: string) unwrap
    {
        lax mut indent0:    string;
        lax mut len0:       int;

        if (TRACE_enable)
        {
            len0    = TRACE_out.len;
            indent0 = TRACE_indent ~ '\t';
            swap(TRACE_indent, indent0);
        }

        defer if (TRACE_enable)
        {
            if (TRACE_out.len > len0)
            {
                TRACE_out.splice(len0, 0, indent0 ~ "< " ~ msg ~ " >\n");
                TRACE_out ~= indent0 ~ "</" ~ msg ~ " >\n";
            }

            swap(indent0, TRACE_indent);
        }
    }

    lax fn TRACE(inline msg: string)
    {
        if (TRACE_enable)
            (((TRACE_out ~= "-------") ~= TRACE_indent) ~= msg) ~= '\n';
    }

    defer if (TRACE_enable)
    {
        println("TRACE\n\n" ~ (TRACE_out || "nothing") ~ "\n");
    }


    //

    struct Warning
    {
        token:              TokenIdx;
        message:            string;
    };

    struct WriteID
    {
        _locid_and_hash:    u32;
    };

    struct EventsSnap
    {
        // Writes invalidate subsequent reads -
        invalidated_by:     WriteID[][];
    };

    struct PrecedingRefArg
    {
        // Callsite info.
        callsite_token:     TokenIdx;
        target:             Target;
        r:                  i32;
        w:                  i32;

        // Argument binding.
        arg:                SolvedNode;
    };

    struct Events
    {
        using snap:         EventsSnap;

        // In a loop, reads forbid subsequent writes -
        used_in_a_loop:     bitset::BitSet;

        // Previously bound reference arguments at currently checked callsites -
        preceding_ref_args: PrecedingRefArg[];

        // COW validation, indirect copies behind callsites.
        cows_inside:        COWInside[];
    };

    fn clear(ref events: Events)
    {
        events = [];
    }

    fn Events_merge(ref events: EventsSnap, snap: EventsSnap)
    {
        fn Events_merge(ref dest: $T[], src: $T[])
        {
            if (dest.len < src.len)
                dest.grow(src.len);

            for (mut i = 0; i < src.len; i++) {
                shadow let src = src[i];
                if (src)
                    dest[i].set::add(src);
            }
        }

        for (fieldname i: EventsSnap)
            events.i.Events_merge(snap.i);
    }

    fn Events_restore(ref events: Events,

        // Restores these events -
        restore: EventsSnap,

        // Without climbing past parent_loop_start.
        parent_loop_start: i32)
    {
        if (!parent_loop_start)
            BUG("Events_restore: no parent_loop_start, cant decide which events need to be survive");

        if (parent_loop_start == 1)
        {
            events.snap = restore;
            return;
        }

        // Previously we just assigned events =
        fn Events_restore(ref dest: $T[], src: $T[])
        {
            if (dest.len > parent_loop_start)
                dest.shrink(parent_loop_start);

            if (src.len > parent_loop_start)
            {
                dest.grow(parent_loop_start);
                dest ~= src[parent_loop_start :];
            }
        }

        for (fieldname i: EventsSnap)
            events.i.Events_restore(restore.i);
    }

    struct PostdomSnap
    {
        // Moves.
        used_again:         bitset::BitSet;

        // BCK & COW.
        ever_written:       bitset::BitSet;

        // COW.
        mayEscapeVia:       i32;
        exitPaths:          ExitPaths;
    };

    struct Postdom
    {
        using snap:         PostdomSnap;
        parent_loop_start:  i32;
    };

    fn Postdom_resetAtFnEnd(ref postdom: Postdom)
    {
        postdom                     = [];
        postdom.parent_loop_start   = 1;
        postdom.exitPaths           = XP_EmptyReturn;
    }

    fn branch(ref dest: Postdom, src: Postdom)
    {
        for (fieldname i: PostdomSnap)
            dest.snap.i |= src.snap.i;

        dest.parent_loop_start = max(
            dest.parent_loop_start || BUG(),
             src.parent_loop_start || BUG());
    }

    struct Usage
    {
        done_relaxing:      bitset::BitSet;
        var_usage:          Type[];
    };

    struct Flow
    {
        // Reference graph.
        rg_parents:     Lifetime[];
        rg_invalidates: Lifetime[];     // Non-disjoint siblings and children.
        rg_children:    i32[][];        // Used by validateCOW

        // Arguments at risk.
        at_soft_risk:   bitset::BitSet[];
        at_hard_risk:   bitset::BitSet[];

        // AAR: helpers.
        is_arg:         bitset::BitSet;
        arg_parents:    i32[][];
        arg_targets:    i32[];
    };

    struct CurrentFn
    {
        true using out:     SolvedNode;

        // Start-of-func scope0 for implicit scopeskip.
        scope0:             ScopeMemo;

        asserts:            DeclAsserts;

        using flow?:        Flow;

        using effects?:     Effects;
        using events?:      Events;
        autoshadow_ok!:     i32;

        // The replacement for the callsites stuff.
        using relaxed?:     Usage;

        // So we can pass the F_INLINE flag onto mustBecomeInline
        TODO_FIX_isInline?: bool;

        //
        TODO_FIX_catches?:  i32;

        // Tempfix, securing old inliner against recursive inlining.
        now_inlining?:      Target[];

        //
        using postdom?:     Postdom;

        //
        TODO_FIX_children?: i32[][];

        //
        TODO_FIX_unique?:   i32;
    };

    struct ChildTarget
    {
        token:              TokenIdx;
        parent_rev:         u32;
        target:             Target;
    }

    struct SpecExtras
    {
        scope_items:        ScopeItem[];
        arg_spec_types:     map::Map(string, Type);
    };

    struct Ephemeral
    {
        local_of:           i32;
        revision:           u32;

        scope_memo?:        ScopeMemo;
        scope_skip?:        ScopeSkipMemos;

        spec_extras?:       SpecExtras;

        callers?:           i32[];
        calls?:             i32[];

        children?:          ChildTarget[];
        specs?:             map::Map(string, Target); // mangle -> spec;
    };

    using flags TypeParamFlags {
        TP_isArgSpec;
        TP_isTypenameArgSpec;
        TP_needsConsumedTypes;
    };

    struct TypeParam {
        matched:        Type;
        invariant:      Type;
        consumed:       Type;
        flags:          TypeParamFlags;
    };

    type TypeParams = map::Map(string, TypeParam);

    using enum SolverPass
    {
        Solving = 0
        RelaxMut
        BorrowCheck
        ArgumentsAtRisk
        MaybeCopyOrMove
        RelaxCopyResize
    };

    struct SolverState
    {
        _scope:             Scope;
        _root_scope:        ScopeMemo;
        _ss:                ScopeSkipMemos;
        _field_items:       ScopeItem[];
        _pub_imports:       i32[];
        _helpers_data:      HelpersData[];
        _ephemeral:         Ephemeral[];

        // Can't we just list them all and scan through?
        //  Do we need the mangling nonsense?
        //   We can bucket however many times we want here,
        //    its append only and trivial to maintain.
        _spec_errors:       string[];

        //
        _warnings:          Warning[];
        shortModuleName:    string;

        TODO_FIX_convert_args:  SolvedNode[];
        TODO_FIX_inline_safety: i32;

        //
        _typeParams:        TypeParams;

        //
        _solvingFnort:      Target;
        _nestingFnort:      Target;
    };

    struct HelpersData
    {
        target!?:       Target;
        pass!?:         SolverPass;

        id?:            string;
        mask!?:         HelpersMask;
        local_of!?:     i32;
        locals_start!?: i32;

        ret_expect?:    Type;
        ret_actual?:    Type;

        usage?:         Type[];

        postdom?:       Postdom;
        loop_PREVITER?: Postdom;    // TODO dont remember why i added this
                                    //  might be ExitPath related, seems dodgy af
        postevt?:       EventsSnap;

        kills!?:        Helpers;
    };

    using enum StaticEval {
        SE_Unknown = 0
        SE_False
        SE_True
    };

    using enum BorrowCheckPass {
        BCK_bck
        BCK_aar
        BCK_ooe
    };

    using enum ArgQuery {
        AQ_WhyNotNovec
    };

    using enum DeadBreak {
        DeadBreak_Dont = 0
        DeadBreak_Always
        DeadBreak_Only_WhileSolvingRecursion
    };

    struct Reorder {
        true applicable: bool;
        map: i32[];
    };

    fn clear(ref flow: Flow)
    {
        if (flow.at_hard_risk || flow.at_soft_risk)
            throw("Flow.clear(): Non-empty at-risk tables.");

        for (fieldname i: Flow)
            flow.i.clear();
    }

    fn clear(ref reorder: Reorder) {
        reorder.applicable = false;
        reorder.map.clear();
    }


    //

    using enum ArgRationale {

        // acceptsTempCopies
        CantTempCopy_HostArg_Ref
        CantTempCopy_HostArg_MutRef
        CantTempCopy_HostArg_Implicit

        // RESOLVE_byTempCopy
        CantTempCopy_FastFn
        CantTempCopy_NonCopiable
        CantTempCopy_ReturnedFromFn
    };


    // The solver state.

    let using mut ss:                   SolverState;
    mut _notes:                         SolverNotes;    // TODO DISJOINT move all these in the SolverState
    mut _current_fn:                    CurrentFn;
    let implicit mut _helpers:          Helpers[];      // TODO rename, this is the block helpers stack, unwinds during solve


    // Prep.

    ss.shortModuleName          = module.modid && getShortModuleName(module.fname);
    ss._spec_errors             = [ "BUG: Specializer reentry." ];
    ss.TODO_FIX_convert_args    = [ SolvedNode ];
    ss.TODO_FIX_convert_args[0].kind = "__convert";

    fn push(data: HelpersData)
    {
        let ret         = Helpers(index: _helpers_data.len);
        _helpers       ~= ret;
        _helpers_data  ~= data;
        return ret;
    }

    _scope.extended ~= Extended();  // global nodes and such
    push(HelpersData());            // not sure why this is needed


    //

    using inline fn GET(h: Helpers): HelpersData
    {
        return _helpers_data[h.index];
    }

    using fn EXT(target: Target)
    {
        if (target.locid)
            return [];

        let modid   = target.modid;
        let globid  = target.globid;

        shadow let _scope =
            modid == module.modid
                ? _scope
                : ctx.modules[modid].out.solve.scope;

        return _scope.extended.unless_oob(globid);
    }

    fn humanizeTypeName(type: Type)
    {
        if (type.isStruct)
            return lookupUserType(type).name;

        if (let itemType = tryClear_sliceable(type))
        {
            if (itemType == t_byte)
                return "string";

            return humanizeTypeName(itemType)
                ~ (type.TODO_FIX_isArray ? "[]" : "[:]");
        }

        if (type.canon == t_bool.canon)
            return "bool";
        if (type.canon == t_byte.canon)
            return "byte";

        return type.canon;
    }

    fn fail_appendStack(mut reason: string)
    {
        // What were we currently solving?
        mut callstack = 0;
        mut pass0: SolverPass;
        for (mut i = _helpers.len; i --> 0; )
        {
            let h = _helpers[i];
            if (h.isFnOrType)
            {
                if (!callstack++)
                    reason ~= "\n";

                let pass = (pass0 != (pass0 = h.pass) || callstack == 1) && h.pass ~ " ";
                reason ~= "\n                "[: (17 - pass.len).max(1)] ~ pass;

                let o = GET(h.target);
                reason ~= o;

                {
                    mut argsOut = "";

                    let args = EXT(h.target).args;
                    for (shadow mut i = 0; i < args.len; i++)
                    {
                        if (!argsOut)
                            argsOut ~= "(";
                        else
                            argsOut ~= ", ";

                        argsOut ~= humanizeTypeName(args[i].type);
                    }

                    if (argsOut)
                        reason ~= argsOut ~= ")";
                }

                let token = o.solved.token;
                if (token)
                    reason ~= " at " ~ formatTokenCoord(token, from: module.modid);
            }
        }

        return reason;
    }

    fn tryBacktrack(from: TokenIdx, v: string, k: ::kind = "id"): TokenIdx
    {
        mut here = from;
        while (here.tokidx --> 0)
        {
            let token = here._token;
            if (token.kind != k)
                break;

            if (token.value == v)
                return here;
        }

        return [];
    }

    fn fail(reason: string, backtrack!: string)
    {
        if (backtrack)
            _here = _here.tryBacktrack(backtrack) || _here;

        fail(reason);
    }

    fn fail(reason: string)
    {
        reason || BUG("fail(): No reason.");
        return FAIL(reason.fail_appendStack());
    }

    shadow fn BUG(mut reason?: string)
    {
        fail("COMPILER BUG:\n\n\t" ~ (reason || "Assertion failed."));
    }

    fn BUG(token: TokenIdx, reason: string)
    {
        _here = token;
        BUG(reason);
    }

    fn str(o: Overload)
    {
        let kind    = o.kind;
        mut prefix  = kind.str;
        if (kind == "var")
        {
            prefix = (o.flags & F_INJECTED && "injected ")
                   ~ (o.flags & F_IMPLICIT && "implicit ")
                   ~ (o.flags & F_REF && "ref ")
                   ~ (o.flags & F_ARG && "arg ")
                        || "var ";

            prefix.pop();
        }

        return prefix.qKW ~ " " ~ o.name.human.qID;
    }

    fn str(arg: Argument)
    {
        mut prefix = (arg.flags & F_INJECTED && "injected ")
                   ~ (arg.flags & F_IMPLICIT && "implicit ")
                   ~ (arg.flags & F_REF && "ref ");

        prefix ~= "arg";

        mut fn = "";
        if (arg.target)
        {
            let parent = arg.target.parent;
            if (parent != _current_fn.target)
                fn = GET(parent).name.human.qID ~ ":";
        }

        return prefix.qKW ~ " " ~ fn ~ arg.name.human.qID;
    }

    fn human(id: string)
    {
        let t = hacks::tryParseClosureID(:id).target;
        if (!t)
            return id;

        return GET(t.parent).name ~ ":" ~ GET(t).name;
    }

    fn makeNote(note: SolverNotes, inline reason?: string)
    {
        if (note & options.break_notes)
        {
            // TODO what i really want here is `lazy reason`,
            //  not `inline reason`, works but needs this workaround
            //   because i dont want the expression inlined twice.
            shadow let reason = reason;

            fail("`break_notes`: Unwanted event: " ~ note.str.qBAD
                ~ (reason ? "\n\t\t" ~ reason : "."));
        }

        _notes |= note;
    }


    // Public & private imports.

    fn _Scope_import__forceCopy(modid: i32): void
    {
        let s = ctx.modules[modid].out.solve.scope;

        _scope.items    ~= s.items   [: s.pub_items ];
        _scope.converts ~= s.converts[: s.pub_cnvrts];
    }

    fn _Scope_import__forceCopy_privates(modid: i32): void
    {
        let s = ctx.modules[modid].out.solve.scope;

        _scope.items    ~= s.items   [s.pub_items  :];
        _scope.converts ~= s.converts[s.pub_cnvrts :];
    }

    fn Scope_import(modid: i32)
    {
        _scope.imports.each(_ss.imports): |m|
            if (m == modid)
                return false;

        modid || BUG("Attempting to import modid-0.");
        _scope.imports ~= modid;
        _Scope_import__forceCopy(modid);
        return true;
    }

    fn Scope_import_privates(modid: i32): void
    {
        _scope.privates.each(_ss.privates): |m|
            if (m == modid)
                return;

        modid || BUG("Attempting to import_privates modid-0.");
        _scope.privates ~= modid;
        _Scope_import__forceCopy_privates(modid);
    }


    //

    fn isLocal(target: Target)
    {
        return !!target.locid;
    }

    fn parent(target: Target)
    {
        target.isLocal || BUG("Using .parent on a non-local");
        return Target(:target.modid, :target.globid, locid: 0);
    }

    fn localfn(index: i32)
    {
        return Target(:module.modid, globid: index, locid: 0);
    }

    fn isFnOrType(h: Helpers): bool
        !!(h.mask & (HM_Function | HM_Struct));

    using fn GET(target: Target)
    {
        let modid   = target.modid;
        let globid  = target.globid;
        let locid   = target.locid;

        shadow let _scope =
            modid == module.modid
                ? _scope
                : ctx.modules[modid].out.solve.scope;

        if (locid)
        {
            if (SELF_TEST && _scope.extended.len <= globid)
                BUG("Invalid local target -modid.");

            let locals = _scope.extended[globid].locals;

            if (SELF_TEST && locals.len < locid)
                BUG("Out of range local target from: " ~ GET(target.parent)
                    ~ "\n\tlocals=" ~ locals.len ~ "\n\tlocal=" ~ locid);

            return locals[locid - 1];
        }

        return _scope.overloads[globid - 1];
    }

    fn GET_mut(target: Target)
    {
        let globid  = target.globid;
        let locid   = target.locid;

        globid > 0 && target.modid == module.modid || assert();

        if (locid)
            return _scope.extended[globid].locals[locid - 1];

        return _scope.overloads[globid - 1];
    }

    fn EXT_mut(target: Target)
    {
        target.modid == module.modid || assert();
        return _scope.extended.grow_if_oob(target.globid);
    }

    fn GET_next_local_index()
    {
        let globid = _current_fn.target.globid;
        return globid
            && _scope.extended[globid].locals.len + 1;
    }

    fn nested(index: i32, from!: Target)
    {
        index > 0 || assert();
        return Target(:from.modid, :from.globid, locid: index);
    }

    fn nested(index: i32)
    {
        return nested(:index, from: _nestingFnort);
    }

    using fn EPH(target: Target)
    {
        return target.modid == module.modid
            && _ephemeral.unless_oob(target.globid);
    }

    fn EPH_mut(index: i32)
    {
        return _ephemeral.grow_if_oob(index);
    }

    fn EPH_mut(target: Target)
    {
        target.modid == module.modid || assert();
        return EPH_mut(target.globid);
    }

    fn localOf(target: Target)
    {
        if (target.isLocal)
            return target.globid;

        return target.local_of;
    }


    //


    // RemoteNode nonsense

    fn solved_set(target: Target, node: SolvedNode)
        target.GET_mut.solved = node;


    //

    fn SolvedNode(
        ::kind,
        type:       Type,
        flags?:     Flags,
        value?:     string,
        items?:     SolvedNode[],
        target?:    Target,
        helpers?:   Helpers)
    {
        return SolvedNode(
            :kind, :flags, :value,
            :items,
            :type, :target, token: _here,
            :helpers);
    }


    //

    fn Lifetime_fromNative(sig: [Node], args: [SolvedNode], actual: Type): Lifetime
    {
        sig.len + FN_ARGS_BACK == args.len || BUG("sig.len != args.len");

        let ret = sig[sig.len + FN_RET_BACK];
        mut mutref = ret.kind == "call" && ret.items.len == 1 && ret.value == "&mut";

        mut res: Type;
        for (;;)
        {
            for (mut i = 0; i < args.len; i++)
            {
                let inArg = sig[i];
                let annot = inArg.items[LET_TYPE];
                if (annot.items.len == 1 && ((annot.kind == "call"
                    && (!mutref && (annot.value == "&" || annot.value == "[:]") || annot.value == "&mut"))

                        // TODO FIX REMOVE OLD SLICE SYNTAX
                     || !mutref && annot.kind == "arrlit"))
                {
                    res && fail("Ambiguous __native lifetime.");

                    res = args[i].target.type;
                    res.lifetime || fail("Missing arg lifetime.");
                }
            }

            // Try again without the mutref,
            //  currently we have a bunch of drama related to case-patterns,
            //   the mutref annots actually come in the branches, not the arg annots.
            if (!mutref || res.lifetime)
                break;

            mutref = false;
        }

        res.lifetime.Lifetime_if_only(|locid| !!locid)
            || fail("Non-single-local __native lifetime.");

        // TODO FIX UNIQUENESS adding a static lifetime to ref results
        //  that are not assignable from the source argument,
        //   this coincides with container derefs currently -
        //
        // We only want to avoid attempts to move from there for now.
        //
        if (!isAssignable(host: actual, res))
        {
            let flatCount = actual.getFlatCount();

            if (TODO_FIX_static_ZSTs && !flatCount)
                return Lifetime_static();

            return Lifetime_makeShared(res.lifetime, :flatCount);
        }

        return res.lifetime;
    }

    fn TEST_Lifetime(lifetime: Lifetime,
        lax type!: Type,
        lax tempsOK!?: bool,
        lax argPositionsOK!?: bool): Lifetime
    {
        if (SELF_TEST)
        {
            if (!lifetime)
                BUG("TEST_Lifetime: empty lifetime");

            mut first       = true;
            mut hasStatic   = false;
            mut lastLocid   = 1000000;
            mut lastArgIdx  = 1000000;

            lifetime.Lifetime_each: |locid, isStatic, isTemp, isArgIdx, argidx, paths|
            {
                !hasStatic      || BUG("TEST_Lifetime: static is not last");
                if (isStatic)
                    hasStatic = true;

                //
                if (isTemp) {
                    tempsOK     || BUG("TEST_Lifetime: unexpected temporary");
                    first       || BUG("TEST_Lifetime: temporary is not first");
                }

                first = false;

                //
                if (locid) {
                    !argPositionsOK         || BUG("TEST_Lifetime: unexpected locid");
                    lastArgIdx == 1000000   || BUG("TEST_Lifetime: local after argpos");
                    lastLocid > locid       || BUG("TEST_Lifetime: locid out of order");
                    lastLocid = locid;
                }

                //
                if (isArgIdx) {
                    argPositionsOK          || BUG("TEST_Lifetime: unexpected argidx");
                    lastLocid == 1000000    || BUG("TEST_Lifetime: argidx after local");
                    lastArgIdx > argidx     || BUG("TEST_Lifetime: argidx out of order");
                    lastArgIdx = argidx;
                }

                //
                if (isStatic || isTemp)
                    paths == "\x00\x00" || BUG("TEST_Lifetime: static/temp paths != x00x00");
                else
                    assertPathsValid(paths,
                        expect_flatCount: type.getFlatCount(),
                        region_flatCount: locid
                            ? nested(locid).type.getFlatCount()
                            : -1);
            }
        }

        return lifetime;
    }

    lax fn TEST_varLifetime(lax lifetime: Lifetime, lax staticOK!?: bool, lax locid!expect?: i32) =
    {
        if (SELF_TEST && !lifetime.Lifetime_if_only(
                |locid, isStatic|
                    locid && (!expect || locid == expect)
                        || isStatic && staticOK))
        {
            BUG("Bad local lifetime: " ~ lifetime);
        }
    }

    fn Lifetime_fromBinding(target: Target, flatCount: i32): Lifetime
    {
        target.locid || target.modid == module.modid || BUG("not from this module");

        // Local?
        let locid = target.locid;
        if (locid && (flatCount || !TODO_FIX_static_ZSTs))
            return Lifetime_from(:locid, :flatCount);

        // Else static.
        return Lifetime_static();
    }


    //

    fn str(lifetime: Lifetime)
    {
        mut str = "";

        lifetime.Lifetime_each: |locid, isStatic, isTemp, isArgIdx, argidx, paths|
        {
            if (str) str ~= "|";

            str ~= locid        ? nested(locid).str
                 : isStatic     ? "static".qLT
                 : isTemp       ? "temp".qLT
                 : isArgIdx     ? "arg#" ~ argidx
                                : BUG("invalid region");

            mut offset = 0;
            paths.lifetime::walkPaths(:offset,
                onPathStart:        ||                      str ~= " [",
                onPathDone:         |isLastPath|            str ~= isLastPath ? " ]" : " ],",
                onSubRegion:        |flatCount, flatOffset, isLastSubRegion|
                    str ~= " #" ~ flatCount ~ " @" ~ flatOffset ~ (isLastSubRegion ? "" : ","),
            );
        }

        return str;
    }

    fn Lifetime_replaceArgsAtCallsite(target: Target, argNodes: [SolvedNode]): Lifetime
    {
        return target.type.lifetime.Lifetime_process(
            each: |isStatic, isTemp, locid, argidx, paths,
                continue_keep,
                continue_replace|
            {
                if (isStatic)
                    continue_keep();

                if (isTemp || locid)
                    BUG("Lifetime_replaceArgsAtCallsite: Found a temp or locid.");

                let argNode = argNodes[argidx];
                let argLt   = argNode.type.is_ref
                    ? argNode.type.lifetime
                    : Lifetime_temporary();

                continue_replace(
                    Lifetime_op_join(argLt, paths));
            });
    }


    //

    fn autoshadow(ref shadows: bool, local_of: i32, id: string)
    {
        if !(_current_fn.autoshadow_ok)
            return;

        if (!shadows && local_of && shouldAutoshadow(id))
            shadows = true;
    }

    fn shouldAutoshadow(id: string)
    {
        if (!OPTI_autoshadow)
            return false;

        _scope.items.each(_ss.items): |item, i|
            if (i >= _root_scope.items_len)
                if (item.id == id)
                    return false;

        return true;
    }

    fn Binding(id: string, mut type: Type, flags!: Flags, ref shadows!: bool)
    {
        mut name        = id;
        let local_of    = _current_fn.target.globid;

        // Unique identifiers.
        if (_root_scope)
        {
            // LEAKY TEMPLATES, part 1:
            //  All locals are F_SHADOW - this is a usability thing really,
            //   otherwise you'd simply have to `shadow` everything manually.
            //
            // Actually turning this on for everything -
            //  it might optimize scope lookups all over the place.
            //
            autoshadow(:shadows, :local_of, :id);
        }

        // Reserve the slot.
        let target = Scope_create(_scope, kind: "var", :name, :flags, nest:local_of);

        // Setup the lifetime for references to this binding.
        ref overload = GET_mut(target);
        {
            let lifetime = Lifetime_fromBinding(target, type.getFlatCount());

            ///////////////////////////////////////////////////////////////
            // Throw away argument lifetime, union below will fix it up. //
            // SHALLOW LIFETIMES: Now we do this for all refs.           //
            // if (flags & F_ARG) /////////////////////////////////////////
            type.lifetime = Lifetime(); ///////////////////////////////////
            ///////////////////////////////////////////////////////////////

            overload.type = flags & F_MUT
                ? add_mutref(type, lifetime)
                : add_ref   (type, lifetime);
        }

        return target;
    }

    fn createTemplate(node: Node): Template
    {
        return Template(
            node,
            imports:   !_current_fn && _scope.imports);
    }


    //

    fn createDefinit(type: Type): SolvedNode
    {
        if (type.is_ref)
        {
            if (CANNOT_definit_mutrefs && type.is_mutref)
                BUG("createDefinit: Cannot definit a mutref: " ~ type.humanizeType(lt: true));
            if (!type.lifetime.hasStatic)
                BUG("createDefinit: Cannot definit a non-static reference: " ~ type.humanizeType(lt: true));
        }

        // TODO FIX several issues, most trivial,
        //  importantly we have to start adding AlwaysTrue/AlwaysFalse to numeric literals,
        //   so there's a bit of fiddling i'm leaving for later
        //
        // if !(type.vfacts & AlwaysFalse)
        //     BUG("createDefinit: Missing vfacts.AlwaysFalse: " ~ type.humanizeType(lt: true));

        // TODO FIX this is backwards, its not always practical -
        //  tryRetype just switches the type but doesn't switch from definit to int/real lit.
        //   what'd be more useful is to have int & real literals snap to definit instead of these two.
        //
        if (type.is_integral)
            return SolvedNode(kind: "int", :type, value: "0");

        if (type.is_floating_pt)
            return SolvedNode(kind: "real", :type, value: "0");

        if (type.is_boolean)
            return createBool(value: "false", :type);

        return SolvedNode(kind: "definit", :type);
    }

    fn solveDefinit(type: Type): SolvedNode
    {
        return createDefinit(definitType(:type));
    }

    fn getModule(modid!: i32)
    {
        if (modid == module.modid)
            return module;

        return ctx.modules[modid];
    }

    fn trimmedName(shadow module: Module)
    {
        let fname = module.fname;

        mut start = 0;
        mut end   = fname.len;

        for (mut i = end; i --> 0; )
        {
            let c = fname[i];
            if (c == '/')
            {
                start = i + 1;
                break;
            }

            if (c == '.')
                end = i;
        }

        return fname[start : end];
    }

    fn stableTypeID(type: Type)
    {
        // TODO FIX - we dont want this -
        //  we want quals & vfacts serialized as masks,
        //   and a type "shape" string, which basically the type structure,
        //    without any targets/indices/whatever inside.
        //
        // This is a better approximation than serializeType,
        //  which puts a bunch of indices in,
        //   which thrashes cpp output too often.
        //
        return humanizeType(type);
    }

    fn humanizeType(type: Type, mut lt!?: bool, mut no_quals!?: bool, mut usage!?: bool, lax i!?: int, diff!?: Type)
    {
        if (diff)
        {
            // TODO now that we're taking the comparison type
            //  these can become more granular,
            //   and we can emphasize the exact differences
            no_quals    = (type.quals & q_TAGS)  == (diff.quals & q_TAGS);
            usage       = (type.quals & q_USAGE) != (diff.quals & q_USAGE);
            lt          =  type.lifetime         !=  diff.lifetime;
        }

        mut result = humanizeTypeName(type);

        if (!no_quals)
            result ~= humanizeQuals(type.quals);

        if (usage)
        {
            shadow mut usage = type.quals & q_USAGE;
            mut offset = -3;

            result ~= " { ";
            while (usage)
            {
                if (usage & 1)
                    result ~= "#" ~ offset ~ " ";

                usage >>= 1;
                offset++;
            }
            result ~= "}";
        }

        if (lt && type.lifetime)
            result ~= "`" ~ type.lifetime;

        if (type.vfacts)
            result ~= " " ~ type.vfacts;

        return result;
    }

    fn explainTypeDiff(a: Type, b: Type, sep = "<->")
    {
        return humanizeType(a, diff: b)
             ~ " " ~ sep ~ " "
             ~ humanizeType(b, diff: a);
    }

    fn str(n: SolvedNode)
    {
        mut src = n.kind.str.qKW;

        if (n.kind == "call" || n.kind == "let" || n.kind == "letdef")
            src ~= "(" ~ n.target ~ ")";
        else if (n.value)
            src ~= "(" ~ n.value.qID ~ ")";

        if (n.type)
            src ~= " -> " ~ humanizeType(n.type);

        if (n.items.len == 1)
            src ~= " { " ~ n.items.only ~ " }";
        else if (n.items.len > 0)
            src ~= " { " ~ n.items.len ~ " }";

        return src;
    }


    //

    fn solveTypeCast(node: Node): SolvedNode
    {
        let left   = node.items[0];
        let right  = node.items[1];

        // left -> right.
        let expect = evalTypeAnnot(right);
        mut actual = solveNode(left, expect);

        //
        convertIfNeeded(:actual, :expect, "Cannot convert: ");
        return actual;
    }

    fn solveTypeAssert(node: Node): SolvedNode
    {
        mut typeParams0 = steal(_typeParams);
        defer swap(_typeParams, typeParams0);

        return createBool(evalTypePattern(node));
    }


    //

    fn reorderByNumUsings(
        ref reorder: Reorder,
        host_args: Argument[], num_args: i32, num_usings!: i32)
    {
        reorder.map.clear();

        if (num_usings)
        {
            for (mut i = 0; i < host_args.len; i++)
            {
                let x = i - num_usings;
                reorder.map.push(
                    x >= 0 && x < num_args ? x : -1);
            }
        }

        reorder.applicable = !!reorder.map;
    }

    fn reorderByArgIDs(
        ref reorder: Reorder,
        names: string[], mut optional: bitset::BitSet,
        host_args: Argument[], num_usings!: i32): bool
    {
        reorder.applicable = true;
        reorder.map.clear();

        //
        mut used = 0;
        mut offset = 0;
        mut usings_left = num_usings;

        for (mut i = 0; i < host_args.len; i++)
        {
            mut idx = names.find(host_args[i].name);
            if (idx < 0)
            {
                if (usings_left > 0)
                {
                    usings_left--;
                }
                else
                {
                    for (shadow mut i = offset; i < names.len; i++)
                    {
                        offset++;
                        if (!names[i])
                        {
                            idx = i;
                            break;
                        }
                    }
                }
            }
            else
            {
                used++;
                optional.rem(idx);
            }

            reorder.map.push(idx);
        }

        usings_left && BUG("reorderByArgIDs: usings_left != 0");

        // Fail if some name ended up unused.
        //  TODO FIX THIS MESS
        if (used != names.len)
        {
            for (mut i = 0; i < names.len; i++)
                if (!names[i])
                    used++;

            if (used + optional.popcount != names.len)
                return false;
        }

        // Drop trailing misses.
        {
            mut trailing_misses     = 0;
            mut non_trailing_misses = 0;
            for (mut i = reorder.map.len; i --> 0; )
            {
                if (reorder.map[i] >= 0)
                {
                    for (; i --> 0; )
                        if (reorder.map[i] < 0)
                            non_trailing_misses++;

                    break;
                }

                trailing_misses++;
            }

            let trailing_usings = (num_usings - non_trailing_misses).max(0);

            // We dont want to drop trailing usings,
            //  dont remember why we do this at all but the idea is
            //   to only drop defaulted arguments & implicits.
            //
            if (trailing_misses > trailing_usings)
                reorder.map.shrink(
                    reorder.map.len - (
                        trailing_misses - trailing_usings));
        }

        // See if needed.
        if (reorder.map.len != names.len)
            return true;

        for (mut i = 0; i < reorder.map.len; i++)
            if (reorder.map[i] != i)
                return true;

        // Matches but no need for the reorder stuff.
        reorder.clear();

        return true;
    }

    noinline fn ERRMSG_findUnmatchedArgName(reorder: Reorder, names: string[])
    {
        mut used: bitset::BitSet;
        for (mut i = 0; i < reorder.map.len; i++)
        {
            let pos = reorder.map[i];
            if (pos >= 0)
                used.add(pos);
        }

        names.each: |name, i|
        {
            if (used.has(i))
                continue;

            mut count = 0;
            mut first = names.len;

            names.each: |n, shadow i|
                if (n == name)
                    if (!count++)
                        first = i;

            if (first < i)
                return "Duplicate explicitly named arguments: " ~ count.str.qBAD ~ " args named " ~ names[i].qBAD ~ ".";

            return "Explicit named argument mismatch: no arg " ~ names[i].qBAD ~ ".";
        }

        return "Explicit argument name related error.\n\n\tBUG failed to explain what's wrong.";
    }

    fn findRestStart(ext: Extended)
    {
        for (mut i = ext.args.len; i --> 0; )
        {
            let arg = ext.args[i];
            if  (arg.flags & F_REST_ARG) return i;
            if !(arg.flags & F_IMPLICIT) break;
        }

        return ext.args.len;
    }

    fn tryMatch__mutargs(
        mut id: string,
        ref reorder!reorder_out: Reorder,
        ref conversions!conversions_out: Target[][],
        ref error!: string,
        local_scope!?: bool,
        misc_scope!?: Scope,
        args?: [SolvedNode],
        flags!?: Flags, target!?: Target): Target
    {
        let error_len0 = error.len;

        if (SELF_TEST)
            for (mut i = 0; i < args.len; i++)
                if (!args[i].kind)
                    BUG("Falsy arg.kind!");

        mut matchIdx: Target;
        mut ambigOkIdx: Target;

        fn countUsings()
        {
            shadow let scope = local_scope ? _scope : misc_scope;

            mut count = 0;
            if (scope.usings)
                scope.usings.each(local_scope && _ss.usings, |u| u ? count++ : BUG());

            return count;
        }

        mut minArity        = args.len;
        let numUsings       = countUsings();
        let explicitArity   = minArity;
        let maxArity        = explicitArity + numUsings;

        // Prep labelled args for remap.
        mut names: string[];
        mut optional: bitset::BitSet;
        if (flags & F_NAMED_ARGS)
        {
            mut some = false;

            for (mut i = 0; i < args.len; i++)
            {
                let arg = args[i];
                names.push(arg.kind == "argid"
                    ? { some = true; arg.value } || BUG()
                    : "");

                if (arg.flags & F_OPT_ARG)
                {
                    minArity--;
                    optional.add(i);
                }
            }

            some || BUG();
        }

        mut reusable_mangle: string;

        // Argument & `using` dependent lookup,
        //  basically we do everything we can to get rid of imports.
        //
        // THIS LOOKS WORSE THAN IT IS:
        //  We only pushback stuff when the modules are not imported and there's an actual match,
        //   and we could possibly further filter them by arity.
        //
        mut extra_items: Target[];
        if (local_scope && !target)
        {
            mut seen: bitset::BitSet;

            fn visitTypeImports(type: Type)
            {
                let visit = type.lookupTypeImports();
                for (mut i = -1; i < visit.len; i++)
                {
                    let modid = i >= 0 ? visit[i] : type.modidOfOrigin;
                    if (seen.has(modid))
                        continue;

                    // Lazy init -
                    //  we want to ignore self and all imports,
                    //   and everything we've already traversed.
                    if (!seen)
                    {
                        seen.add(0);
                        seen.add(module.modid);
                        _scope.imports.each(
                            local_scope && _ss.imports,
                                |shadow modid| seen.add(modid));
                    }

                    if (!seen.add_once(modid))
                        continue;

                    //
                    let s = ctx.modules[modid].out.solve.scope;
                    for (shadow mut i = 0; i < s.pub_items; i++)
                        if (s.items[i].id == id)
                            extra_items.push(s.items[i].target);
                }
            }

            // Usings.
            if (numUsings)
                (local_scope ? _scope : misc_scope).usings.each(
                    local_scope && _ss.usings,
                        |u| visitTypeImports(GET(u).type));

            // Field access, method calls & operator calls.
            //  TODO no way to opt-out of this for operators currently,
            //   consider regular id-names for all ops, so we can freefn call them.
            if (flags & (F_ACCESS | F_METHOD | F_OPERATOR))
                for (mut i = 0; i < args.len; i++)
                    visitTypeImports(args[i].type);
        }

        // TODO the whole field_items thing is a mess,
        //  we really need a cleaner way to put these things up.
        let considerFieldItems = local_scope && !target
            && (flags & F_ACCESS || !minArity)
            && minArity <= 1 && maxArity;

        fn field_items = considerFieldItems && _field_items;

        //
        mut alternate_ids: string[];

        ///////////////////////////////////
        mut conversions: Target[][];
        mut reorder: Reorder;
        ///////////////////////////////////

        //
        for (;;)
        {
            mut scope_iterator: i32;
            mut overloadIdx: Target;

            //
            inline fn _SCOPE = flags & F_IMPLICIT ? _scope.implicits : _scope.items;
            inline fn _SSKIP = flags & F_IMPLICIT ? _ss.implicits    : _ss.items;

            !local_scope && (extra_items || field_items) && BUG(
                "!local_scope but extra_items or field_items");

            //
            mut shadows: bool;
            :SHADOWING_GROUP while (overloadIdx =
                target
                    ? search(dont_search_just_return: target, scope_iterator)
                    : local_scope
                        ? _SCOPE.search(id, scope_iterator, scope_skip: _SSKIP, :extra_items, :field_items, :shadows)
                        : misc_scope.items[: misc_scope.pub_items].search(id, scope_iterator))
            {
                !local_scope && shadows && BUG("!local_scope but shadows");

                //
                mut TODO_FIX_dontBotherSpecializing = false;

                ///////////////////////////////////
                conversions.clear();
                reorder.clear();
                ///////////////////////////////////

                fn matchFail(inline err: string)
                {
                    if (error)
                        error ~= "\n\n\t" ~ overloadIdx.explainWhichFn ~ "\n\t    " ~ err;

                    continue :SHADOWING_GROUP;
                }

                // Make sure we know what this is.
                ensureLazySolved(overloadIdx);

                let overload = GET(overloadIdx);

                let kind    = overload.kind;
                let isType  = kind == "type";

                ////////////////////////////////////////////
                // Conversions / typename aliases.
                if (minArity && isType && !target)
                {
                    let alt = overload.type.canon;
                    if (alt != id) // e.g. i32
                        alternate_ids.push(alt);
                }
                ////////////////////////////////////////////

                // Arity check.
                let arity = overloadIdx.EXT;
                let isZeroInit = isType && !explicitArity;
                if (!isZeroInit && (arity.max < minArity || arity.min > maxArity))
                {
                    fn str(min: i32, max: i32)
                        min != max  ? "[" ~ min ~ " upto " ~ max ~ "]"
                                    : min.str;

                    if (arity.min > arity.max)
                    {
                        // This borders on a compiler bug -
                        //  but this is the best I can currently do,
                        //
                        matchFail("Declaration cycle, signature not yet available."
                                ~ "\n\n\t    To fix this, you might need to shuffle functions around"
                                    ~ "\n\t\tuntil every dependency (type annot or arg default expr)"
                                    ~ "\n\t\tof " ~ overloadIdx ~ " is declared above it."
                                ~ "\n\n\t    This borders on a compiler bug, sorry about it,"
                                    ~ "\n\t\twe gotta come up with a better solve order algorithm.");
                    }

                    matchFail("Wrong number of arguments: expects " ~ str(:arity.min, :arity.max)
                            ~ ", got " ~ str(minArity, maxArity) ~ ".");
                }

                // Reorder by argument names or number of implicit `using` args.
                let host_args   = arity.args;
                let num_usings  = !isZeroInit && arity.min > explicitArity
                                && arity.min - explicitArity;

                if (!names)
                    reorderByNumUsings(:reorder, host_args, args.len, :num_usings);
                else if (!reorderByArgIDs(:reorder, names, optional, host_args, :num_usings))
                    matchFail(ERRMSG_findUnmatchedArgName(:reorder, :names));

                // Forbid optional argument ambiguities -
                //  We should either have all optional args satisfied at the receiver or sender part,
                //   we shouldn't allow dangling cables on both ends because that's super typo-prone.
                //
                if (optional && reorder)
                    if (reorder.map.len < args.len && reorder.map.len < arity.max)
                        matchFail("Optional argument ambiguity, not all optional arguments provided, and not all callsite arguments used. Cannot distinguish from a typo. [TODO LIST MISSING ARGS]");

                // TODO FIX the two reorder fns don't deal correctly with rest args,
                //  this seems to fix it but honestly I'm not sure
                //   if it can deal with the rest of the arg-related stuff.
                //
                mut REST_TYPE: Type;
                let REST_START = arity.findRestStart();
                if (REST_START < host_args.len)
                    if (reorder && reorder.map.len < args.len)
                        for (mut i = 0; i < args.len; i++)
                            if (!optional.has(i) && !reorder.map.has(i))
                                reorder.map ~= i;

                let N = (reorder ? reorder.map.len : args.len)
                    .max(!isZeroInit && arity.min);

                if (N)
                {
                    if (REST_START < N)
                    {
                        let expect = host_args[REST_START].type;
                        if (expect)
                            REST_TYPE = tryClear_sliceable(expect) || fail(
                                overloadIdx.name
                                    ~ ": Rest argument annotation is not an array: "
                                    ~ humanizeType(expect));
                    }

                    reorder.map.len >= args.len || !reorder || optional || BUG(
                        "reorder < args:\n\t\treorder=" ~ reorder.map.len ~ "\n\t\t#args=" ~ args.len);

                    :ARG_OK
                    for (mut i = 0; i < N; i++)
                    {
                        let rest        = i >= REST_START;
                        let host_arg    = host_args[rest ? REST_START : i];
                        let expect      = rest ? REST_TYPE : host_arg.type;

                        // Its either reorder or args, asserted above [^].
                        let callsiteIndex   = reorder       ? reorder.map[i]
                                            : i < args.len  ? i
                                            : /*using*/ -1;

                        if (callsiteIndex < 0)
                        {
                            // Argument may not be defaulted -
                            //  we might be supplying defaults via names
                            //   before we've actually exhausted
                            //    all the non-defaulted stuff.
                            //
                            if (host_arg.default || host_arg.flags & F_IMPLICIT)
                                continue :ARG_OK;

                            // Usings - can't match on explicitly named arguments.
                            if !(host_arg.flags & F_MUSTNAME || flags & F_CONVERSION)
                            {
                                // Can't proceed if we don't know what we're looking for.
                                //  If we decide to not support more than a single using,
                                //   we could simply assume it's a match here.
                                //
                                if (expect)
                                {
                                    let conversion = tryConvert(:misc_scope, :local_scope, :expect);
                                    if (conversion)
                                    {
                                        conversions.grow_if_oob(i) = conversion;
                                        continue :ARG_OK;
                                    }
                                }
                            }

                            matchFail("Cannot infer missing " ~ host_arg);
                        }

                        // Explicit argname requirements.
                        if (host_arg.flags & F_MUSTNAME)
                        {
                            if (names.len <= callsiteIndex || !names[callsiteIndex])
                                matchFail(host_arg ~ " must be :explicitly named.");
                        }

                        // Autocall.
                        if (host_arg.autocall)
                        {
                            mut autocall_args:          SolvedNode[];
                            mut autocall_reorder:       Reorder;
                            mut autocall_conversions:   Target[][];

                            autocall_args.resize(1);
                            autocall_args[0] = args[callsiteIndex];

                            mut autocall_error = error
                                && "Cannot match " ~ host_arg ~ " autocall " ~ host_arg.autocall.qCODE ~ ": ";

                            PROFILE(.TryMatch_Autocall);

                            let t = tryMatch__mutargs(

                                // TODO allow autocalls to be fully::qualified,
                                //  in which case we'd be doing `local_scope: false`, and
                                //   `misc_scope: modules[autocall_modid].items` here instead
                                local_scope: true,

                                id: host_arg.autocall, args: autocall_args, flags: F_ACCESS,
                                reorder: autocall_reorder, conversions: autocall_conversions,
                                error: autocall_error);

                            if (!t)
                                matchFail(autocall_error.replace("\t", "\t\t"));

                            if (autocall_conversions)
                                conversions.grow_if_oob(i) ~= autocall_conversions.only;

                            conversions.grow_if_oob(i) ~= t;
                            autocall_reorder.map.len < 2 || BUG("autocall: reorder");
                        }

                        // Actual arg type.
                        let hasConv = conversions.len > i && conversions[i].len;
                        let actual = hasConv
                            ? GET(conversions[i].last).type
                            : args[callsiteIndex].type;

                        if (actual.is_never)
                        {
                            // Converting to never means no point in going further,
                            //  the caller node will never call this.
                            if !(host_arg.flags & F_INLINE)
                                TODO_FIX_dontBotherSpecializing = true;

                            continue :ARG_OK;
                        }

                        // Template arguments.
                        if (!expect)
                        {
                            // TODO FIX Check that ref args are mutrefs,
                            //  otherwise we get mustMatch fails after a spec-ok.
                            if (host_arg.flags & F_REF && !actual.is_mutref)
                                matchFail(host_arg ~ " expects a mutref, got " ~ humanizeType(actual));

                            // Might as well do the exact same thing here.
                            if (host_arg.flags & F_TYPENAME && !(actual.vfacts & Typename))
                                matchFail(host_arg ~ " expects a type, got a value: " ~ humanizeType(actual));

                            continue :ARG_OK;
                        }

                        if (isAssignableAsArgument(expect, actual || BUG("tryMatch: !actual")))
                            continue :ARG_OK;

                        /////////////////
                        // Literal fixup.
                        if (!hasConv)
                        {
                            let        arg = args[callsiteIndex];
                            shadow let arg = arg.kind == "argid"
                                ? arg.items.only
                                : arg;

                            let retype = tryRetyping(arg, expect);
                            if (retype && isAssignableAsArgument(expect, retype))
                                continue :ARG_OK;
                        }
                        //        /LITFIX
                        /////////////////

                        // Go through conversions here.
                        if !(flags & F_CONVERSION)
                        {
                            let conversion = tryConvert(:misc_scope, :local_scope, :expect, :actual, retype: !hasConv && args[callsiteIndex]);
                            if (conversion)
                            {
                                conversions.grow_if_oob(i) ~= conversion;
                                continue :ARG_OK;
                            }
                        }

                        // Nope, args fail.
                        matchFail(host_arg  ~ " expects " ~ humanizeType(expect)
                                            ~ ", got "    ~ humanizeType(actual));
                    }

                    if (REST_START < N)
                    {
                        for (mut i = REST_START; i < N; i++)
                        {
                            let hasConv         = conversions.len > i && conversions[i].len;
                            let callsiteIndex   = reorder ? reorder.map[i] : i;
                            let actual          = hasConv
                                ? GET(conversions[i].last).type
                                : args[callsiteIndex].type;

                            // TODO FAILCASE
                            // TODO FAILCASE no coverage for never items here,
                            // TODO FAILCASE  trivial to fix, replace with superType_neverOK
                            REST_TYPE = i == REST_START
                                ? solveArrlit_itemType_init(head: actual)
                                : type_trySuper(REST_TYPE, actual)
                                    || matchFail("Rest arguments have no common supertype: "
                                                             ~ humanizeType(REST_TYPE)
                                                    ~ " <- " ~ humanizeType(actual));
                        }

                        REST_TYPE = solveArrlit_done(itemType: REST_TYPE);
                    }
                }

                // Specialize.
                if (kind == "template" && !TODO_FIX_dontBotherSpecializing)
                {
                    mut cant_reuse: string;

                    shadow ref args_mangled =
                        (reorder || conversions
                            ? cant_reuse : reusable_mangle);

                    let specIdx = trySpecialize(
                        :overloadIdx, :args, :reorder,
                        :conversions, :args_mangled,
                        :REST_START, :REST_TYPE);

                    if (specIdx.is_SPECFAIL)
                        matchFail(_spec_errors[specIdx._packed.u32.i32] || "Could not specialize.");

                    ensureLazySolved(overloadIdx = specIdx);
                }

                // TODO FIX: we allow ambig among overloads that will be dead-code eliminated by the callsite,
                //  but we don't ignore them when we're about to match something for real.
                if (ambigOkIdx && !TODO_FIX_dontBotherSpecializing)
                    matchIdx = ambigOkIdx;

                // Forbid ambiguity.
                if (matchIdx)
                {
                    fn fnName(idx: i32) idx
                        ? localfn(index: idx).str
                        : "global scope";

                    let PREV        = matchIdx;
                    let NEXT        = overloadIdx;

                    if (SELF_TEST)
                    {
                        let inner       = PREV.localOf;             // first to match is innermost scope
                        let outer       = NEXT.localOf;             //  what we're currently looking is upscope
                        let callsite    = _current_fn.target.globid;//   as seen from where we currently are

                        mut _c = callsite;
                        while (_c > inner) _c = localfn(index: _c).localOf;
                        _c == inner || BUG(
                            "Leaking `" ~ id ~ "` between functions [inner/callsite]: "
                                ~ inner.fnName ~ "::" ~ PREV
                                ~ " is seen from " ~ callsite.fnName);

                        mut _i = inner;
                        while (_i > outer) _i = localfn(index: _i).localOf;
                        _i == outer || BUG(
                            "Leaking `" ~ id ~ "` between functions [inner/outer]: "
                                ~ inner.fnName ~ "::" ~ PREV ~ " and "
                                ~ outer.fnName ~ "::" ~ NEXT
                                ~ " as seen from " ~ callsite.fnName);
                    }

                    fail("Ambiguous " ~ (id ? "call to " ~ id.qBAD : "callsite") ~ ", matches multiple items in scope:\n"
                        ~ "\n\t" ~ explainWhichFn(PREV, conversions_out)
                        ~ "\n\t" ~ explainWhichFn(NEXT, conversions    ));
                }

                // Done!
                if (TODO_FIX_dontBotherSpecializing)
                    ambigOkIdx = overloadIdx;
                else
                    matchIdx = overloadIdx;

                // Output conversions /////////////
                swap(reorder,     reorder_out    );
                swap(conversions, conversions_out);
                ///////////////////////////////////

                // Arity 0 auto-shadows.
                if (shadows)
                    break :SHADOWING_GROUP;
            }

            //////////////////////////////////
            // Conversions / typename aliases.
            if (!alternate_ids)
                break;

            id = alternate_ids.last;
            alternate_ids.pop();
            //////////////////////////////////
        }

        // Not defined msg.
        if (error && error.len == error_len0 && !matchIdx)
            error ~= id.isNotDefinedHere;

        return matchIdx || ambigOkIdx;
    }

    fn isNotDefinedHere(id: string)
        id.qID ~ " is not defined here.";

    //

    fn couldRetype(node: SolvedNode): bool
    {
        return node.kind == "int"
            || node.kind == "real"
            || node.kind == "definit"
            || node.kind == "str"
            || node.kind == "if"  && node.items[1 : 3].all(fn couldRetype)
            || node.kind == "block" && !(node.helpers.mask & HM_LabelUsed) && node.items.last.couldRetype;
    }

    fn tryRetyping(node: SolvedNode, expect: Type): Type
    {
        if (node.is_arithmetic && expect.is_arithmetic)
        {
            if (node.kind == "int")
                return solveInt(node.value, expect);

            if (node.kind == "real")
                return solveReal(node.value, expect);
        }

        if (node.kind == "definit")
            return definitType(expect);

        if (node.kind == "str")
            return solveString(node.value, expect);

        if (node.kind == "if")
        {
            let left  = tryRetyping(node.items[1], expect);
            let right = tryRetyping(node.items[2], expect);
            return left && right
                && type_trySuper(left, right);
        }

        if (node.kind == "block")
            return !(node.helpers.mask & HM_LabelUsed)
                && tryRetyping(node.items.last, expect);

        return [];
    }

    fn applyRetype(ref node: SolvedNode, retype: Type)
    {
        if (node.kind == "if")
        {
            applyRetype(node.items[1], retype);
            applyRetype(node.items[2], retype);
        }
        else if (node.kind == "block")
        {
            node.helpers.mask & HM_LabelUsed && BUG(
                "Trying to retype a labelled block, we cant do this still.");

            applyRetype(node.items.last, retype);
        }

        node.type = retype;
    }


    //

    fn token(target: Target)
    {
        return target.template.node.token
            || target.solved.token;
    }

    fn explainWhichFn(t: Target, conversions?: Target[][], backtrack!?: string, fmt = NoContext)
    {
        mut result = t.str;

        if (t.flags & F_INJECTED)
        {
            // Token of origin is the first callsite that incurred this injected argument,
            //  but it could be used by multiple additional callsites further down,
            //   so the token/snippet is pretty arbitrary.
            //
            // It's also not really useful in explaining what the argument is,
            //  because it's implicit, and usually not mentioned in the snippet at all.
            //
            result ~= "\n";
        }
        else
        {
            result ~= " at " ~ t.token.addr_and_snippet(:fmt, :backtrack);

            for (mut i = 0; i < conversions.len; i++)
            {
                let c = conversions[i];
                if (c)
                    result ~= explainConversion(c,
                        prefix: t.args.len > 1 && t.args[i] ~ ": ");
            }
        }

        return result;
    }

    fn explainConversion(shadow path: [Target], prefix!?: string)
    {
        mut res = "";
        for (mut i = 0; i < path.len; i++)
        {
            if (!i) res ~= "\n";
            res ~= "\t    ";
            if (!i && prefix) res ~= prefix;
            res ~= "using".qKW ~ " ";
            res ~= path[i].explainWhichFn(backtrack: "using");
        }

        return res;
    }


    //

    fn make_field_reference(from: Type, field: Overload)
    {
        using let _ = field_unpackOffset(field);

        return make_field_reference(

            to:         field.type,
            quals:      (from || BUG()).quals,
            lifetime:   TODO_FIX_static_ZSTs && !memberFlatCount
                ? Lifetime_static()
                : from.lifetime,

            :memberFlatCount,
            :memberFlatOffset);
    }

    fn tryConvert(
        expect: Type, actual?: Type, retype?: SolvedNode,
        misc_scope!?: Scope, local_scope!: bool): Target[]
    {
        PROFILE(.TryConvert);

        mut match:  Target[];
        mut path:   Target[];

        let has_converts    = (local_scope ? _scope : misc_scope).converts.len;

        ////////////////////////////////////
        mut arg0 = TODO_FIX_convert_args[0];

        mut TODO_FIX_reorder: Reorder;
        mut TODO_FIX_conversions: Target[][];
        ////////////////////////////////////

        fn descend(from: Type, nullary!: bool, isStruct!: bool, root?: bool)
        {
            fn foreach(t: Target)
            {
                //////////////////////////////////////////////////
                mut arg0type0 = TODO_FIX_convert_args[0].type;

                if (!nullary)
                {
                    // Decidability [A]:
                    //
                    // Enforce strict ordering of conversion functions -
                    //  they can still solve out of order, but you can't use the syntax sugar
                    //   before the `using` declaration. Makes everything way simpler.
                    //
                    // Obsoleted by Decidability [C] below.
                    //
                    // let here = _current_fn.target.globid;
                    // if (here && t.index > here && t.modid == module.modid && t.local_of != here)
                    //     return;

                    if (root && retype)
                        TODO_FIX_convert_args[0] = retype;
                    else
                        TODO_FIX_convert_args[0].type = from;
                }

                defer if (!nullary)
                {
                    if (root && retype)
                        TODO_FIX_convert_args[0] = arg0;
                    else
                        TODO_FIX_convert_args[0].type = arg0type0;
                }
                //////////////////////////////////////////////////

                PROFILE(.TryMatch_Convert);

                mut error: string;
                mut candidate: Target;
                if (nullary || (candidate = tryMatch__mutargs(
                    target: t, :error,
                    id: "",
                    args: TODO_FIX_convert_args,
                    reorder: TODO_FIX_reorder,
                    conversions: TODO_FIX_conversions,
                    flags: F_CONVERSION)))
                {
                    shadow let t = nullary ? t : candidate;

                    let convert = GET(t);
                    convert.type || fail("No convert.type, perhaps a `using inline fn` without a return type annotation: `" ~ convert ~ "`.");

                    let convertType = convert.kind != "field"
                        ? convert.type
                        : make_field_reference(:from, convert);

                    shadow let isStruct = convertType.isStruct;

                    if (convert.status & (SS_DID_START | SS_FINALIZED) == SS_DID_START)
                    {
                        // Decidability [B]:
                        //
                        // We ignore unsolved conversions:
                        //  this means you can't use a using fn recursively,
                        //   which solves the problem of unspecified return values,
                        //    because initially the t_never assigns to everything.
                    }
                    else if (isAssignableAsArgument(convertType, /*into*/host: expect))
                    {
                        // Actual is assignable to current `from` type,
                        //  this means we've got a conversion edge that works.
                        if (match)
                        {
                            mut suffix  = "\n"          ~ explainConversion(match)
                                        ~ "\n\tand:\n"  ~ explainConversion(path ~ t);

                            if (actual)
                                fail("Conversion ambiguity, multiple ways to convert "
                                    ~ humanizeType(actual) ~ " into "
                                    ~ humanizeType(expect) ~ ":" ~ suffix);
                            else
                                fail("using".qBAD ~ " ambiguity, multiple ways to obtain a "
                                    ~ humanizeType(expect) ~ " in this scope:" ~ suffix);
                        }

                        match = path;

                        // AUTOCALL /////////////
                        if (TODO_FIX_conversions)
                            match ~= TODO_FIX_conversions.only;

                        match ~= t;
                    }
                    else
                    {
                        let mightHaveConversion = isStruct || (local_scope ? _scope : misc_scope).converts;
                        if (mightHaveConversion)
                        {
                            // Forbid cyclic conversions.
                            //  Delaying the error check to speed up the general case.
                            if (path.len > 10)
                            {
                                for (mut i = path.len; i --> 0; )
                                {
                                    if (path[i] == t)
                                    {
                                        mut err = "Conversion loop:\n";

                                        for (shadow mut i = i; i < path.len; i++)
                                        {
                                            err ~= "\n\t    ";

                                            shadow let convert = GET(path[i]);
                                            err ~= convert ~ ": " ~ humanizeType(convertType) ~ " ->";
                                        }

                                        err ~= "\n\t        " ~ convert;
                                        fail(err);
                                    }
                                }
                            }

                            ///////////////////////////////
                            let path0 = path.len;
                            defer path.shrink(path0);

                            // AUTOCALL /////////////
                            if (TODO_FIX_conversions)
                                path ~= TODO_FIX_conversions.only;

                            path ~= t;

                            ///////////////////////////////
                            descend(convertType, nullary: false, :isStruct);
                            ///////////////////////////////
                        }
                    }
                }
            }

            // Usings.
            if (nullary)
            {
                (local_scope ? _scope : misc_scope)
                    .usings.each(local_scope && _ss.usings,
                        |u| foreach(u));
            }

            // On-struct stuff.
            else
            {
                if (isStruct)
                {
                    let inner = lookupUserType(from).converts;

                    // TODO no need to for the outer isAssignableAsArgument check.
                    // TODO can we split these into incoming and outgoing converts,
                    //       so we don't have to check anything at all?
                    //
                    for (mut i = 0; i < inner.len; i++)
                        foreach(inner[i]);
                }

                // Conversions.
                if (has_converts)
                    (local_scope ? _scope : misc_scope)
                        .converts.each(local_scope && _ss.converts,
                            fn foreach);
            }
        }

        // Go.
        descend(actual, nullary: !actual, :actual.isStruct, root: true);

        // We're done here.
        return match;
    }


    //

    fn match__mutargs(
        misc_scope: Scope, local_scope: bool,
        id: string, ref args: SolvedNode[],
        ref reorder: Reorder,
        ref conversions: Target[][],
        flags: Flags, target: Target): Target
    {
        mut error: string;

        PROFILE(.TryMatch_SolveCall);

        let ret = tryMatch__mutargs(:misc_scope, :local_scope, :id, :args, :reorder, :conversions, :flags, :target, :error);
        if (ret)
            return ret;

        // Compose error message:
        //  separate pass, so we don't have to worry about unnecessary string concats.
        error = "Bad call to " ~ (target ? target.str : id.qID)
                ~ (args && " with args (" ~ args.map(.humanizeType).join(", ") ~ ")")
                ~ ": ";

        let debug = tryMatch__mutargs(:misc_scope, :local_scope, :id, :args, :reorder, :conversions, :flags, :target, :error);
        if (debug)
            BUG("Did match on second pass: " ~ debug);

        fail(error);
    }


    //

    fn solveNode(node: Node, type?: Type): SolvedNode
    {
        HERE(node);

        let k = node.kind;

        if (k == "root")        return solveRoot(node);
        if (k == "block")       return solveBlock(node, :type);
        if (k == "argid")       return solveArgID(node, :type);

        if (k == "let")         return solveLet(node, letdefType: type);
        if (k == "call")        return solveCall(node);
        if (k == "arrlit")      return solveArrlit(node, type);

        if (k == "not")         return solveNot(node);
        if (k == "if")          return solveIf(node, type);
        if (k == "or")          return solveOr(node, type);
        if (k == "and")         return solveAnd(node, type);

        if (k == "loop")        return solveLoop(node);
        if (k == "break")       return solveJump(node);
        if (k == "return")      return solveJump(node);
        if (k == "continue")    return solveJump(node);

        if (k == "int")         return solveInt(node, type);
        if (k == "real")        return solveReal(node, type);
        if (k == "str")         return solveString(node, type);
        if (k == "char")        return solveChar(node);
        if (k == "bool")        return createBool(:node.value);

        if (k == "definit")     return solveDefinit(type);

        if (k == "import")      return solveImport(node);
        if (k == "defer")       return solveDefer(node);
        if (k == "try")         return solveTryCatch(node);

        if (k == "typecast")    return solveTypeCast(node);
        if (k == "typeassert")  return solveTypeAssert(node);
        if (k == "typeparam")   return solveTypeParam(node);
        if (k == "addroffn")    return solveAddrOfFn(node);

        // Exotics.
        if (k == "forfieldsof") return solveForFieldsOf(node);
        if (k == "pragma")      return executeCompilerPragma(node);
        if (k == "empty")       return createEmpty();
        if (k == "unwrap")      return createUnwrap();

        if (unorderedClassify(k))
            return solveDeclExpr(node);

        //
        return fail("TODO: solveNode(" ~ k ~ ").");
    }

    fn solveDeclExpr(node: Node, TODO_FIX_useSpecPath!?: bool): SolvedNode
    {
        mut res = solveNodes([ node ], DeadBreak_Dont,
            :TODO_FIX_useSpecPath).only;

        // Anonymous structs & co.
        if (res.target && res.target.kind == "type")
            res.type = res.target.type;

        return res;
    }

    fn isTypeDecl(::kind)
    {
        return kind == "struct"    || kind == "union"
            || kind == "primitive" || kind == "enum"  || kind == "flags";
    }

    fn unorderedClassify(::kind): i32
    {
        if (kind == "fn")
            return 1;

        if (kind.isTypeDecl)
            return 10;

        return 0;
    }

    fn unorderedPrep_A(node: Node, TODO_FIX_useSpecPath!?: bool): SolvedNode
    {
        let kind = node.kind;

        if (kind == "fn")
            return uPrepFn_A(node);

        if (kind.isTypeDecl)
            return uPrepStruct(node, :TODO_FIX_useSpecPath);

        BUG("TODO: unorderedPrep_A(" ~ node.kind ~ ").");
    }

    fn unorderedPrep_B(nodes: [Node], results: [SolvedNode], unorderedClass: i32)
    {
        if (unorderedClass != 1)
            return;

        mut hasSnap = false;
        mut lastSnap: ScopeMemo;

        for (mut i = nodes.len; i --> 0; )
        {
            // Decidability [C]:
            //
            // Conversion fns don't see below their declaration,
            //  otherwise we start running into conversion loop drama.
            //
            // This obsoletes Decidability [A] above.
            //
            let node    = nodes[i];
            if (node.flags & F_CONVERSION)
                hasSnap = false;

            // Everyone in this group sees everyone else.
            let target  = results[i].target;
            ref eph     = target.EPH_mut;
            if (eph.scope_memo)
            {
                if (!hasSnap)
                {
                    hasSnap = true;
                    lastSnap = eph.scope_memo;
                }
                else
                {
                    eph.scope_memo = lastSnap;
                }
            }
        }
    }


    //

    fn _current_fn_eachArg_BACK(visit)
    {
        for (mut i = _current_fn.items.len + FN_ARGS_BACK; i --> 0; )
        {
            let t = _current_fn.items[i].target;
            if (t && t.flags & F_ARG)
                visit(t, position?: i);
        }
    }

    fn _current_fn_eachArg_FWD(visit)
    {
        for (mut i = 0; i < _current_fn.items.len + FN_ARGS_BACK; i++)
        {
            let t = _current_fn.items[i].target;
            if (t && t.flags & F_ARG)
                visit(t, position?: i);
        }
    }


    //

    fn type_mayPointInto(host: ValueType, guest: ValueType)
    {
        if (guest.is_reinterpretable)
            return true; // TODO check sizes

        // ref bytes = ints.view(of: byte)
        guest.if_sliceable: |sliceT|
            if (sliceT.is_reinterpretable)
                return true;

        // Acceleration -
        //  we use the non_triv_mask as a bloom filter
        //   to get avoid the full loop below when possible.
        //
        let host_shape          = getShape(host);
        let guest_non_triv_mask = getShape(guest).non_triv_mask;

        // Guest might be some kind of ZST -
        // TODO FIX clean those up and see why we're at all bothering here.
        if (!guest_non_triv_mask)
            return false;

        if (host_shape.non_triv_mask & guest_non_triv_mask
                                    != guest_non_triv_mask)
            return false;

        //
        mut seen: StructCanon[];

        fn type_maybeInside(shadow host: ValueType)
        {
            if (host.canon == guest.canon)
                return true;

            host.if_sliceable: |host_sliceT|
                return type_maybeInside(host_sliceT);

            if (host.isStruct)
            {
                let scp = parseStructCanon(host.canon);
                let s   = lookupUserType(scp);

                if (s.non_triv_mask & guest_non_triv_mask
                                   != guest_non_triv_mask)
                    return false;

                if (seen.set::add(scp))
                {
                    for (mut i = 0; i < s.items.len; i++)
                    {
                        let f = s.items[i].target;
                        if (type_maybeInside(host: f.type))
                            return true;
                    }
                }

                // TODO FIX investigate these, I'm seeing one in build.fu
                // if (SELF_TEST)
                //     BUG("[PERF] type_maybeInside: non_triv_masks failed to optimize a go through some struct: " ~ host.Type.humanizeType);
            }

            return false;
        }

        return type_maybeInside(:host);
    }


    //

    fn validateCOW(item: SolvedNode,
        here! = _here,
        callee?: Target, host_arg?: Argument,
        calleeReturnDiscarded!?: bool)
    {
        PROFILE(.ValidateCOW);

        // validateCOW is used for 'copy' nodes but also for callargs,
        //  where the copy-inside list has many vtype/token pairs.
        fn eachCOWInside(visit)
        {
            if (callee)
            {
                let callee_cows = callee.cows_inside;
                for (shadow mut i = 0; i < callee_cows.len; i++)
                {
                    let callee_cow = callee_cows[i];

                    // TODO FIX: first naive attempt at some escape-analysis-like thing,
                    //  very limited but I need this to get closer to a bootstrap.
                    //
                    // Basically - if the COWInside is produced after all arguments
                    //  have finished writing, and if the return value here is discarded,
                    //   ignore them and don't propagate them upward.
                    //
                    // TODO FIX: this ignores the possiblity for values
                    //  to escape via throw / exceptions,
                    //   although that's not currently possible.
                    //
                    if (calleeReturnDiscarded && !callee_cow.mayEscapeVia)
                        continue;

                    if (callee_cow.argTarget == host_arg.target.locid)
                    {
                        visit(:callee_cow.vtype, token?: callee_cow.token,
                            uncaughtThrowOnly?:
                                callee_cow.exitPaths == XP_NoReturn
                                    && !_current_fn.TODO_FIX_catches);
                    }
                }
            }
            else
            {
                visit(:item.type.vtype, token?: _here,
                    uncaughtThrowOnly?: false);
            }
        }

        fn eachLiveChildMutref(index: i32, visit)
        {
            let children = _current_fn.TODO_FIX_children.unless_oob(index);
            for (mut i = 0; i < children.len; i++)
            {
                let child = children[i];

                // We only care about mutref children.
                let t = nested(child);
                let o = GET(t);
                if (!o.solved.type.is_mutref)
                    continue;

                // Skip if we've already seen the declaration for this var,
                //  which means ref is taken after the copy is made.
                if (_current_fn.done_relaxing.has(child))
                    continue;

                visit(child?: child, t?: t, o?: o);
            }
        }

        // Step 1:
        // Climb parents, collecting all preexisting refs
        //  that could possibly be used after the COW "copy" is made
        //   to mutate the original as-if-unique,
        //    breaking value semantics on the copy.
        fn cannotCOW_climbParents(lifetime: Lifetime, expected_refs!?: i32[])
        {
            lifetime.Lifetime_each: |locid, region, paths|
            {
                if (!locid)
                    continue;

                let o = GET(nested(locid));
                o.kind == "var" || BUG("cannotCOW_climbParents found a non-var: " ~ o);

                // Climb parents.
                cannotCOW_climbParents(
                    Lifetime_op_join(
                        Lifetime_climbType(o).lifetime,
                        paths),

                    // We don't want to forbid the copy when we visit this locid
                    //  as a child of one of our parents.
                    :expected_refs ~ locid);

                // Check children.
                cannotCOW_descendChildren(locid, region, :expected_refs);

                // GLOBAL COMPONENT
                // Here we're adding stuff to the arguments-at-risk bitmasks,
                //  to prevent COW copies to be created while there are outstanding
                //   writeable refs to their contents, but indirectly,
                //    via aliased function arguments.
                ref flow = _current_fn.flow;
                if (o.flags & F_ARG)
                {
                    // Let's just hard risk all mutref arguments for starters,
                    //  we'll be relaxing this later as more practical examples become available.
                    let arg_targets = flow.arg_targets;
                    for (shadow mut i = 0; i < arg_targets.len; i++)
                    {
                        let t = arg_targets[i];
                        if (!t || t == locid)
                            continue;

                        // Mutrefs only.
                        shadow let o = GET(nested(t));
                        if (!o.solved.type.is_mutref)
                            continue;

                        // Nothing to do if already hard-risked.
                        if (flow.at_hard_risk.unless_oob(t).has(locid))
                            continue;

                        fn needsHardRisk(shadow index: i32)
                        {
                            // Gotta visit children first -
                            //  otherwise a direct match on the parent
                            //   exits early and fails to hard-risk the argument,
                            //    see cowAfterConditionalWithLoop testcase.
                            //
                            eachLiveChildMutref(index): |child| {
                                let reason = needsHardRisk(child);
                                if (reason)
                                    return reason;
                            }

                            if (_current_fn.ever_written.has(index)) {
                                eachCOWInside: |vtype, uncaughtThrowOnly| {

                                    // If COW only occurs via a throw route,
                                    //  no writes that follow this call can clobber it.
                                    if (uncaughtThrowOnly)
                                        continue;

                                    if (type_mayPointInto(host: vtype, o.type))
                                        return index;
                                }
                            }

                            return 0;
                        }

                        let reason = needsHardRisk(t);
                        if (reason)
                        {
                            makeNote(N_COWRestrict, nested(locid) ~ " at risk from " ~ nested(t) ~ " via " ~ nested(reason));

                            flow.at_soft_risk.grow_if_oob(t).add(locid);

                            fn TODO_FIX_slicesAgain()
                            {
                                // Initially I assumed the TODO_FIX_isArray in the hard/soft risk stuff in updateScope
                                //  would convert soft -> hard risk for slices [which is the wrong thing to do in the first place]
                                //   but that doesn't work because there we care about reallocation,
                                //    here it's about aliasing, anyways, doesn't work.
                                //
                                // We gotta remove the need for this kind of trash,
                                //  which can only happen if we formalize the differences between arrays and slices
                                //   and array-into-slice conversions.
                                //
                                return nested(t).type.is_sliceable;
                            }

                            if (reason != t || TODO_FIX_slicesAgain)
                                flow.at_hard_risk.grow_if_oob(t).add(locid);
                        }
                    }

                    // Remember this copy, we'll propagate along.
                    eachCOWInside: |vtype, token, uncaughtThrowOnly|
                    {
                        let mayEscapeVia = _current_fn.postdom.mayEscapeVia;
                        let exitPaths    =
                            uncaughtThrowOnly
                                ? XP_NoReturn
                                : _current_fn.postdom.exitPaths || BUG("No current_fn.exitPaths");

                        //
                        ref my_cows = _current_fn.events.cows_inside;
                        for (shadow mut i = 0; i < my_cows.len; i++)
                        {
                            ref my_cow = my_cows[i];
                            if (my_cow.argTarget    == locid &&
                                my_cow.vtype.canon  == vtype.canon)
                            {
                                my_cow.vtype.quals  |= vtype.quals;
                                my_cow.mayEscapeVia |= mayEscapeVia;
                                my_cow.exitPaths    |= exitPaths;
                                return;
                            }
                        }

                        // Nope, couldn't insert, add a new one.
                        my_cows ~= COWInside(
                            :vtype, :token, argTarget: locid,
                            :mayEscapeVia,
                            :exitPaths);
                    }
                }
            }
        }

        // Step 2:
        // At this point we haven't folded var_usage up parent refs,
        //  so we gotta descend the invalidation chain manually.
        fn cannotCOW_descendChildren(parent_locid: i32, parent_region: Lifetime, expected_refs!: i32[])
        {
            parent_locid.eachLiveChildMutref: |child, t, o|
            {
                // Ignore this if we're copying through this ref.
                if (expected_refs.has(child))
                    continue;

                //
                let inter = _current_fn.flow.rg_parents.unless_oob(child).Lifetime_inter(parent_region);
                if (!inter)
                    continue;

                if (_current_fn.ever_written.has(child))
                {
                    // For a ref to clobber a COW copy,
                    //  the thing it points to must fit inside the COW type -
                    //   e.g. ref i32 into an cow(i32[]).
                    eachCOWInside: |vtype, token|
                    {
                        if (type_mayPointInto(host: vtype, o.type))
                        {
                            let cow_inside = token;

                            mut err = !callee
                                ? "A copy is needed, but "
                                : host_arg ~ " to " ~ callee ~ " is indirectly copied from:\n"
                                    ~ qSTACK_cow_inside(callee, callee.solved, :host_arg, :cow_inside)
                                    ~ "\n\t... but "

                            err ~= "COW will break due to pre-existing mutref: "
                                    ~ explainWhichFn(t, fmt: FullContext);

                            err ~= "\n\tBoth refer to: "
                                    ~ explainWhichFn(nested(parent_locid), fmt: FullContext);

                            _here = here;
                            fail(err);
                        }
                    }
                }

                // Continue.
                cannotCOW_descendChildren(child, inter, :expected_refs);
            }
        }

        cannotCOW_climbParents(item.type.lifetime);
    }

    fn propagateType(ref node: SolvedNode, slot: Type, relax_mask!: Quals, kills!?: Helpers)
    {
        let k = node.kind;

        ////////////////////////////
        let here0   = _here;
        _here       = node.token;
        defer _here = here0;
        ////////////////////////////

        //
        inline fn PASS_MoveOnLastUse    = relax_mask == RELAX_all;
        inline fn PASS_MaybeCopyOrMove  = relax_mask == RELAX_all;

        fn trackUse(lt: Lifetime, ref bitset: bitset::BitSet)
        {
            fn trackUse(t: Target)
            {
                let locid = t.locid;
                if (!bitset.add_once(locid))
                    return false;

                let o = GET(t);
                let letNode = o.solved;
                if (letNode.is_ref)
                {
                    if (o.flags & F_ARG)
                        return false;

                    if (!trackUse(Lifetime_climbType(o).lifetime, :bitset))
                        return false;
                }

                return locid >= _current_fn.parent_loop_start;
            }

            mut allTrue = true;
            lt.Lifetime_each: |locid, isTemp|
            {
                if (isTemp && MOVE_from_temp)
                    continue;

                if !(locid && trackUse(nested(locid)))
                {
                    // Can't break early,
                    //  needs to flag all lifetimes underneath.
                    allTrue = false;
                }
            }

            return allTrue;
        }

        fn tryTrackLastUse(lt: Lifetime)
        {
            return PASS_MoveOnLastUse
                && trackUse(:lt, _current_fn.postdom.used_again);
        }

        fn trackJustMoved(lt: Lifetime)
        {
            lt.Lifetime_each: |locid, isTemp|
            {
                if (isTemp && MOVE_from_temp)
                    continue;

                locid || BUG(
                    "trackJustMoved: found a non-local.");

                trackJustMoved(Lifetime_climbType(nested(locid)).lifetime);
            }
        }


        // Tracking writes alla bck,
        //  will now use this in cannotCOW which was relying on var usage,
        //   which A] is not flow-sensitive
        //     and B] seems to be messed around with by propagateType(loop)
        //
        fn callarg_trackWrites(lt: Lifetime)
        {
            lt.Lifetime_each: |locid|
            {
                if (locid &&
                    _current_fn.ever_written.add_once(locid))
                {
                    shadow let t = nested(locid);

                    callarg_trackWrites(
                        Lifetime_climbType(t).lifetime);

                    if (t.flags & F_ARG)
                        _current_fn.postdom.mayEscapeVia |= 1 << (locid % 32);
                }
            }
        }


        //

        fn Breakable_begin(loop_PREVITER?: bool)
        {
            if (node.helpers)
                node.helpers.postdom = _current_fn.postdom;

            // This only works during the second propagateType pass -
            //  basically we're reusing the events collected during RelaxMut,
            //   to pre-seed what's gonna happen on next/prev loop iteration during MaybeCopyOrMove.
            if (loop_PREVITER && PASS_MaybeCopyOrMove)
                _current_fn.postdom.branch(node.helpers.loop_PREVITER);
        }

        fn Breakable_end(loop_PREVITER?: bool)
        {
            // We only collect loop_PREVITER stuff in RelaxMut,
            //  no point in doing it during MCOM because nothing comes after it.
            if (loop_PREVITER && !PASS_MaybeCopyOrMove)
            {
                ref previter    = node.helpers.loop_PREVITER;
                previter        = _current_fn.postdom;

                // We want to forget about all events
                //  for stuff that's local to the loop,
                //   otherwise we see writes to local variables
                //    past their last use.
                //
                let loop_start  = node.helpers.locals_start;

                for (fieldname i: PostdomSnap)
                    if (typeof (previter.i) -> bitset::BitSet)
                        previter.i.clear(start: loop_start);
            }

            if (node.helpers)
                _current_fn.postdom.branch(node.helpers.postdom);
        }


        //

        fn isDiscardable(t: Target): bool
        {
            if (t.fx_mask & Fx_NotDeadCode)
                return false;

            let host_args = t.args;
            for (mut i = 0; i < host_args.len; i++)
                if (host_args[i].flags & F_WRITTEN_TO)
                    return false;

            return true;
        }

        fn isShallowLiteral(::kind)
        {
            return kind == "int" || kind == "real" || kind == "char"
                || kind == "str" || kind == "bool"
                || kind == "definit";
        }

        fn isDiscardable(shadow node: SolvedNode): bool
        {
            if (node.items)
                return false;

            // Discardable calls degrade into blocks.
            if (node.kind == "call" || node.kind == "letdef")
                return false;

            if (node.kind == "empty" || node.kind == /*empty*/"block" || node.kind == "fndef" || node.kind.isShallowLiteral)
                return true;

            BUG("TODO: isDiscardable(" ~ node.kind ~ ")");
        }


        //

        let canDiscard = slot.isIrrelevant;

        // Shortcutting lets, they source the slot from usage.
        if (k == "let" || k == "letdef")
        {
            // Addrofn & co.
            if (!node.target)
                return;

            if (PASS_MaybeCopyOrMove)
            {
                shadow ref node = GET_mut(node.target).solved;

                mut type = node.type; // TODO DISJOINT

                ref init = node.items[LET_INIT];
                if (init)
                    maybeCopyOrMove(init, type);
            }

            relaxBlockVar(node.target, :relax_mask, :canDiscard);

            k == "letdef" || BUG("Unexpected let node.");

            // Discarding unused variables.
            if (node.target.status & SS_UNUSED)
            {
                makeNote(N_UnusedLet);
                node = node.target.solved.items[LET_INIT] || createEmpty();
            }

            return;
        }

        node.type.try_relax(:slot, :relax_mask);

        fn discardIntoBlock()
        {
            node = createBlock(:node.items, slot);
            // Keeping the slot type intact ^^^^ here,
            //  otherwise spec-relax later tries to specialize with voids,
            //   caught this because F_TYPENAME args ended up bound to t_voids
            //    during relax(spec_of) below.

            return propagateType(:slot, node, :relax_mask);
        }

        fn trackVarUsage(locid: i32, shadow slot: Type)
        {
            if (SELF_TEST)
            {
                TEST_unusedButCopied("trackVarUsage " ~ nested(locid), slot);

                if (slot.lifetime.hasTemporary)
                    BUG(nested(locid) ~ ", trackVarUsage: slot is ref2temp: " ~ slot.humanizeType(lt: true));
            }

            shadow ref usage = _current_fn.var_usage.grow_if_oob(locid);
            if (!usage)
                usage = slot;
            else
                usage = type_tryIntersect(usage, slot) || BUG(
                    nested(locid) ~ ": Usage intersection failure: "
                                  ~ explainTypeDiff(usage, slot, "&"));
        }


        // Control flow.

        if (k == "and" || k == "or")
        {
            let type = node.type; // TODO DISJOINT

            let rest = !canDiscard && (k == "or" || slot.is_mutref && CANNOT_definit_mutrefs)
                ? slot
                : t_proposition;

            let postdom0 = _current_fn.postdom;

            let mcomOrItems = k == "or"
                && PASS_MaybeCopyOrMove
                && !canDiscard
                && !type.is_boolean;

            ref items = node.items;
            for (mut i = items.len; i --> 0; )
            {
                ref item = items[i];

                if (mcomOrItems)
                    maybeCopyOrMove(item, type);

                propagateType(item, :relax_mask, i == items.len - 1 ? slot : rest);

                ////////////////////////////////////////////////////////////////
                if (canDiscard && i == items.len - 1 && item.isDiscardable)
                {
                    makeNote(N_UnusedAndOr);
                    items.pop();
                    _current_fn.postdom == postdom0 || BUG();
                }
                ////////////////////////////////////////////////////////////////

                // Conditional - tail exprs are skippable.
                if (i) _current_fn.postdom.branch(postdom0);
            }

            ////////////////////////////////////////////////////////////////
            if (items.len < 2)
                node = items.if_only || createEmpty(type: slot);
            else if (canDiscard)
                node.type = t_bool;
            ////////////////////////////////////////////////////////////////
        }
        else if (k == "if")
        {
            let type = node.type; // TODO DISJOINT

            ref items = node.items;

            if (PASS_MaybeCopyOrMove && !canDiscard)
                for (mut i = items.len; i --> 1; )
                    maybeCopyOrMove(items[i], type);

            //
            mut postdom0 = _current_fn.postdom;
            mut canDiscard_cond = canDiscard;
            for (mut i = items.len; i --> 0; )
            {
                // MOVE ON LAST USE ////////////////////////////////////////////
                if (i == 1)
                {
                    // Cons branch, alt already solved.
                    swap(postdom0, _current_fn.postdom);
                }
                else if (i == 0)
                {
                    // Finally the cond, cons and alt already solved.
                    _current_fn.postdom.branch(postdom0);
                }
                // MOVE ON LAST USE ////////////////////////////////////////////

                propagateType(items[i], :relax_mask,
                    slot:  i != 0 || canDiscard_cond ? slot : t_proposition,

                    // CAN AFFECT cons/alt.type (see `if (kills)` below):
                    //  If all assumptions check out,
                    //   the slot will either accept this value or will retype itself,
                    //    e.g. a block retval can be affected when this is in tail position.
                    //
                    kills: i != 0 && kills);

                // Re: testcase doesNothing(pointlessArg):
                //  if/else wouldn't be discarded on first relax,
                //   caught by a copy generated for the first operand to the ==
                //    getting discarded on second relax.
                //     BTW it's crazy that we generate copy nodes for arithmetic operands.
                if (canDiscard_cond && i && !items[i].isDiscardable)
                    canDiscard_cond = false;
            }

            if (canDiscard)
            {
                if (canDiscard_cond)
                {
                    makeNote(N_UnusedIfElse);
                    node = items[0];
                }
                else if (items[1].isDiscardable)
                {
                    node = createOr([ items[0], items[2] ], t_void);
                }
                else if (items[2].isDiscardable)
                {
                    node = createAnd(items.slice(0, 2), t_void);
                }
                else
                {
                    node.type = t_void;
                }
            }
            else if (kills)
            {
                // Control flow simplification can affect node.type, see above.
                node.type = superType_neverOK(
                    "if/else after control flow simplification: ",
                        items[1], items[2]);
            }

            // BCK Events_merge needs loop_start
            //////////////////////////////////////////
            node._loop_start = _current_fn.parent_loop_start;
            //////////////////////////////////////////

        }
        else if (k == "try")
        {
            fn attempt      = node.items[TRY_TRY];
            fn error        = node.items[TRY_ERR];
            fn recover      = node.items[TRY_CATCH];

            // Relax in reverse, catch goes first.
            let postdom0    = _current_fn.postdom;

            propagateType(recover, t_void, :relax_mask);

            // The catch is conditional -
            //  only executes if try block throws.
            _current_fn.postdom.branch(postdom0);

            propagateType(error, t_string, :relax_mask);

            //////////////////////////////////////////////
            let throws0 = _current_fn.fx_mask & Fx_Throws;
            _current_fn.fx_mask &= ~Fx_Throws;
            //////////////////////////////////////////////

            _current_fn.TODO_FIX_catches++;
            propagateType(attempt, t_void, :relax_mask);
            _current_fn.TODO_FIX_catches--;

            // Drop the whole catch if possible,
            // TODO FIX this defeats relaxing the catch & err parts first.
            if !(_current_fn.fx_mask & Fx_Throws)
            {
                makeNote(N_UnusedTry);
                node = attempt;
            }

            //////////////////////////////////////////////
            _current_fn.fx_mask &= ~Fx_Throws;
            _current_fn.fx_mask |= throws0;
            //////////////////////////////////////////////
        }
        else if (k == "loop")
        {
            fn init         = node.items[LOOP_INIT];
            fn pre_cond     = node.items[LOOP_PRE_COND];
            fn pre          = node.items[LOOP_PRE];
            fn body         = node.items[LOOP_BODY];
            fn post         = node.items[LOOP_POST];
            fn post_cond    = node.items[LOOP_POST_COND];

            // MOVE ON LAST USE ////////////////////////////////////////////
            Breakable_begin(loop_PREVITER: true);
            let loop_start0                 = _current_fn.parent_loop_start || BUG();
            _current_fn.parent_loop_start   = node.helpers.locals_start || BUG();

            mut var_usage0: Type[];
            swap(_current_fn.var_usage, var_usage0);
            // MOVE ON LAST USE ////////////////////////////////////////////

            // Relax in reverse.
            if (post_cond)
                propagateType(post_cond, t_proposition, :relax_mask);

            if (post)
            {
                if (post.isDiscardable)
                    post = [];
                else
                    propagateType(post, t_void, :relax_mask);
            }

            if (body)
            {
                if (body.isDiscardable)
                    body = [];
                else
                    propagateType(body, t_void, :relax_mask);
            }

            if (pre)
            {
                // TODO FIX Fails to recognize the preheader is not actually part of the loop.
                //  Not sure how to approach this exactly.
                let postdom0 = _current_fn.postdom;

                if (pre.isDiscardable)
                    pre = [];
                else
                    propagateType(pre, t_void, :relax_mask);

                // The preheader is conditional -
                //  only executes before first entry to loop body.
                _current_fn.postdom.branch(postdom0);
            }

            if (pre_cond)
                propagateType(pre_cond, t_proposition, :relax_mask);

            // MOVE ON LAST USE ////////////////////////////////////////////
            _current_fn.parent_loop_start  = loop_start0;
            Breakable_end(loop_PREVITER: true);
            _current_fn.parent_loop_start == loop_start0 || BUG();

            swap(_current_fn.var_usage, var_usage0);

            for (mut i = 0; i < var_usage0.len; i++)
            {
                shadow let slot = var_usage0[i];
                if (slot)
                    trackVarUsage(i, slot);
            }

            node.helpers.usage = var_usage0;
            // MOVE ON LAST USE ////////////////////////////////////////////

            if (init)       propagateType(init, t_void, :relax_mask);
        }

        //
        else if (k == "not")
        {
            if (canDiscard)
            {
                node = node.items.only;
                return node.propagateType(t_void, :relax_mask);
            }

            return node.items.only.propagateType(t_proposition, :relax_mask);
        }
        else if (k == "call")
        {
            /////////////////////////////////////////////////
            node._loop_start = _current_fn.parent_loop_start;
            /////////////////////////////////////////////////

            let t = node.target;
            if (t.kind == "field")
            {
                // TODO just using t.field_unpackOffset -
                //  could be dealt with during parse,
                //   just syntax sugar for an anonymous let.
                //
                using let _ = t.field_unpackOffset;
                shadow let slot = USAGE_structUsageFromFieldUsage(:slot, :memberFlatOffset);

                if (canDiscard)
                {
                    node = node.items.only;
                    return node.propagateType(slot, :relax_mask);
                }

                return node.items.only.propagateType(slot, :relax_mask);
            }

            if (t.kind == "var")
            {
                if (canDiscard)
                {
                    node = createEmpty(type: slot);
                    return;
                }

                // This is the old relaxBlockVars callsite loop -
                //  Now we just collect usage while propagating types,
                //   this means we're automatically ignoring type annotations etc.
                //
                if (t.isLocal)
                {
                    trackVarUsage(:t.locid, node.type);

                    // MOVE ON LAST USE ////////////////////////////////////////////
                    {
                        tryTrackLastUse(node.lifetime);
                    }
                    // MOVE ON LAST USE ////////////////////////////////////////////
                }

                return;
            }


            // Regular calls -
            //  we can redirect those to relaxed, cheaper specializations,
            //   based on what we want from the return value.
            //
            fn redirectCallTarget(spec: Target)
            {
                if (spec == node.target)
                    return;

                ensureLazySolved(spec);

                spec.args.len == t.args.len || BUG(
                    "Relaxed spec.args.len != original.args.len");

                checkAssignable(host: node.type, spec.type,
                    "Relaxed specialization does not return a subtype");

                if (node.type.is_ref)
                    node.type.lifetime = TEST_Lifetime(:node.type,
                        Lifetime_replaceArgsAtCallsite(spec, node.items),
                        tempsOK: true);

                node.target = spec;
                makeNote(N_RelaxRespec);
            }

            if (t.spec_of && t.type.is_ref)
            {
                // Template spec relaxer, this is nasty.
                //  Not sure what the ideal method to deal with this here would be,
                //   we're basically just going back and redoing things,
                //    and we don't have the original shit to work with.
                //
                mut relaxed: SolvedNode[];
                for (mut i = 0; i < node.items.len; i++)
                {
                    let orig = node.items[i];

                    // We'll only attempt to relax arguments whose lifetimes appear in the return value.
                    //  There's this other thing, perhaps we only need to relax a single such argument?
                    //
                    if (t.type.lifetime.Lifetime_has(argidx: i))
                    {
                        // TODO fix this relaxer can't scale up to q_USAGE,
                        //  we gotta replace it with the backwards design.
                        shadow let relax_mask = relax_mask &~ q_USAGE;

                        mut type = orig.type;
                        if (type.try_relax(:slot, :relax_mask))
                        {
                            if (!relaxed)
                                relaxed = node.items.slice(0, i);

                            relaxed ~= SolvedNode("__relaxed", :type);
                            continue;
                        }
                    }

                    if (relaxed)
                        relaxed ~= orig;
                }

                if (relaxed)
                {
                    TRACE_BRACKET("RELAX trySpecialize " ~ t.globid ~ " " ~ t ~ " for " ~ relaxed.map(.type.humanizeType).join(", "));

                    mut args_mangled: string;
                    let spec = trySpecialize(
                        t.spec_of, args: relaxed, :args_mangled, REST_START: relaxed.len);

                    if (!spec.is_SPECFAIL)
                        redirectCallTarget(spec);
                }
            }

            // Discard unused total computations.
            if (canDiscard && node.target.isDiscardable)
            {
                makeNote(N_UnusedCall);
                return discardIntoBlock();
            }

            ////////////////////////////////////////////////////////////////
            ////////////////////////////////////////////////////////////////
            //
            // Returns never? No effects follow,
            //  this is the last thing that's gonna happen.
            //   TODO clear loop_start too, basically clear Postdom here.
            //
            if (node.target.type.is_never && !_current_fn.TODO_FIX_catches)
            {
                _current_fn.postdom.snap        = [];
                _current_fn.postdom.exitPaths   = XP_NoReturn;
            }
            //
            ////////////////////////////////////////////////////////////////
            ////////////////////////////////////////////////////////////////

            // So this call stays.
            _current_fn.fx_mask |= node.target.fx_mask;

            // MOVE ON LAST USE ////////////////////////////////////////////
            if (PASS_MoveOnLastUse && node.items)
            {
                let host_args = t.args;
                for (mut i = 0; i < host_args.len; i++)
                {
                    let arg = node.items[i];

                    let host_arg = host_args[i];
                    if (host_arg.is_ref)
                        tryTrackLastUse(arg.lifetime);

                    if (host_arg.flags & F_COW_INSIDE)
                        validateCOW(arg, :host_arg,
                            callee: node.target,
                            here: arg.token,
                            calleeReturnDiscarded: canDiscard);
                }
            }
            // MOVE ON LAST USE ////////////////////////////////////////////

            // Relax arguments.
            if (node.items) :ARGUMENTS
            {
                if (t.kind == "type") :STRUCT_INIT
                {
                    // Since we don't relax constructors we need to deal with them separately,
                    //  good thing it's simpler because they have a guaranteed LTR order of eval.
                    //
                    let s = t.type.tryLookupUserType();
                    if (s.kind != "struct")
                        break :STRUCT_INIT;

                    s.items.len == node.items.len || BUG(
                        "Call(type): struct.items.len != call.items.len");

                    for (mut i = node.items.len; i --> 0; )
                    {
                        let field   = GET(s.items[i].target);
                        ref arg     = node.items[i];

                        using let _ = field.field_unpackOffset();

                        shadow mut slot = USAGE_fieldUsageFromStructUsage(
                            fieldType: field.type,
                            structUsage: slot.usage,
                            :memberFlatOffset,
                            :memberFlatCount);

                        if (PASS_MaybeCopyOrMove)
                            maybeCopyOrMove(arg, slot, isArgument: true);

                        arg.propagateType(:slot, :relax_mask);
                    }

                    break :ARGUMENTS;
                }

                //
                let host_args   = node.target.args;
                let RTL         = node.target.isRTL;

                host_args.len == node.items.len || BUG(
                    "propagateType(call) args.len != host_args.len at call to " ~ node.target);

                argsReverse(:RTL, :host_args): |i, host_arg|
                {
                    ref arg = node.items[i];

                    if (PASS_MaybeCopyOrMove)
                        maybeCopyOrMove(arg, host_arg, isArgument: true);

                    arg.propagateType(host_arg, :relax_mask);

                    if (host_arg.flags & F_WRITTEN_TO)
                        callarg_trackWrites(arg.type.lifetime);
                }
            }
        }
        else if (k.isShallowLiteral)
        {
            // Something alla discard.
            if (canDiscard)
            {
                if (SELF_TEST)
                    node.items && BUG("propagateType canDiscard(" ~ k ~ ") has items.");

                node.kind   = "empty";
                node.value  = "";
            }
        }
        else if (k == "empty" || k == "fndef")
        {
            /////////////////////////
            // What do we do here? //
            /////////////////////////
        }
        else if (k == "copy")
        {
            if (canDiscard)
                BUG("Trying to discard a copy: " ~ node);

            if (relax_mask != RELAX_all)
                BUG("Found a copy node during first relax: " ~ node);

            ref item = node.items.only;
            mut isCopy = true;

            // No longer doing this for trivials -
            //  it can trigger a bullshit MoveMustSeq.
            if (!item.is_trivial)
            {
                // Move on last use.
                if (tryTrackLastUse(item.type.lifetime))
                {
                    isCopy = false;
                }
                else
                {
                    if (!item.type.is_trivial)
                        validateCOW(item);

                    // Partial copy.
                    let usage       = node.type.usage;
                    let flatCount   = node.type.getFlatCount();
                    let maxUsage    = getMaxUsage(:flatCount);
                    if (usage != maxUsage) :PARTIAL_COPY
                    {
                        let s       = tryLookupUserType(node.type);
                        if (s.kind != "struct")
                            break :PARTIAL_COPY;

                        // So we'll break down the copy(a) into a
                        //  A(copy(a.x), [], copy(a.y)).
                        //
                        // If `a` is not a trivial expression, we'll need to go through a helper var
                        //  to make sure we don't repeat its effects / expenses.
                        //
                        if (!usage.USAGE_justOneThing(:flatCount) && !item.isFieldChain)
                        {
                            // So this returns a { let a = ...; A(copy(a.x), [], copy(a.y)) }
                            //
                            let letdef = createLet(setScope: false,
                                "__partcopy_ref", init: item, flags: []);

                            node.items.only = CallerNode("__partcopy_ref", :letdef.target || BUG());
                            node            = createBlock(letdef, node);
                        }

                        // This is the copy(a) -> A(copy(a.x), ...) conversion.
                        //
                        else
                        {
                            mut args: SolvedNode[];
                            for (mut i = 0; i < s.items.len; i++)
                            {
                                let fieldTarget = s.items[i].target;
                                let field       = GET(fieldTarget);
                                using let _     = field.field_unpackOffset();

                                let usedFieldType = USAGE_fieldUsageFromStructUsage(
                                    structUsage: usage,
                                    fieldType:   field.type,
                                    :memberFlatOffset,
                                    :memberFlatCount);

                                if (usedFieldType.isIrrelevant)
                                {
                                    args ~= createDefinit(field.type);
                                }
                                else
                                {
                                    mut copy    = node;
                                    copy.type   = usedFieldType;
                                    copy.items  = [
                                        CallerNode(
                                            debug: "__partcopy_field",
                                            target: fieldTarget,
                                            args: /*there's only one*/ [ item ])
                                    ];

                                    args ~= copy;
                                }
                            }

                            let type0   = node.type;
                            node        = CallerNode(
                                debug: "__partcopy_struct",
                                target: s.target,
                                :args);

                            node.type   = type0;
                        }

                        return propagateType(:slot, :node, :relax_mask, :kills);
                    }
                    // /Partial copy.

                    // TODO FIX bck doesnt see the `return propagateType` above //
                    shadow ref item = node.items.only; ///////////////////////////

                    // ... or fail if non-copyable.
                    if (!item.type.is_rx_copy)
                        fail("A value is needed, but can neither copy nor move from: " ~ item);

                    if (!node.type.is_trivial)
                        makeNote(N_NonTrivAutoCopy);
                }
            }

            // TODO FIX bck doesnt see the `return propagateType` above //
            shadow ref item = node.items.only; ///////////////////////////

            //
            propagateType(item, :relax_mask,
                slot: isCopy
                    ? make_copyable(slot)
                    : slot);

            item.is_ref || BUG("Nothing to copy, item is not a ref: " ~ item);

            //
            if (!isCopy)
            {
                // TODO FIX C++ codegen uses the F_MOVED_FROM flag
                //  to remove `const` annotations on locals & refs to locals.
                //
                Lifetime_F_MOVED_FROM(item.lifetime);

                // This is the move event bitmask,
                //  currently only used for ensuring correct OOE.
                //
                trackJustMoved(item.lifetime);

                node.kind = "move";
            }
        }
        else if (k == "arrlit")
        {
            if (canDiscard)
            {
                makeNote(N_UnusedArrlit);
                return discardIntoBlock();
            }

            ref items       = node.items;
            let itemSlot    = clear_sliceable(node.type);

            if (PASS_MaybeCopyOrMove)
                for (mut i = 0; i < items.len; i++)
                    maybeCopyOrMove(items[i], itemSlot);

            for (mut i = 0; i < items.len; i++)
                propagateType(items[i], :relax_mask,
                    slot: itemSlot);
        }
        else if (k == "argid")
        {
            node = node.items.only;
            node.propagateType(:relax_mask, :slot);
        }
        else if (k == "jump")
        {
            mut h = node.helpers;
            while (h.kills)
                h = node.helpers = h.kills;

            h.ret_actual || BUG(
                "propagateType(jump): h.ret_actual not available: #" ~ h.index);

            ref expr            = node.items.only;

            // Postdom.
            {
                _current_fn.postdom = h.postdom || BUG(
                    "propagateType(jump): h.loop_start not available: #" ~ h.index);

                // Adding this nonsense for COWsInside,
                //  basically for the compiler to accept its own code right now,
                //   we need to recognize exitpath=throws, so that we know those cows don't occur
                //    unless a callee unwinds, so no worries about loops etc.
                if (h.mask & HM_Function)
                {
                    let kind = expr.kind;

                    _current_fn.postdom.exitPaths =
                        kind == "empty" || kind == "definit"
                            ? XP_EmptyReturn
                            : XP_NonEmptyReturn;
                }
            }

            //
            let redundant       = kills && kills.index <= h.index;
            shadow let kills    = redundant ? kills : h;

            if (PASS_MaybeCopyOrMove)
                maybeCopyOrMove(expr, h.ret_actual);

            propagateType(expr, :relax_mask, h.ret_actual, :kills);

            // Remove redundant jumps.
            if (redundant)
            {
                node = expr;
            }
            else :NOT_IRRELEVANT
            {
                h.mask |= HM_LabelUsed;

                // Let's get rid of irrelevant expressions,
                //  wrap them in a block and follow them by a simple
                //   return(empty).
                //
                if (h.ret_actual.isIrrelevant)
                {
                    if (expr.kind == "empty")
                    {
                        expr.type = h.ret_actual;
                    }
                    else
                    {
                        mut not_empty = createEmpty(type: h.ret_actual);
                        swap(expr, not_empty);

                        node = createBlock(not_empty, node);
                    }

                    break :NOT_IRRELEVANT;
                }

                // Code cleanup -
                //
                // If the jump expression is a block,
                //  and the block doesn't use its label (so only returns via its tail expression),
                //   replace self with the block and wrap the tail in this jump.
                //
                fn tryInjectJumps(shadow ref expr: SolvedNode)
                {
                    fn injectJumps(shadow ref expr: SolvedNode)
                    {
                        if (!tryInjectJumps(expr))
                            expr = createJump(:h, expr);
                    }

                    if (expr.is_never)
                    {
                        // Nothing to do = success.
                        return true;
                    }

                    // This is unfortunate, injecting a discarding jump.
                    h.ret_actual || BUG("tryInjectJumps: no h.ret_actual on #" ~ h.index);
                    if (h.ret_actual.is_void && !expr.is_void)
                    {
                        if (expr.kind != "block")
                            expr = createBlock(t_void, items: [ expr ]);

                        expr.items.if_last.is_void && BUG(
                            "tryInjectJumps: Block tail is void, but block.type isn't: " ~ expr.type.humanizeType);

                        expr.items ~= createEmpty();
                    }

                    //
                    if (expr.kind == "block"
                            && expr.items
                            && !(expr.helpers.mask & HM_LabelUsed))
                    {
                        // Unlablled block = inject into tail.
                        injectJumps(expr.items.last);

                        expr.type = t_never;
                        return true;
                    }
                    else if (expr.kind == "if")
                    {
                        // If = inject into cons & alt.
                        for (mut i = 1; i < expr.items.len; i++)
                            injectJumps(expr.items[i]);

                        expr.type = t_never;
                        return true;
                    }

                    return false;
                }

                if (tryInjectJumps(expr))
                    node = expr;
            }
        }
        else if (k == "block")
        {
            let h = node.helpers;
            if (h.ret_actual)
            {
                // MCOM [A]
                if (PASS_MaybeCopyOrMove)
                    mcom_BlockReturns_CopyOrMoveDecision(h);

                h.ret_actual.try_relax(:slot, :relax_mask);

                // MCOM [B]
                if (PASS_MaybeCopyOrMove && !canDiscard && !h.ret_actual.is_never)
                    maybeCopyOrMove(node.items.last, h.ret_actual);
            }

            if (h)
            {
                h.mask &= ~HM_LabelUsed;
                h.kills = kills;
            }

            ref items = node.items;
            {
                // Defers first - in reverse order of evaluation,
                //  which is FORWARD order in the AST, hence the ++ here.
                for (mut i = 0; i < items.len - 1; i++)
                {
                    shadow ref node = items[i];
                    shadow let k = node.kind;

                    if (k == "defer")
                    {
                        ref expr = node.items.only;
                        propagateType(expr, :relax_mask, t_void);

                        //
                        if (expr.isDiscardable)
                        {
                            makeNote(N_UnusedDefer);
                            items.splice(i--, 1);
                        }
                    }
                    else if (k == "and" || k == "or")
                    {
                        // Convert:
                        //
                        //  { a && b.never; c... }
                        //  { a || c.never; b... }
                        //
                        // ... into:
                        //
                        //  { if (a) b; else c }
                        //
                        // This helps bck better figure out some patterns down the line.
                        //
                        if (node.items.last.is_never)
                        {
                            let cond = node.items.slice(0, node.items.len - 1);
                            let cons = node.items[node.items.len - 1];
                            let alt  = items.slice(i + 1, items.len);

                            items.splice(i + 1, alt.len);

                            shadow let cond = k == "and"
                                ? createAnd(cond, t_proposition)
                                : createOr (cond, t_proposition);

                            shadow let alt = createBlock(alt, :alt.last.type);

                            //
                            let replacement = createIf(:cond,
                                k == "and" ? cons : alt,
                                k == "and" ? alt : cons);

                            items[i] = replacement;
                        }
                    }
                }

                //////////////////////
                Breakable_begin();
                defer Breakable_end();
                //////////////////////

                // Tail item.
                while (items)
                {
                    ref tail = items.last;

                    // Unwrap trailing defer.
                    if (tail.kind == "defer")
                    {
                        // Discard trailing defer:err.
                        tail = tail.value == "err"
                            ? createEmpty()
                            : tail.items.only;
                    }

                    // TODO FIX: preserving explicit returns for fns,
                    //  ideally we'll just inject one at the end of doTrySpec.
                    shadow let kills = !(h.mask & HM_Function && !h.ret_actual.is_void) && (kills || h);

                    propagateType(tail, :relax_mask, slot,

                        // CAN AFFECT tail.type / h.ret_actual (see `if (kills)` below):
                        :kills);

                    if (!canDiscard || !tail.isDiscardable)
                        break;

                    items.pop();
                }

                // Regular items - in reverse order of eval.
                for (mut i = items.len - 1; i --> 0; )
                {
                    ref expr = items[i];
                    if (expr.kind != "defer")
                    {
                        propagateType(expr, :relax_mask, t_void);

                        if (expr.isDiscardable)
                            items.splice(i, 1);
                    }
                }
            }

            // TODO FIX args need extra iteration here.
            if (h.target == _current_fn.target)
            {
                _current_fn_eachArg_BACK: |t, position|
                {
                    relaxBlockVar(t, :relax_mask);

                    // Cleanup unused implicits that got injected and ended up.
                    if (t.status & SS_UNUSED && t.flags & F_IMPLICIT)
                    {
                        // println("\n\tREMOVE UNUSED IMPLICIT " t "\n");
                        makeNote(N_UnusedImplicit);

                        _current_fn.items[position].target == t || BUG();
                        _current_fn.items.splice(position, 1);
                    }
                }
            }

            if (!items && !(h.mask & HM_Function))
            {
                if (SELF_TEST && !canDiscard)
                    BUG("Empty block type is relevant: " ~ node.type.humanizeType);

                node.kind = "empty";
                node.helpers = [];
            }
            else if (items.len == 1 && !(h.mask & (HM_LabelUsed | HM_Function)))
            {
                // Unwrap single item blocks.
                node = items.only;
            }
            else
            {
                if (canDiscard)
                {
                    // Discard return value.
                    node.type = t_void;
                }
                else if (kills)
                {
                    // Control flow simplification can affect the return value of the block
                    //  by replacing a redundant jump in tail position.
                    //   The slot is supposed to fix itself up in the same manner.
                    //
                    if (items)
                    {
                        let tail = items.last;
                        if (h.ret_actual)
                        {
                            reportReturnType(:h, :tail.type);
                            node.type = h.ret_actual;
                        }
                        else
                        {
                            node.type = tail.type;
                        }
                    }
                }

                let tail = node.items.if_last;
                if (tail.kind == "block" && !(tail.helpers.mask & HM_LabelUsed))
                {
                    // Cleanup -
                    //
                    // If the tail item is an unlabelled block,
                    //  just unwrap it here, the extra scope is redundant.
                    //
                    node.items.splice(node.items.len - 1, 1, tail.items);
                }
            }
        }
        else if (k == "root")
        {
            // Tries to relax global lets (there's nothing else to relax globally).
            //  Three problems with that:
            //
            //   - F_PUBS can't be relaxed.
            //
            //   - callsites contain garbage from resolved fns:
            //     - generally I think we should get rid of persistant callsites, just keep them around during fnsolve;
            //     - which will work automatically if we injected globals as args but that's crazy;
            //     - perhaps we should just keep a list of globals used which propagates up the solvestack.
            //
            //   - finally there's the problem with F_PUB templates:
            //     - they can see private stuff from module scope, so can't relax those either.
            //
            for (mut i = node.items.len; i --> 0; )
                propagateType(node.items[i], t_void, :relax_mask);
        }
        else if (k == "pragma")
        {
            /////////////////////////////////////////////////
            node._loop_start = _current_fn.parent_loop_start;
            /////////////////////////////////////////////////

            // Noop - but do track variable use
            //  so we don't emit warnings
            //   and so we don't overrelax.
            //
            for (mut i = 0; i < node.items.len; i++)
            {
                ref item = node.items[i];
                item.propagateType(node.items[i].type, :relax_mask);

                // Forgot about this one!
                //  Caught it when we got rid of Events.ever_written
                if (item.is_mutref)
                    callarg_trackWrites(item.type.lifetime);
            }

            // Effect pragmas.
            if (node.value == "clock")
                _current_fn.fx_mask |= EFFECTS_clock;
            else if (node.value == "input")
                _current_fn.fx_mask |= EFFECTS_input;
            else if (node.value == "output")
                _current_fn.fx_mask |= EFFECTS_output;
        }
        else
        {
            fail("TODO: propagateType(" ~ k ~ ").");
        }
    }


    //

    fn solved(
        node: Node, type: Type, items?: SolvedNode[], target?: Target)
            : SolvedNode
    {
        return SolvedNode(
            kind:  node.kind ,
            flags: node.flags,
            value: node.value,

            :items, :type, :target);
    }

    fn solveRoot(node: Node): SolvedNode
    {
        // Root vars & such.
        let helpers = Helpers(_helpers.len);
        push(HelpersData());

        //
        let items = solveNodes(node.items, DeadBreak_Always, t_void);
        if (items.if_last.is_never)
        {
            _here = items.last.token;
            fail("Noreturn during static init: this program will never finish booting.");
        }

        mut root = SolvedNode(kind: "root", type: t_void, :items, :helpers);
        runAllPasses(root);
        return root;
    }

    fn solveBlock(node: Node, type!: Type, fnbody_of!?: i32, mask! = HM_CanBreak, id!?: string, locals_start!?: i32): SolvedNode
    {
        mut nodes = node.kind == "block"  ? node.items : [ node ];
        shadow let id = id || node.kind == "block" && node.value;

        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer if !(mask & HM_LoopPreheader) Scope_pop(_scope, scope0);
        ////////////////////////////////

        let helpers_idx = _helpers.len;
        push(HelpersData( :id, :mask,
            ret_expect:     type,
            target:         fnbody_of && localfn(index: fnbody_of),
            local_of:       fnbody_of ? fnbody_of : _current_fn.target.globid,
            locals_start:   fnbody_of ? +1 : locals_start || GET_next_local_index()));

        let h           = _helpers[helpers_idx];

        // TODO FIX adding the trailing return /////////////////////////
        if (fnbody_of && nodes)
        {
            let k = nodes.last.kind;
            if (k == "unwrap")
                _current_fn.TODO_FIX_isInline = true;
            else
                nodes.last = Node(kind: "return", value: [], :nodes.last.token,
                    items: nodes.last.kind != "empty" && [ nodes.last ],
                    flags: F_IMPLICIT);
        }
        ////////////////////////////////////////////////////////////////

        let items       = solveNodes(
            nodes,
            type_all:           t_void,
            type_last:          type,
            use_type_last:      !type.is_void,
            DeadBreak_Always);

        // TODO clean this up, non-return ret-expects
        //
        // PREVIOUSLY STRONGER
        //
        // if !(mask & HM_CanReturn)
        //  Running into issues with recursions through inlines,
        //   the return value might not be exact.
        //
        // This note is obsolete if we stop inlining via solveBlock,
        //  e.g. use inlineExpression for all inline fns.
        //
        if (!fnbody_of)
            h.ret_expect = [];

        // Block tail expressions.
        {
            let tail = items ? items.last.type : t_void;
            if (!tail.is_never)
                reportReturnType(:h, items ? items.last.type : t_void);
            else if (!h.ret_actual)
                h.ret_actual = t_never;
        }

        h.ret_actual || BUG("No ret_actual");

        //
        mut block = createBlock(:items,
            type: h.ret_actual || BUG(),
            :h);

        if (fnbody_of)
        {
            // Don't run further passes if dirty -
            //  some of our AST might be broken,
            //   invalidated callsites and such,
            //    just finish up asap.
            //
            let status = localfn(index: fnbody_of).status;
            if (!(status & SS_DIRTY))
            {
                sortInjectedArguments();

                if (!currentFn_mustBecomeInline())
                    runAllPasses(block);
                else
                    mcom_BlockReturns_CopyOrMoveDecision(:h);
            }
        }

        return block;
    }

    fn currentFn_mustBecomeInline()
    {
        if (_current_fn.TODO_FIX_isInline)
            return "Explicitly marked inline.";

        return _current_fn.far_jumps
            && "Contains non-local control flow.";
    }

    fn warn(inline message: string, token!: TokenIdx = _here)
    {
        _warnings.grow_if_oob(_current_fn.target.globid) ||= Warning(:token, message: message.fail_appendStack);
    }

    lax fn TEST_unusedButCopied(inline topic: string, slot: Type)
    {
        if (SELF_TEST && slot.is_rx_copy && slot.isIrrelevant && !slot.is_zst)
            BUG(topic ~ ": Usage is copy but no usage bits set: " ~ slot.humanizeType);
    }

    fn relaxBlockVar(t: Target, relax_mask!: Quals, canDiscard!?: bool)
    {
        let o = GET(t);

        // ROOT: Don't relax public globals.
        //  Can't do much even if we're exporting a single template, it's a shame.
        if (_current_fn)
        {
            let usage = _current_fn.var_usage.unless_oob(t.locid);
            let isUnused = !usage;
            if (isUnused)
            {
                if !(o.flags & F_LAX || o.status & SS_MATCHED || o.type.is_zst)
                    warn(:o.solved.token, "Unused variable: " ~ o ~ ": make it " ~ "lax".qKW ~ " if this is intentional.");
            }

            TEST_unusedButCopied("relaxBlockVar " ~ t, usage);

            //
            shadow ref o = GET_mut(t);
            if (isUnused)
                o.status |= SS_UNUSED;
            else
                o.status & SS_UNUSED && BUG("relaxBlockVar: previously SS_UNUSED " ~ o ~ " now used as " ~ humanizeType(usage));

            if (isUnused && canDiscard)
                o.solved.type = t_void;

            //////////////////////////////////////////////
            // TODO one of these two is redundant       //
            o.type.try_relax(slot: usage, :relax_mask); //
            //////////////////////////////////////////////

            ref node = o.solved;
            node.type || BUG("relaxBlockVar: !var.solved.type, can`t propagateType");
            node.type.try_relax(slot: usage, :relax_mask);

            // Lose the F_MUT annots on values that don't need them.
            if (o.flags & F_MUT)
            {
                if (usage.is_mutref)
                {
                    let type = clear_refs(node.type);
                    node.type = type;
                }
                else
                {
                    o.flags &= ~F_MUT;
                }
            }

            // Decide on relaxable refs.
            shadow ref o = GET_mut(t);
            if (o.flags & F_RELAXABLE_REF)
            {
                let strip = F_RELAXABLE_REF | (!usage.is_mutref && F_REF);

                o.flags             &= ~strip;
                o.solved.flags      &= ~strip;
            }
        }

        // Either way, try to relax.
        ref node = GET_mut(t).solved;

        // Steal init expression for processing.
        if (node.items && node.items[LET_INIT]

            // TODO FIX ignoring arguments, they're gonna relax at the callsite anyway.
            //  This works around RELAX_all now also doing mcom,
            //   while previously mcom_node did not visit argument defaults,
            //    and now we're noticing `copy` nodes during initial relax (after inline).
            //
            && !(o.flags & F_ARG))
        {
            mut init: SolvedNode;
            swap(init, node.items[LET_INIT]);

            init.propagateType(node.type, :relax_mask);

            shadow ref o = GET_mut(t);
            shadow ref node = o.solved;

            // TODO FIX Codegen helper, this is for the `fu_STR& src = sources[i]` case.
            //  Ideally we should do without this, otherwise we can rerun the solveLet crap.
            if (node.type.is_ref && !(node.flags & F_ARG))
                node.type.lifetime = init.type.lifetime;

            // Done, put it back.
            swap(init, node.items[LET_INIT]);
        }

        // All good.
        _current_fn.done_relaxing.add(t.locid);
    }

    fn createBlock(
        type: Type, mut items: SolvedNode[], h?: Helpers): SolvedNode
    {
        // Compact + stress test.
        for (mut i = items.len; i --> 0; )
        {
            ref item    = items[i];
            let k       = item.kind;

            if (k == "block")
            {
                if (item.items.if_last.kind == "unwrap")
                {
                    // Was this an interesting feature?
                    //  Not sure how you'd use it even, it's really out there.
                    //
                    // relinkJumps(:h, item);
                    item.kind == "block" && !(item.helpers.mask & HM_LabelUsed) ||
                        fail("`unwrap` doesn't currently support early returns.");

                    items.splice(i, 1,
                        item.items.slice(0, item.items.len - 1));
                }
            }
        }

        //
        return SolvedNode(
            kind: "block", :type, :items,
            helpers: h);
    }

    fn createBlock(mut a: SolvedNode, mut b: SolvedNode)
    {
        // TODO FAILCASE this is a nice testcase for ensuring no copies are made of a & b -
        //  both are unconditionally & fully copied, so both fnargs, however annotated,
        //   should become vals, and only moves should remain here.
        //
        if (b.kind == "block")
        {
            b.items.unshift(a);
            return b;
        }

        return createBlock(type: b.type, [ a, b ]);
    }


    //

    shadow fn lookupUserType(type: Type): Struct
    {
        return tryLookupUserType(type)
            || fail("Not a struct nor custom primitive: " ~ humanizeType(type));
    }

    fn getBasePrim(type: Type): string
    {
        mut offset = type.canon.basePrimPrefixLen();
        if (offset < type.canon.len)
            return lookupUserType(type).basePrim;

        return type.canon;
    }

    fn parseBasePrimBitWidth(basePrim: string): u16
    {
        mut size: u16 = 0;
        for (mut i = 1; i < basePrim.len; i++) {
            size *= 10;
            size += basePrim[i++].u16 - '0'.u16;
        }

        return size;
    }

    fn solveInt(v: string, type: Type): Type
    {
        shadow let parse = intlit::Intlit(v);
        parse.error && fail(parse.error);

        fn check()
        {
            if (type && type.is_primitive)
            {
                let c = type.getBasePrim();

                fn want(t: Type)
                    c == t.canon;

                if (!parse.unsigned)
                {
                    if (parse.minsize_f <= 32 && want(t_f32) ||
                        parse.minsize_f <= 64 && want(t_f64) ||

                        parse.minsize_i <= 32 && want(t_i32) ||
                        parse.minsize_i <= 64 && want(t_i64) ||
                        parse.minsize_i <= 16 && want(t_i16) ||
                        parse.minsize_i <= 8  && want(t_i8 ))
                    {
                        return type;
                    }
                }

                if (!parse.signed)
                {
                    if (parse.minsize_u <= 32 && want(t_u32) ||
                        parse.minsize_u <= 64 && want(t_u64) ||
                        parse.minsize_u <= 16 && want(t_u16) ||
                        parse.minsize_u <= 8  && want(t_u8 ))
                    {
                        return type;
                    }
                }
            }

            if (parse.unsigned || !parse.signed && parse.base != 10)
            {
                if (parse.minsize_u <= 32) return t_u32;
                if (parse.minsize_u <= 64) return t_u64;
            }
            else
            {
                if (parse.minsize_i <= 32) return t_i32;
                if (parse.minsize_i <= 64) return t_i64;
            }

            return fail("Bad int literal.");
        }

        // No refs & basic abstract eval.
        shadow mut type = clear_refs(check());

        if !(options.dev & options::DEV_DontFoldLiterals)
            type.vfacts = parse.absval
                ? AlwaysTrue
                : AlwaysFalse;

        return type;
    }

    fn solveReal(
        /*TODO `f` suffix*/lax v: string,
        type: Type): Type
    {
        if (type.canon == t_f32.canon) return t_f32;

        return t_f64;
    }


    //

    fn solveInt(node: Node, type: Type): SolvedNode
        solved(node,
             solveInt(node.value, type));

    fn solveReal(node: Node, type: Type): SolvedNode
        solved(node,
             solveReal(node.value, type));


    //

    fn solveChar(node: Node): SolvedNode
    {
        return solved(node, t_byte);
    }

    fn solveString(v: string, type: Type): Type
    {
        //////////////////////////////////////////////
        // HACK - Retyping string literals to enums //
        if (type && type.is_primitive)
        {
            let members = tryLookupUserType(type).items;
            for (mut i = 0; i < members.len; i++)
                if (members[i].id == v)
                    return clear_refs(type);
        }
        //////////////////////////////////////////////

        mut ret = t_string;

        if !(options.dev & options::DEV_DontFoldLiterals)
            ret.vfacts = v.len
                ? AlwaysTrue
                : AlwaysFalse;

        return ret;
    }

    fn solveString(node: Node, type: Type): SolvedNode
    {
        return solved(node,
            type: solveString(node.value, type));
    }

    fn createEmpty(::kind = "empty", type = t_void, target?: Target): SolvedNode
    {
        return SolvedNode(:kind, :type, :target);
    }

    fn executeCompilerPragma(node: Node)
    {
        if (node.value != "break")
            return SolvedNode("pragma", :node.value,
                items: solveNodes(node.items, DeadBreak_Dont),
                 type: t_void);

        compilerBreak();
        return createEmpty();
    }


    //

    fn createBool(value: StaticEval): SolvedNode
    {
        return createBool(value == SE_True  ? "true"
                        : value == SE_False ? "false"
                        : BUG());
    }

    fn createBool(value: bool): SolvedNode
    {
        return createBool(value ? "true" : "false");
    }

    fn createBool(value: string, mut type = t_bool): SolvedNode
    {
        type.vfacts = value == "true"   ? AlwaysTrue
                    : value == "false"  ? AlwaysFalse
                    : BUG();

        return SolvedNode(kind: "bool", :value, :type);
    }


    //

    fn createTypeParam(value: string): Node
    {
        return Node(kind: "typeparam",
            :value, token: _here || BUG());
    }

    fn X_addrofTarget(targets: [Target])
        Type(ValueType(canon: packAddrOfFn(targets)));

    fn X_addrofTarget(target: Target)
        X_addrofTarget([ target ]);


    //

    fn CompoundArgID_outerSplice(ref name: string): string
    {
        mut exclam = false;

        for (mut i = 0; i < name.len; i++)
        {
            let c = name[i];

            // Strip internal argument name.
            if (c == '!')
            {
                exclam && BUG("CompoundArgID: double bang in `" ~ name ~ "`.");
                exclam = true;

                let i0 = i++;
                for ( ; i < name.len; i++)
                    if (name[i] == '.')
                        break;

                name.splice(i0, i - i0);
                i = i0 - 1;
                continue;
            }

            // Extract autocall expression.
            if (c == '.')
            {
                let ret = name.slice(i + 1);
                name.shrink(i);
                return ret;
            }
        }

        if (!exclam)
            BUG("CompoundArgID: no `.` nor `!` in id `" ~ name ~ "`.");

        return [];
    }

    fn getOrCreateChild(lax node: Node, onReuse, onCreate)
    {
        let parent = _current_fn.target;

        if (parent)
        {
            let parent_rev  = parent.revision;
            ref children    = parent.EPH_mut.children;

            for (mut i = 0; i < children.len; i++)
            {
                ref child   = children[i];
                if (child.token != node.token || child.parent_rev == parent_rev)
                    continue;

                child.parent_rev = parent_rev;

                let target = child.target;
                onReuse(target);
                return target;
            }
        }

        let target = Scope_create(_scope);
        onCreate(target);

        if (parent)
        {
            let parent_rev  = parent.revision;
            ref children    = parent.EPH_mut.children;

            children       ~= ChildTarget(:node.token, :parent_rev, target);
        }

        return target;
    }

    fn resetChild(target: Target)
    {
        if (target.is_SPECFAIL || target.kind == "template")
            return;

        ref status = GET_mut(target).status;
        status & SS_LAZY || BUG("resetChild: not SS_LAZY: " ~ target);
        status &= ~(SS_DID_START | SS_FINALIZED | SS_DIRTY);

        // Disconnect.
        let calls = steal(target.EPH_mut.calls);
        for (mut i = 0; i < calls.len; i++)
        {
            let callee = localfn(index: calls[i]);
            callee.EPH_mut.callers.set::rem(target.globid)
                || BUG("resetChild: Missing in callers on " ~ callee);
        }

        let callers = steal(target.EPH_mut.callers);
        for (mut i = 0; i < callers.len; i++)
        {
            let caller = localfn(index: callers[i]);
            caller.EPH_mut.calls.set::rem(target.globid)
                || BUG("resetChild: Missing in calls on " ~ caller);
        }

        // Without this recursive closures start feeding
        //  historical revisions of closed-over arguments
        //   back into the current solve.
        //
        ref args = EXT_mut(target).args;
        for (mut i = args.len; i --> 0; )
            if (args[i].flags & F_INJECTED)
                args.splice(i, 1);

        //
        target.calls && BUG();
    }

    fn uPrepFn_A(node: Node): SolvedNode
    {
        let id          = node.value;
        let local_of    = _current_fn.target.globid;
        let status      = SS_LAZY; // Actual template fns are eager.

        let target      = getOrCreateChild(node,

        onCreate: |target|
        {
            ref o           = GET_mut(target);
            o.kind          = "fn";
            o.name          = "prep " ~ node.value;
            o.flags         = node.flags;
            o.status        = status;

            ref ext         = target.EXT_mut;
            ext.template    = createTemplate(node);
            ext.min         = 0x7fffffff.i32;
            ext.max         = 0;
        },

        onReuse: |target|
        {
            resetChild(target);
        });

        //
        mut shadows     = !!(node.flags & F_SHADOW);
        autoshadow(:shadows, :local_of, :id);

        Scope_set(_scope, :target, :id, :shadows);

        // TODO DISJOINT cannotCOW false positive
        let scope_skip  = _current_fn && _ss;

        //
        ref eph         = target.EPH_mut;
        eph.local_of    = local_of;
        eph.scope_memo  = _current_fn && Scope_snap(_scope);
        eph.scope_skip  = scope_skip;

        // Experimental conversion functions.
        if (node.flags & F_CONVERSION)
            _scope.converts.push(target);

        return createFnDef(:target, type: X_addrofTarget(target));
    }

    fn createFnDef(type: Type, target: Target): SolvedNode
    {
        return SolvedNode(kind: "fndef", :type, :target);
    }


    //

    fn mangleSignature(args: [Argument]): string
    {
        mut mangle = "";
        for (mut i = 0; i < args.len; i++)
        {
            if (i)
                mangle ~= ", ";

            mangle ~= args[i].name;
            mangle ~= ':';
            mangle ~= serializeType(args[i], debug: "mangleSignature");
        }

        return mangle;
    }

    fn mangleArgTypes(args: [$T]): string
    {
        mut mangle = "";
        mut numNonInjected = 0;
        for (mut i = 0; i < args.len; i++)
        {
            let arg = args[i];

            // Injected arguments shouldn't affect the mangle,
            //  it doesn't affect the template matching.
            //
            // Uncomment the if (mangle.len > 15) below
            //  to observe the trash that this filters out.
            //
            if (typeof(arg) -> Argument && arg.flags & F_INJECTED)
                continue;

            if (numNonInjected++)
                mangle ~= ',';

            let argType: Type = arg;
            if (argType)
                mangle ~= serializeType(argType, debug: "mangle[$T]");
        }

        // if (mangle.len > 15)
        //     println("MANGLE: ", mangle);

        return mangle;
    }

    fn mangleArgTypes(
        args: [SolvedNode], reorder: Reorder,
        conversions: Target[][],
        REST_START: i32, REST_TYPE: Type): string
    {
        mut mangle = "";

        let REST_END = reorder ? reorder.map.len : args.len;
        let N = REST_END.min(REST_START);
        for (mut i = 0; i < N; i++)
        {
            if (i)
                mangle ~= ',';

            let callsiteIndex = reorder ? reorder.map[i] : i;

            if (conversions.len > i && conversions[i].len)
                mangle ~= serializeType(
                    GET(conversions[i].last).type, debug: "mangle.conv");

            else if (callsiteIndex >= 0 && callsiteIndex <= args.len)
                mangle ~= serializeType(
                    args[callsiteIndex].type, debug: "mangle.no-conv");
        }

        if (REST_START < REST_END)
        {
            if (REST_START)
                mangle ~= ',';

            mangle ~= serializeType(REST_TYPE, debug: "mangle[Nodes].rest");
        }

        return mangle;
    }


    //

    fn is_SPECFAIL(target: Target): bool
    {
        return !!(target._packed & 0x8000_0000_0000_0000);
    }

    fn getSpecs(parent_idx: i32)
    {
        return EPH_mut(parent_idx).specs;
    }

    fn trySpecialize(
        overloadIdx: Target, args: [SolvedNode], ref args_mangled: string,
        REST_START: i32, REST_TYPE?: Type,
        reorder?: Reorder, conversions?: Target[][])
            : Target
    {
        args_mangled ||= mangleArgTypes(
            :args, :reorder, :conversions,
            :REST_START, :REST_TYPE);

        //
        mut parent_idx = overloadIdx.local_of;
        {
            // If we're taking a closure as an argument,
            //  we're becoming a closure ourselves of whatever that closure is closing over -
            //   so that e.g. lifetime reasoning can have an easier time etc.
            //
            // TODO all of these must form up a common shadowing group -
            //  So nothing by the same name should come in from outer scope,
            //   and yet none of these things shadow each other.
            //
            for (mut i = 0; i < args.len; i++)
            {
                let arg_t = args[i];
                if (arg_t.isAddrOfFn)
                {
                    unpackAddrOfFn(arg_t.canon, |target|
                    {
                        if (target.locid || target.modid == module.modid)
                        {
                            let local_of = target.localOf;
                            if (parent_idx < local_of)
                                parent_idx = local_of;
                        }
                    });
                }
            }
        }

        // TODO memoize the whole mangle.
        //  Or use a hash here, perhaps nest them per template or smth.
        //   Also this prefix is nasty, unless we can reuse between modules.
        //
        // TODO perhaps reuse between modules?
        //  Would make the prefix stuff more meaningful.
        //
        let mangle = overloadIdx.modid ~ "#" ~ overloadIdx.globid ~ " " ~ args_mangled;
        return getSpecs(:parent_idx).map::get(mangle) || doTrySpecialize(:parent_idx,
            :overloadIdx, args_in:args, :mangle,
            :reorder, :conversions,
            :REST_START, :REST_TYPE)
                || BUG("doTrySpecialize returns empty target.");
    }


    //

    fn ScopeSkip_push(ref scope_skip: ScopeSkip[], start: i32, end: i32)
    {
        start <= end || BUG("ScopeSkip_push: bad args.");
        if (end == start)
            return;

        let last = scope_skip.if_last;
        last.end <= start || BUG("ScopeSkip_push: last.end > start.");

        // Opti - don't grow if possible, so we stay in small storage.
        if (scope_skip && last.end == start)
            scope_skip.last.end = end;
        else
            scope_skip ~= ScopeSkip(:start, :end);
    }


    //

    fn destroyOverload(t: Target)
    {
        TRACE_BRACKET("destroyOverload " ~ t.globid ~ " " ~ t);

        fn intoTombstone(shadow t: Target)
        {
            TRACE("intoTombstone " ~ t.globid ~ " " ~ t);

            ref ext = EXT_mut(t);
            ext = [];

            ref o = GET_mut(t);
            o = [];

            o.kind = "__tombstone";

            // Discard everything inside.
            let children = EPH(t).children;
            for (mut i = 0; i < children.len; i++)
                intoTombstone(children[i].target);

            let specs = EPH(t).specs;
            specs.each: |spec| intoTombstone(spec);
        }

        intoTombstone(t);

        // Is this necessary? This whole thing is a mess.
        // GET_mut(t).status |= SS_UPDATED;
        // lazySolveEnd(t);
    }


    //

    fn doTrySpecialize(
        parent_idx!: i32, into?: Target,
        overloadIdx?: Target, args_in?: [SolvedNode],
        mangle?: string, reorder?: Reorder, conversions?: Target[][],
        REST_START?: i32, REST_TYPE?: Type)
            : Target
    {
        PROFILE(.DoTrySpec);

        let SPECFAIL_RentrySafety =
            Target(_packed: 0x8000_0000_0000_0000);

        //
        let original = overloadIdx || into || BUG();
        mut template = original.template;

        // println    ("\n  BEGIN " template.node.value.qID "\t" args_in.len ": " mangle);
        // defer println("    END " template.node.value.qID "\n");

        ////////////////////
        let here0   = _here;
        defer _here = here0;
        _here       = original.template.node.token;
        ////////////////////

        //
        fn setSpec(shadow mangle: string, target: Target, nx!: bool, allowReplaceNonSpecfails?: bool)
        {
            ref t = getSpecs(:parent_idx).map::ref(mangle);

            fn id(shadow target)
                target.is_SPECFAIL  ? "SPEC_FAIL"
                                    : "`" ~ GET(target).name ~ "`";

            (!t == nx) && (!t || t.is_SPECFAIL || allowReplaceNonSpecfails) || BUG(
                "About to screw up royally, replacing spec: "
                    ~ t.globid ~ " with " ~ target.globid
                        ~ ", mangle: " ~ mangle ~ ", that's: "
                        ~ t.id ~ " becoming " ~ target.id);

            t = target;
        }

        //
        mut mangles: string[];
        mut currentSpec = SPECFAIL_RentrySafety;

        fn resetSpec(spec: Target, allowReplaceNonSpecfails?: bool)
        {
            if !(spec == currentSpec)
            {
                currentSpec = spec;
                for (mut i = 0; i < mangles.len; i++)
                    setSpec(mangles[i], spec, nx: false, :allowReplaceNonSpecfails);
            }
        }

        let resetMangle = |shadow mangle: string, allowReplaceNonSpecfails?: bool|
        {
            if (mangles.set::add(mangle))
            {
                let preexisting = getSpecs(:parent_idx).map::get(mangle);
                if (preexisting)
                {
                    mangles.set::rem(mangle);

                    if (!currentSpec.is_SPECFAIL)
                    {
                        TRACE("REPLACE " ~ currentSpec.globid ~ " " ~ currentSpec ~ " with " ~ preexisting.globid ~ " " ~ preexisting);

                        destroyOverload(currentSpec);
                    }

                    resetSpec(preexisting, :allowReplaceNonSpecfails);

                    return preexisting;
                }

                setSpec(mangle, currentSpec, nx: true);
            }
        };

        fn resetMangle(shadow args: [Type] or [Argument], allowReplaceNonSpecfails?: bool)
        {
            // TODO FIX
            let start = mangle.find(' ') + 1 || BUG();
            shadow let mangle = mangle.slice(0, start) ~ mangleArgTypes(args);
            resetMangle(mangle, :allowReplaceNonSpecfails);
        };

        fn SPECFAIL(reason: string)
        {
            let index       = _spec_errors.len;
            _spec_errors   ~= reason;

            let spec        = Target(
                :SPECFAIL_RentrySafety._packed | index.u64);

            resetSpec(spec);
            return spec;
        }

        //
        let items   = template.node.items;
        let numArgs = template.node.kind == "fn"
            ? items.len + FN_ARGS_BACK
            : BUG("template.node.kind != `fn`");


        // Arguments - type params.

        mut typeParams0 = steal(_typeParams);
        defer swap(_typeParams, typeParams0);

        if (!into)
        {
            mut error = "";

            mut args: Type[];
            if (reorder)
            {
                for (mut i = 0; i < reorder.map.len; i++)
                {
                    let callsiteIndex = reorder.map[i];
                    args.push(
                        callsiteIndex >= 0 && callsiteIndex < args_in.len
                            && args_in[callsiteIndex].type);
                }
            }
            else
            {
                for (mut i = 0; i < args_in.len; i++)
                    args.push(args_in[i].type);
            }

            for (mut i = 0; i < conversions.len; i++)
            {
                let c = conversions[i];
                if (c)
                    args[i] = GET(c.last).type;
            }

            if (REST_TYPE)
                args[REST_START] = REST_TYPE;

            /////////////////
            // Literal fixup.
            mut retypeIndices: i32[];

            //
            mut errout = [ Warning ];

            // First off, solve type params.
            for (   mut pass_retype  = 0;
                        pass_retype == 0 || pass_retype == 1 && retypeIndices;
                        pass_retype++)
            {
            //        /LITFIX
            /////////////////

                for (mut i = 0; i < numArgs; i++)
                {
                    if (pass_retype)
                    {
                        // TODO fix, .try_shift instead.
                        if (!retypeIndices.has(i))
                            continue;
                    }

                    mut inType  = args.len > i && args[i];
                    let inValue = reorder
                        ? reorder.map.len > i && reorder.map[i] >= 0 && args_in[reorder.map[i]]
                        : args_in.len > i && args_in[i];

                    let argNode = items[i] || BUG();
                    let annot   = argNode.items[LET_TYPE];

                    // Use previously solved argument defaults
                    //  to let all type params solve normally.
                    let host_arg = original.args[i];

                    shadow let inValue = inValue || {
                        inType = host_arg.default.type;
                        host_arg.default
                    };

                    /////////////////
                    // Literal fixup.
                    if (couldRetype(inValue))
                    {
                        if (!pass_retype)
                        {
                            retypeIndices.push(i);
                            continue;
                        }

                        let paramType =
                            annot.kind == "typeparam"
                                ? _typeParams.map::ref(annot.value).matched
                                : annot.kind == "call" && !annot.items
                                    && Scope_lookupType(annot.value, :annot.flags);

                        // Ignore literals if possible.
                        if (paramType)
                        {
                            let retype = tryRetyping(inValue, paramType);
                            if (retype && retype.canon != inType.canon)
                            {
                                inType = retype;
                                if (args.len > i)
                                    args[i] = inType;
                            }
                        }
                    }
                    //        /LITFIX
                    /////////////////

                    //////////////////////////////////////////////////////////////////////////////////////////////
                    // TODO FIX type unions can mess up when other args get defered and they get served first.  //
                    //  I think we should go quantum here, basically figure out everything this could be        //
                    //   and collapse along the way.                                                            //
                    if (!pass_retype && annot.kind == "typeunion")
                    {
                        retypeIndices.push(i);
                        continue;
                    }
                    //////////////////////////////////////////////////////////////////////////////////////////////

                    //
                    argNode.kind == "let"  || BUG();

                    //
                    if (inType)
                    {
                        // Replace any foreign lifetimes with Lifetime_temporay,
                        ref_anonymize(inType);

                        // Enable conversions on fully typed arguments.
                        let exactType = host_arg.type;
                        if (exactType)
                        {
                            if (args.len > i)
                                args[i] = exactType;

                            continue;
                        }

                        //
                        let argName = argNode.flags & F_COMPOUND_ID
                            ? cleanID(argNode.value)
                            :         argNode.value;

                        argName || BUG("No argName");

                        // Same pattern - grabs a mutref.
                        ref argName_typeParam = _typeParams.map::ref(argName);

                        let isTypedef = !!(argNode.flags & F_TYPENAME);

                        // TYPES vs VALUES //////
                        if (isTypedef)
                            inType.vfacts & Typename || BUG(
                                argName ~ " not a typename: " ~ humanizeType(inType));
                        else
                            inType = clear_Typename(inType); // See solveLetLike_dontTouchScope: t_init = clear_Typename
                        // TYPES vs VALUES //////

                        // TODO FIX VFACTS //////////////////////////
                        // Discard everything but typename.
                        inType.vfacts = isTypedef && Typename;
                        // TODO FIX VFACTS //////////////////////////

                        //
                        (argName_typeParam && fail(
                            "Type param name collision with " ~ host_arg ~ "."))
                                .matched = inType;

                        ////////////////////////////////////////
                        argName_typeParam.flags |= TP_isArgSpec;

                        if (isTypedef)
                            argName_typeParam.flags |= TP_isTypenameArgSpec;

                        // Type check.
                        if (annot)
                        {
                            let argOk = trySolveTypeParams(
                                annot, inType, :errout,
                                invariant: false);

                            if (!error && !argOk)
                            {
                                error = "arg".qKW ~ " " ~ argName.qID ~ ":";
                                errout.len > 1 || BUG("BUG trySolveTypeParams did not provide an explanation.");
                                for (shadow mut i = 1; i < errout.len; i++)
                                    error ~= "\n\t    " ~ errout[i].message;
                            }

                            if (error)
                                break;
                        }
                    }
                }
            }

            /////////////////
            // Literal fixup.
            resetMangle(args);
            //        /LITFIX
            /////////////////

            // Match pattern arm here.
            if (error)
                return SPECFAIL(error);
        }


        // Body pattern.

        fn isNativeBody(n_body: Node)
            n_body.kind == "call" && n_body.value == "__native";

        fn useConsumedType_ifNative(tp) // TODO (tp: TypeParam) test:useConsumedType
            tp.flags & (TP_isArgSpec | TP_isTypenameArgSpec) == TP_isArgSpec;

        fn n_fn = template.node;

        if (!into)
        {
            // Pattern matching.
            let body = items[items.len + FN_BODY_BACK] || BUG();
            if (body.kind == "pattern")
            {
                let undo = _typeParams;
                let branches = body.items;

                mut did_match = false;
                for (mut i = 0; i < branches.len; i++)
                {
                    let branch = branches[i].items;
                    let n_body = branch[branch.len + FN_BODY_BACK];

                    ////////////////////////////////////
                    // NATIVE RELAXER             [0] //
                    //  Tag all arg tps we want .consumed types on,
                    //   the flag is used by evalTypePattern.
                    if (n_body.isNativeBody)
                        _typeParams.each: |ref tp|
                            if (tp.useConsumedType_ifNative)
                                tp.flags |= TP_needsConsumedTypes;

                    // Fails cond if any?
                    let cond = branches[i].items[0];
                    if (cond && !evalTypePattern(cond))
                    {
                        _typeParams = undo;
                        continue;
                    }

                    // Pass.
                    fn sig = n_fn.items;
                    {
                        let n_ret = branch[branch.len + FN_RET_BACK];
                        if (n_ret) sig[sig.len + FN_RET_BACK] = n_ret;

                        sig[sig.len + FN_BODY_BACK] = n_body || BUG("doTrySpec: no case/body.");
                    }

                    did_match = true;
                    break;
                }

                // All branches mismatch?
                //  Can't return, faking RAII here.
                if (!did_match)
                    return SPECFAIL("No body pattern matched.");
            }

            ////////////////////////////////////
            // NATIVE RELAXER             [2] //
            //  We can't reason about the code of "native" fns,
            //   so we relax based on type assertions here.
            //
            let n_body = n_fn.items[n_fn.items.len + FN_BODY_BACK];
            if (n_body.isNativeBody)
            {
                // Can't use TP_needsConsumedTypes -
                //  only set when fn has patterns.
                _typeParams.each: |ref tp|
                    if (tp.useConsumedType_ifNative)
                        tp.matched = tp.consumed;
            }
            // NATIVE RELAXER                 //
            ////////////////////////////////////
        }

        // Scopes & scope skips.
        mut target: Target;

        {
            ////////////////////////////////////////////////////////////////
            let scope0          = Scope_snap(_scope);
            let ss0             = _ss;
            let helpers_data0   = _helpers_data.len;

            defer {
                Scope_pop(_scope, scope0);
                _ss             = ss0;

                _helpers_data.shrink(helpers_data0);
            }

            // Previously fn ScopeSkip_setup(original: Target, scope0: ScopeMemo)
            {
                if (_root_scope)
                {
                    let eph     = (original.spec_of || original).EPH;
                    let start   = eph.scope_memo || _root_scope;
                    _ss         = eph.scope_skip;

                    ScopeSkip_push(_ss.items,       start: start.items_len,     end: scope0.items_len);
                    ScopeSkip_push(_ss.implicits,   start: start.implicits_len, end: scope0.implicits_len);
                    ScopeSkip_push(_ss.imports,     start: start.imports_len,   end: scope0.imports_len);
                    ScopeSkip_push(_ss.privates,    start: start.privates_len,  end: scope0.privates_len);
                    ScopeSkip_push(_ss.usings,      start: start.usings_len,    end: scope0.usings_len);
                    ScopeSkip_push(_ss.converts,    start: start.converts_len,  end: scope0.converts_len);
                    ScopeSkip_push(_ss.helpers,     start: start.helpers_len,   end: scope0.helpers_len);
                }

                // We'll need the original imports in scope
                //  in order to solve type params & pattern match below.
                let imports = template.imports;
                for (mut i = 0; i < imports.len; i++)
                {
                    Scope_import(imports[i]);
                    if (i == 0)
                        Scope_import_privates(imports[i]);
                }
            }

            // Prep reject.
            target = into || Scope_create(_scope, status: SS_DID_START | SS_LAZY);

            TRACE_BRACKET("doTrySpecialize " ~ target.globid ~ " " ~ template.node.value ~ " " ~ mangle);

            ref eph = target.EPH_mut;
            eph.local_of = parent_idx;

            //
            let spec_extras = into
                ? into.spec_extras
                : (target.EPH_mut.spec_extras = _typeParams.intoSpecExtras());

            ///////////////////////////////////////////////
            let solvingFnort0   = _solvingFnort.exchange(target);
            let nestingFnort0   = _nestingFnort.exchange(target);

            defer {
                _solvingFnort   = solvingFnort0;
                _nestingFnort   = nestingFnort0;
            }
            ///////////////////////////////////////////////

            // Go!
            {
                shadow ref eph = target.EPH_mut;
                let rev0 = eph.revision++;
                if (rev0)
                {
                    if (rev0 >= 1024)
                        BUG("Looping forever: " ~ target ~ ".revision >= 1024");

                    ref o = EXT_mut(target);
                    o.locals.clear();

                    // This looks horrible but hope is
                    //  warnings array should be usually empty,
                    //   otherwise we'll likely emit an error on solved.
                    if (_warnings.len > target.globid)
                        _warnings[target.globid] = Warning();

                    //
                    let specs = target.specs.vals;
                    for (mut i = 0; i < specs.len; i++)
                        resetChild(specs[i]);
                }
            }

            let asserts     = template.node.asserts;

            mut out = CurrentFn(:scope0, :asserts,
                solved(n_fn,
                    :target, type: X_addrofTarget(target)),
                autoshadow_ok:
                    n_fn.flags & F_TEMPLATE ? 1 : 0);

            let root_scope0 = _root_scope;
            if (!root_scope0)
                _root_scope = scope0;

            swap(_current_fn, out);

            defer {
                swap(_current_fn, out);
                _root_scope = root_scope0;
            }

            /////////////////////////////////
            fn outItems() _current_fn.items;

            let inItems = n_fn.items;
            outItems.resize(inItems.len);

            // Arg decls.
            _scope.items ~= spec_extras.scope_items;

            //
            let isFirst     = !into || !into.solved;
            let isTemplate  = template.node.flags & F_TEMPLATE;
            let isSpec      = isTemplate && (!into || !isFirst); // TODO FIX this looks really flaky
            let isUnspec    = isTemplate && !isSpec;

            for (mut i = 0; i < inItems.len + FN_ARGS_BACK; i++)
            {
                let n_arg       = inItems[i];
                _here           = n_arg.token;

                // TODO FIX Template prep: mock up free parameters.
                //          Super unclean but at least its contained here.
                if (isUnspec && (n_arg.flags & F_TEMPLATE || !n_arg.items[LET_TYPE]))
                {
                    let init = n_arg.items[LET_INIT]
                            && solveNode(n_arg.items[LET_INIT]);

                    outItems[i] = SolvedNode(
                        kind: "let", flags: n_arg.flags, value: n_arg.value,
                        type: Type(), items: [ [], init, ]);

                    continue;
                }

                let specType    = isSpec && spec_extras
                    .arg_spec_types.map::get(
                        n_arg.flags & F_COMPOUND_ID
                            ? cleanID(n_arg.value)
                            :         n_arg.value);

                let arg         = solveLet(n_arg, :specType);
                outItems[i]     = arg;
            }

            /////////////////////////////////////////////////////
            let n_ret   = !isUnspec && inItems[inItems.len + FN_RET_BACK];
            let n_body  = inItems[inItems.len + FN_BODY_BACK];

            // Builtin?
            n_body || BUG("solveFn: no body.");

            let isNative = n_body.isNativeBody;

            // Return type annot.
            let ret_expect = n_ret && evalTypeAnnot(n_ret);

            // Seed return value.
            mut ret_seed = n_ret    ? ret_expect || BUG("falsy ret_expect: " ~ n_fn.value)
                                    : t_AssumeNever_WhileSolvingRecursion;

            if (ret_seed.lifetime)
            {
                ret_seed.lifetime = isNative
                    ? Lifetime_fromNative(inItems, _current_fn.items[: _current_fn.items.len + FN_ARGS_BACK], ret_seed)
                    : Lifetime_static(); // we'll overpromise during prep
            }

            // Used twice, once to enable recursion before body, and once when done.
            fn updateScope(shadow out: CurrentFn, mut retval: Type, maybeLast!: bool)
            {
                _here = n_fn.token || BUG();

                ///////////////////////////////
                if (target.status & SS_DIRTY)
                {
                    // Some pass might not have ran,
                    //  so updating the signature might not be safe,
                    //   or might make it unstable.
                    //
                    // --------------------------------------------------------
                    // OPTIMIZABLE (about 10% slowdown from this):
                    //  It's OK to update the sig if:
                    //   - new retval is assignable to old retval.
                    //   - old arguments are assignable to new arguments.
                    // --------------------------------------------------------
                    //

                    TRACE("SS_UPDATED because SS_DIRTY " ~ target.globid ~ " " ~ target);

                    GET_mut(target).status |= SS_UPDATED;
                    return;
                }
                ///////////////////////////////

                shadow let items = out.items;
                shadow let mustBecomeInline = currentFn_mustBecomeInline();

                let N = items.len + FN_ARGS_BACK;
                mut min = 0;
                mut max = 0;

                let NativeHacks =
                    isNative && hacks::NativeHacks(target.name);

                mut numArgsWritten = 0;

                // argTarget -> argIndex mapping.
                mut argPos_1b: i32[];
                for (mut i = 0; i < N; i++)
                {
                    let argNode     = items[i];
                    let argTarget   = argNode.target;
                    if (argTarget)
                        argPos_1b.grow_if_oob(argTarget.locid) = i + 1;
                }

                //
                shadow mut args: Argument[];
                for (mut i = 0; i < N; i++)
                {
                    let argNode = items[i];

                    argNode.kind == "letdef" || argNode.target
                        && BUG("Argnode is not letdef, but has a target: "
                                ~ argNode.target);

                    shadow let argNode = argNode.kind == "letdef"
                        ? argNode.target.solved
                        : argNode;

                    argNode.kind == "let" || argNode.kind == "empty" || BUG();

                    //
                    mut name        = argNode.value;
                    let autocall    = argNode.flags & F_COMPOUND_ID && CompoundArgID_outerSplice(name);
                    let isImplicit  = !!(argNode.flags & F_IMPLICIT);
                    let isInjected  = !!(argNode.flags & F_INJECTED);

                    // ARGUMENTS AT RISK ////////////////////////
                    let argTarget   = argNode.target;
                    let written_via = !isUnspec
                        && argNode.type.is_mutref
                        && (isNative || out.ever_written.has(argTarget.locid));

                    mut soft_risk: bitset::BitSet;
                    mut hard_risk: bitset::BitSet;
                    if (written_via)
                    {
                        numArgsWritten++;

                        if (isNative)
                        {
                            // Natives: we can't see inside, assume everything restricted.
                            soft_risk.add_range(end: N);
                            soft_risk.rem(i);

                            if (!NativeHacks.soft_risk)
                                hard_risk = soft_risk;
                        }
                        else
                        {
                            fn ArgsAtRisk_list(
                                ref output: bitset::BitSet, at_risk: bitset::BitSet[])
                            {
                                at_risk.unless_oob(argTarget.locid).each: |other|
                                {
                                    let otherPos_1b = argPos_1b.unless_oob(other);
                                    if (otherPos_1b)
                                        output.add(otherPos_1b - 1);
                                }
                            }

                            soft_risk.ArgsAtRisk_list(out.flow.at_soft_risk);
                            hard_risk.ArgsAtRisk_list(out.flow.at_hard_risk);

                            if (argNode.type.TODO_FIX_isArray)
                            {
                                ////////////////////////////////////////////////////////////////
                                // TODO FIX soft risk doesn't interop well
                                //  with conversions to slices -
                                //
                                // When an array binds to a slice arg, that caches the array's length -
                                //  Relocating the array via another arg looks like soft-risk to bck,
                                //   but, the way we cg, the view is left dangling.
                                ////////////////////////////////////////////////////////////////

                                mut soft = soft_risk;
                                soft.and_not_assign(hard_risk);

                                soft.each: |index: i32|
                                {
                                    let other = items[index].target.solved;
                                    if !(other.type.TODO_FIX_isArray)
                                        hard_risk.add(index);
                                }
                            }
                        }
                    }
                    /////////////////////////////////////////////

                    // Validate `pure` asserts.
                    // TODO FAILCASE
                    // TODO FAILCASE these dont work for inline fns
                    // TODO FAILCASE
                    if (asserts & A_PURE && written_via)
                        fail(backtrack: "pure", target ~ " is not pure, writes to " ~ argTarget ~ ":\n"
                            ~ qSTACK(:target, :argTarget.locid,
                                        node: out.out));

                    if (asserts & A_PURE_CTX && isImplicit && written_via)
                        fail(backtrack: "purectx", target ~ " is not purectx, writes to " ~ argTarget ~ ":\n"
                            ~ qSTACK(:target, :argTarget.locid,
                                        node: out.out));

                    if (maybeLast && asserts & A_NOVEC && !argNode.isNoVec() && !mustBecomeInline)
                        fail(backtrack: "novec", target ~ " is not novec, " ~ argTarget ~ " is " ~ humanizeType(argNode.type) ~ ":\n"
                            ~ qSTACK(:target, :argTarget.locid,
                                        node: out.out,
                                       query: AQ_WhyNotNovec));

                    //
                    let cow_inside = out.events.cows_inside.some(
                        |cow| cow.argTarget == argTarget.locid);

                    //
                    if (SELF_TEST) {
                        if (soft_risk.has(i)) BUG("updateScope: " ~ argTarget ~ " soft_risk lists self");
                        if (hard_risk.has(i)) BUG("updateScope: " ~ argTarget ~ " hard_risk lists self");
                    }

                    //
                    let may_alias       = hard_risk.negated(end: N);
                    let may_invalidate  = soft_risk.negated(end: N);

                    if (SELF_TEST) {
                        if (may_alias.popcount      > N) BUG("updateScope: " ~ argTarget ~ " may_alias.popcount > N");
                        if (may_invalidate.popcount > N) BUG("updateScope: " ~ argTarget ~ " may_invalidate.popcount > N");
                    }

                    //
                    mut arg = Argument(
                        :name,
                        :autocall,
                        :argNode.flags | (written_via && F_WRITTEN_TO)
                                       | (cow_inside  && F_COW_INSIDE),
                        :argNode.type,
                        default: !isImplicit && argNode.items && argNode.items[LET_INIT],
                        target: argTarget,

                        // Previously soft_risk & hard_risk.
                        :may_alias, :may_invalidate);

                    // TODO make this true for F_INJECTEDs too.
                    if (arg.type.lifetime && !(arg.flags & F_INJECTED))
                        arg.type.lifetime == Lifetime_temporary || BUG("Non-temporary lt on ref arg: " ~ argTarget);
                    else
                        ref_anonymize(arg.type);

                    //
                    if (SELF_TEST)
                    {
                        arg.type || isUnspec || BUG(
                            "updateScope: Unexpected untyped argument.");

                        arg.type.vfacts & (AlwaysTrue | AlwaysFalse)
                            && arg.type.usage
                            && !hacks::tryParseClosureID(id: arg.name)
                            && BUG("updateScope: arg.type is AlwaysTrue/False.");
                    }

                    // Previously this was `if (!isImplicit)`,
                    //  but consider a `fn f(implicit a)`:
                    //   it's nice to be able to pass `a` as usual, e.g. `f(something)`,
                    //    when you don't want a `let implicit a = something;` outside,
                    //     esp given that `implicit` in an arg decl does two things -
                    //      a] enables implicit defaulting, and
                    //      b] whitelists the argument for implicit binding downstream.
                    //
                    // So, when you only need b], this allows you not to pay for a].
                    //
                    if (!isInjected)
                    {
                        if (max != 0x7fffffff.i32)
                            max++;
                        if (!arg.default && !isImplicit)
                            min++;
                    }

                    if (arg.flags & F_REST_ARG)
                        max = 0x7fffffff.i32;

                    args.push(arg);
                }

                // Prep lifetimes for Lifetime_replaceArgsAtCallsite,
                //  and unref all args that are pass-by-value.
                //
                {
                    mut returned: bitset::BitSet;

                    if (SELF_TEST && retval.is_ref)
                        TEST_Lifetime(type: retval, retval.lifetime);

                    retval.lifetime = retval.lifetime.Lifetime_process(
                        |locid, isStatic, continue_keep, continue_replace, paths|
                        {
                            if (!locid)
                            {
                                isStatic || BUG("Non-local/non-static in retval.lifetime.");
                                continue_keep;
                            }
                            else
                            {
                                shadow let argPos_1b = argPos_1b.unless_oob(locid) || BUG(
                                    "Non-argument local in retval.lifetime: " ~ nested(locid));

                                let i   = argPos_1b - 1;
                                let arg = args[i];

                                arg.type.is_ref || BUG(
                                    "Non-ref argument in retval.lifetime: " ~ nested(locid));

                                returned.add(i);

                                continue_replace(
                                    Lifetime_from(argidx: i, :paths));
                            }
                        });

                    for (mut i = 0; i < args.len; i++)
                    {
                        if (returned.has(i))
                            continue;

                        ref arg = args[i];
                        if (arg.type.is_ref && arg.willPassByValue())
                            arg.type = clear_refs(arg.type);
                    }
                }

                //
                retval || BUG("updateScope: no return type.");
                if (retval.is_ref)
                {
                    // TODO FIX: ZST arguments can get unused-removed,
                    //  which can leaves behind a dead region in the retval lifetime.
                    //
                    if (retval.isIrrelevant)
                        retval.lifetime = Lifetime_static;

                    TEST_Lifetime(type: retval,
                        retval.lifetime, argPositionsOK: true);
                }

                retval.lifetime.Lifetime_each: |isArgIdx, isStatic|
                    isArgIdx || isStatic || BUG(
                        "updateScope: Non-static/non-arg leaked:\n\t" ~ retval.lifetime);

                // Unconditionally replacing the stuff.
                let overload    = GET(target);
                ref ext         = target.EXT_mut;

                mut change      = false;

                let hasCallers  = !!target.callers;
                if (hasCallers)
                {
                    change ||= args.len != ext.args.len
                           || !(overload.type == retval);

                    if (!change) for (mut i = 0; i < args.len; i++)
                    {
                        let a = args[i];
                        let b = ext.args[i];

                        fn ignoreLocalLts(type: Type)
                        {
                            if (SELF_TEST && type.is_ref)
                                type.lifetime == Lifetime_temporary || BUG(
                                    "type.lifetime != Lifetime_temporary");

                            return type;
                        }

                        if !(a.name == b.name && a.type.ignoreLocalLts == b.type.ignoreLocalLts)
                        {
                            change = true;
                            break;
                        }
                    }
                }

                ext.min     = min;
                ext.max     = max;
                ext.args    = args;

                if (!isNative)
                    ext.fx_mask = out.fx_mask;

                ext.cows_inside = out.events.cows_inside;

                // TODO FAILCASE
                // TODO FAILCASE these dont work for inline fns
                // TODO FAILCASE
                asserts & A_NOTHROW && ext.fx_mask & Fx_Throws && fail(
                    target ~ " is not nothrow, throws here:\n"
                        ~ qSTACK(:target, Fx_Throws, node: out.out));

                asserts & A_NOCRASH && ext.fx_mask & Fx_Crashes && fail(
                    target ~ " is not nocrash, can crash here:\n"
                        ~ qSTACK(:target, Fx_Crashes, node: out.out));

                asserts & A_NOIO && ext.fx_mask & (Fx_Input|Fx_Output) && fail(
                    target ~ " is not noio, performs I/O here:\n"
                        ~ qSTACK(:target, Fx_Input|Fx_Output, node: out.out));

                asserts & A_PURE_FX && ext.fx_mask & Fx_Output && fail(
                    target ~ " is not purefx, outputs here:\n"
                        ~ qSTACK(:target, Fx_Output, node: out.out));

                asserts & A_NOFLOW && _current_fn.far_jumps && fail(
                    target ~ " is not noflow: contains non-local control flow, jumping out to "
                        ~ localfn(index: _current_fn.far_jumps[0]) ~ ".");

                if (maybeLast && !mustBecomeInline)
                    numArgsWritten || ext.fx_mask || !retval.is_void || overload.flags & F_LAX || warn(:out.token,
                        target ~ " does nothing: returns void and has no effects. Make it " ~ "lax".qKW ~ " if this is intentional.");

                //
                shadow ref overload = GET_mut(target);
                overload.type       = retval;
                overload.flags      = out.flags;

                let kind: ::kind    = isUnspec          ? "template"
                                    : isNative          ? "__native"
                                    : mustBecomeInline  ? "inline"
                                                        : "fn";
                if (kind != overload.kind)
                {
                    overload.kind   = kind;
                    change          = true;
                }

                // Not amazing but it is what it is,
                //  these are the only calls c++ guarantees order of eval for,
                //   and generally js, rust & co behave in the same manner, so why not.
                //
                // 16) Every overloaded operator obeys the sequencing rules of
                //      the built-in operator it overloads when called using operator notation.
                //
                // 20) In every simple assignment expression E1=E2\
                //      and every compound assignment expression E1@=E2,
                //       every value computation and side-effect of E2 is
                //        sequenced before every value computation and side effect of E1.
                {
                    let rtl = args.len == 2
                        && overload.flags & F_OPERATOR
                        && cpp::hasAssignment(overload.name);

                    overload.isRTL_set(rtl);
                }

                //
                let solved = !isUnspec && out.out;

                if (hasCallers)
                {
                    if (!change && kind == "inline")
                    {
                        fn astChange(a: SolvedNode, b: SolvedNode)
                        {
                            if (a.kind != b.kind || a.items.len != b.items.len)
                                return true;

                            for (mut i = a.items.len; i --> 0; )
                                if (astChange(a.items[i], b.items[i]))
                                    return true;

                            return false;
                        }

                        change = astChange(overload.solved, solved);
                    }

                    if (change)
                    {
                        TRACE("SS_UPDATED because change==true " ~ target.globid ~ " " ~ target
                            ~ " callers=[" ~ currentSpec.callers.map(|c| c ~ " " ~ c.localfn).join(", ") ~ "]");

                        overload.status |= SS_UPDATED;
                    }
                }

                overload.solved = solved;

                //
                if (!isNative && !isUnspec)
                {
                    // "namespacing" via the sighash hashes.
                    let sourceModid             = template.node.token.modid;
                    shadow let shortModuleName  = sourceModid != module.modid
                        ? sourceModid && module.modid && getShortModuleName(ctx.modules[sourceModid].fname)
                        : shortModuleName;

                    let sig     = (target.local_of && target.globid.str)
                                ~ shortModuleName
                                ~ target.args.map(
                                    |arg| arg.flags & F_INJECTED
                                        ? ""
                                        : arg.name ~ ":" ~ stableTypeID(arg.type))
                                            .join(",");

                    EXT_mut(target).sighash = sig
                        && (tea::hash62(sig) || BUG());
                }

                // setSpecs & co.
                if (!into)
                {
                    resetMangle(target.args, allowReplaceNonSpecfails: maybeLast);
                    resetSpec(target);
                }
            }

            // Enable recursion.
            if (isFirst)
            {
                mut name = "";
                mut fx_mask: FxMask;

                // __native(id) or __native("include", id)
                if (isNative)
                {
                    for (mut i = 0; i < n_body.items.len; i++)
                    {
                        let item = n_body.items[i].value;
                        if (item.starts(with: '|'))
                            fx_mask |= item == "|output"
                                ? EFFECTS_output
                                : parse(item[1 :], as: FxMask) || BUG("Invalid |Fx mask: " ~ item.qBAD);
                        else
                            name ~= "\n" ~ item;
                    }
                }

                //
                name ||= n_fn.value || BUG("TODO anonymous fns");

                ref overload        = GET_mut(target);
                overload.name       = name;

                ref ext             = target.EXT_mut;
                ext.template        = template;
                ext.spec_of         = overloadIdx;
                ext.fx_mask         = fx_mask;

                //
                updateScope(_current_fn,
                    retval:    ret_seed,
                    maybeLast: isNative && !isUnspec);
            }

            mut didSetBody = false;

            // Regular fns again.
            if (!isUnspec && !isNative)
            {
                // RECURSIVE RELAX //////////////////////////////////
                // This makes it possible to relax functions
                //  that overconstrain recursive arguments,
                //   e.g. take a ref, pass it to themselves,
                //    and do nothing else with it.
                //
                if (isFirst)
                {
                    ref ext = EXT_mut(target);
                    for (mut i = 0; i < ext.args.len; i++)
                        ext.args[i].type.force_relax(
                            relax_mask: RELAX_all &~ q_USAGE);

                    // Make sure mutually recursive fns don't dump each other.
                    ext.fx_mask |= Fx_NotDeadCode | Fx_Throws;
                }
                // RECURSIVE RELAX //////////////////////////////////

                // This is a build speed opti -
                //  the idea being, on subsequent solves,
                //   we unlist ourselves as a caller before we start solving,
                //    so that if we indirectly invalidate a some function by calling another,
                //     it won't invalidate us unless we've called it during this solve.
                //
                if (OPTI_unlist_callers)
                {
                    let self = target.globid;
                    let calls = steal(target.EPH_mut.calls);
                    for (mut i = 0; i < calls.len; i++)
                    {
                        let call = localfn(index: calls[i]);
                        call.EPH_mut.callers.set::rem(self) || BUG(
                            "doTrySpec: " ~ target ~ " not listed as a caller of " ~ call);
                    }
                }

                // Sanity check / document the status stuff,
                //  I tend to forget how these flags work.
                let status = target.GET_mut.status &= ~SS_Debug_AllPassesComplete;
                if (status & (SS_DIRTY | SS_FINALIZED | SS_DID_START) != SS_DID_START)
                    BUG(target ~ " is not SS_DID_START just before solve: " ~ status);

                // This got defered here to avoid inline-recursions before first solve.
                _current_fn.TODO_FIX_isInline = !!(template.node.flags & F_INLINE);

                //
                mut s_body: SolvedNode;
                {
                    PROFILE(.SolveBody);

                    s_body = solveBlock(
                        n_body, type: ret_expect,
                        fnbody_of: target.globid,
                        id: n_fn.value,
                        mask: HM_Function | HM_CanReturn | HM_LabelUsed | (n_fn.flags & F_LAMBDA && HM_Lambda));
                }

                //
                let retval = s_body.helpers.ret_actual || BUG("doTrySpec: no body.ret_actual");

                // MUT DURING SOLVE,
                //  implicit args splice in
                let idx_body = outItems.len + FN_BODY_BACK;
                outItems[idx_body] = s_body || BUG("falsy body");
                didSetBody = true;

                //
                updateScope(_current_fn, :retval, maybeLast: true);
            }

            if (!didSetBody)
            {
                let o = GET(target);
                o.kind != "fn" || BUG(
                    "did not set body on " ~ o ~ ": " ~ humanizeType(o.type));
            }
        }

        // Go!
        lazySolveEnd(target);
        return target;
    }


    //

    fn sortInjectedArguments()
    {
        fn compare(a: SolvedNode, b: SolvedNode)
        {
            shadow let a = GET(a.target);
            shadow let b = GET(b.target);

            let an = a.name;
            let bn = b.name;
            let acid = hacks::tryParseClosureID(id: an);
            let bcid = hacks::tryParseClosureID(id: bn);

            if (acid)
            {
                if (bcid)
                {
                    // Originally it was by modid, then by index,
                    //  flipping b-a.modid || a-b.index since modid was neg,
                    //   doesnt matter which way you go.
                    let cmp = bcid.target.globid - acid.target.globid
                           ||  acid.target.locid - bcid.target.locid;

                    return cmp < 0;
                }

                return true;
            }
            else if (bcid)
            {
                return false;
            }

            return an < bn;
        }

        // Find first injected.
        ref args = _current_fn.items[: _current_fn.items.len + FN_ARGS_BACK];

        for (mut i = 0; i < args.len; i++)
        {
            let arg = args[i];
            if (arg.target && arg.target.flags & F_INJECTED)
                return args[i :].sort(fn compare);
        }
    }


    //

    fn intoSpecExtras(typeParams: TypeParams): SpecExtras
    {
        mut res: SpecExtras;

        // TODO FIX DISJOINT -
        //  tried passing _scope as an item to createTypedef,
        //   getting AAR errors from _ss, should be disjoint-ok.
        let scopeItems0 = _scope.items.len;

        typeParams.map::pairs(|id, tp|
        {
            let type = tp.matched;
            if (!type)
                continue;

            // Argument spectypes.
            if (tp.flags & TP_isArgSpec)
            {
                res.arg_spec_types.map::set(id, type);
                continue;
            }

            // Actual typedefs.
            createTypedef(id, type);
        });

        res.scope_items = _scope.items.steal(start: scopeItems0);

        return res;
    }


    // :(

    fn field_packOffset(ref o: Overload, memberFlatOffset!: i32, memberFlatCount!: i32)
    {
        let packed = memberFlatOffset | memberFlatCount << 16;

        if (SELF_TEST)
        {
            o.kind == "field" || BUG(
                "field_packOffset: Not a field.");

            // TODO FIX: this doesn't work with recursion.
            // !o.solved.helpers || o.solved.helpers.index == packed || BUG(
            //     "field_packOffset: Helpers already set to something else.");
        }

        o.solved.helpers = Helpers(packed);
    }

    fn field_unpackOffset(o: Overload)
    {
        if (SELF_TEST) o.kind == "field" || BUG(
            "field_unpackOffset: Not a field.");

        struct UnpackedOffset {
            memberFlatOffset: i32;
            memberFlatCount:  i32;
        };

        let packed = o.solved.helpers.index;

        return UnpackedOffset(
            memberFlatOffset: packed & 0xffff,
            memberFlatCount:  packed >> 16);
    }


    //

    fn TODO_FIX_getSpecPat(): string
    {
        let spec_of = _current_fn.target && _current_fn.target.spec_of;
        if (!spec_of)
            return "";

        mut specPat = "";
        for (mut i = 0; i < _current_fn.out.items.len + FN_ARGS_BACK; i++)
        {
            let arg = _current_fn.out.items[i];

            shadow let arg = arg.kind == "letdef"
                ? arg.target.solved
                : arg;

            if (!specPat) {
                specPat = "(";
                specPat.appendGlobal(spec_of);
            }

            specPat ~= ":";
            specPat ~= serializeType(arg.type, debug: "TODO_FIX_getSpecPat");
        }

        if (specPat)
            specPat ~= ")";

        return specPat;
    }


    //

    fn createRawTypedef(
        id: string, mut type: Type, flags: Flags, name?: string,
        status?: SolverStatus)
    {
        type        = into_Typename(type);
        let target  = Scope_create(_scope, "type", :type, :flags, name: name || id, :status);

        if (id)
            Scope_set(_scope, :id, :target, shadows: !!(flags & F_SHADOW));

        return target;
    }

    fn createTypedef(id: string, annot: Type, flags?: Flags)
    {
        let s = tryLookupUserType(annot);

        if (s.target && !(flags & F_PUB))
        {
            // TODO FIX we need to clone the typedef
            //  if we have to republish it,
            //   Scope_exports picks up F_PUBs with this modid only.
            //
            return Scope_set(_scope, :id, :s.target, shadows: !!(flags & F_SHADOW));
        }

        // Nope, create a new typedef.
        let target = createRawTypedef(id, annot, :flags);
        if (s.target)
        {
            // TODO FIX this is a horrible fix that's gonna bite back.
            //  The problem is with how pubs work & default constructors work.
            //
            // 1. Previously we just Scope_set the old target,
            //     but it didn't PUB correctly because its modid is foreign.
            //
            // 2. Alternatively, without this, the default constructor doesn't work.
            //
            GET_mut(target) = GET(s.target);
            EXT_mut(target) = EXT(s.target);
        }
    }

    fn solveTypedef(node: Node, specType!?: Type): SolvedNode
    {
        if (node.items[LET_TYPE])
        {
            _here = node.items[LET_TYPE].token;
            fail("Type annotations on type aliases are not supported.");
        }

        if (specType && !(specType.vfacts & Typename))
            BUG("solveTypedef: specType is not a Typename");

        let annot = specType || evalTypeAnnot(
            node.items[LET_INIT] || fail(
                "Type aliases must be initialized."));

        ////////////////////////////////////////////////////////////////
        let id = node.flags & F_COMPOUND_ID
            ? cleanID(node.value)
            :         node.value;
        ////////////////////////////////////////////////////////////////

        createTypedef(id, :annot, :node.flags);

        if (node.flags & F_ARG)
        {
            // TODO FIX adding this for the benefit of the arguments mangler,
            //  making the type fully unused so it gets eliminated by codegen,
            //   this is total lolcode.
            //
            // TODO consider reverting this along with the typedefs stuff,
            //  and just parse `type T` arguments as `lax _: type T` annotations,
            //   along with declaring the type argument, I think we're gonna end up
            //    with something more robust, this is stupid.
            //
            // Aside from this block these are the hashes we want reverted:
            // commit 8a4c6fdbdee697c601b1f2c81920b88525bf0d31 F_TYPENAME args
            // commit bbe551348384451d1172fdfa095c0228ffdfd2dd F_TYPENAME instead of typedef
            //
            // ALTERNATIVELY -
            //  This might be obsoleted by mangle-and-deduplicate-by-content instead of signature -
            //   after the initial signature mangle, we should mangle by the code we got,
            //    and merge functions that end up emitting the same stuff.
            //
            mut relaxed = annot;
            relaxed.quals &= ~q_USAGE;          // otherwise cg starts picking them up :(
            return createEmpty(type: relaxed);
        }

        return createEmpty();
    }


    //

    fn uPrepStruct(node: Node, TODO_FIX_useSpecPath!?: bool): SolvedNode
    {
        return __solveStruct(solve: false, :node, :TODO_FIX_useSpecPath);
    }

    fn __solveStruct(shadow solve!: bool, node: Node, into!?: Target,
        TODO_FIX_useSpecPath!?: bool): SolvedNode
    {
        PROFILE(.SolveStruct);

        let origId      = node.value;

        mut name        = origId ||
            ((_current_fn.target && _current_fn.target.name) || "Anon")
                ~ (_current_fn.TODO_FIX_unique++ && "_" ~ _current_fn.TODO_FIX_unique++);

        {
            mut unique = "";
            _typeParams.each: |tp, key|
                (unique ? unique ~= "," : unique)
                   ~= key ~ ":" ~ stableTypeID(tp.matched);

            if (unique)
                name ~= "_" ~ tea::hash62(unique);
        }

        let kind        = node.kind;
        let isStruct    = kind == "struct";
        let isUnion     = kind == "union";

        let isPrimDecl  = !isStruct && !isUnion;

        //
        mut basePrimType:   Type;
        mut basePrim:       string;

        if (isPrimDecl)
        {
            let baseannot   = node.items[STRUCT_BASE];
            basePrimType    = baseannot
                ? evalTypeAnnot(baseannot)
                : t_u8; // TODO decide later

            basePrim        = getBasePrim(basePrimType);
        }

        //
        let asserts = node.asserts;

        mut out_target  = into;
        mut out_type: Type;

        //
        mut shape_hasher = tea::hash(origId);

        mut shape = Shape(
            :basePrim,
            non_triv_mask:  0,
            hash:           shape_hasher.u64,

            flatCount:      isPrimDecl && 1,
            // bit_width:      isPrimDecl && parseBasePrimBitWidth(basePrim),

            declDepth:      0);

        if (isPrimDecl)
            shape_hasher.hash(basePrim);

        if (out_target)
        {
            out_type    = out_target.type;
        }
        else
        {
            // TODO FIX see canon_tryIntersect/_tryUnion,
            //  they can only handle single specpats correctly.
            //
            let specPat = !origId
                && TODO_FIX_useSpecPath
                && TODO_FIX_getSpecPat();

            //
            out_type    = initStruct(:kind, :shape, :name, :asserts, :specPat);
            out_target  = createRawTypedef(id: origId, :name,
                type: out_type, :node.flags,
                status: SS_LAZY);

            out_target.EXT_mut.template = createTemplate(:node);
        }

        // Trying to push this down now.
        if (!solve)
            return createEmpty(target: out_target);

        ///////////////////////////////////////////////
        let solvingFnort0   = _solvingFnort.exchange(out_target);
        defer _solvingFnort = solvingFnort0;
        ///////////////////////////////////////////////

        GET_mut(out_target).status |= SS_DID_START;

        ///////////////////////////////////////////////
        let helpers0 = _helpers.len;
        let helpers_data0 = _helpers_data.len;
        defer {
            _helpers.shrink(helpers0);
            _helpers_data.shrink(helpers_data0);
        }

        push(HelpersData(mask: HM_Struct, target: out_target || BUG(
            "solveStruct: no out_target: `" ~ origId ~ "`.")));
        ///////////////////////////////////////////////

        // Struct fields only.
        mut structConverts: Target[];
        mut structImports:  i32[];

        mut non_triv_reason = !out_type.is_rx_copy && -1;

        // Solve members & check defaults.
        let primType = isPrimDecl && clear_Typename(
            out_type || BUG("Falsy isPrimDecl.out_type"));

        fn solveMember(shadow node: Node)
        {
            node.kind == "let" || BUG("solveStructMembers_1: " ~ node.kind);

            if (!isPrimDecl)
                node.items[LET_INIT] &&
                node.items[LET_INIT].kind != "definit" &&
                    fail("All structs must be zerofilled by default."
                        ~ " Please remove the initializer of struct member `" ~ node.value ~ "`.");

            mut ret = solveLetLike_dontTouchScope(node, :primType);

            // TODO FIX VFACTS //
            ret.type.vfacts = [];
            // TODO FIX VFACTS //

            // Can't continue/return back/fwd compat.
            return ret;
        }

        let items   = node.items && node.items[STRUCT_MEMBERS].items;
        let members = items.map(fn solveMember);

        // (Re)poplate fields.
        {
            ref innerScope = lookupUserType_mut(out_type.canon).items;
            if (!innerScope && members)
            {
                let isUnscoped = !!(node.flags & F_USING);

                // Dereferencing a struct does not require it
                //  to have any particular qualities.
                let args = !isPrimDecl
                    ? [ Argument(name: "this",
                                 type: despeculateStruct(out_type)) ]
                    : [ Argument(name: "This",
                                 type: into_Typename(out_type),
                              default: isUnscoped
                                    && createEmpty(type: into_Typename(out_type))) ];

                for (mut i = 0; i < members.len; i++)
                {
                    let id = items[i].value;

                    // `true` fields.
                    let isPredicate = items[i].flags & F_PREDICATE;

                    let target = Scope_create(
                        _scope, !isPrimDecl ? "field" : "enumv", name: id || BUG(),
                        flags: F_PUB | isPredicate);

                    ref ext     = EXT_mut(target);
                    ext.args    = args;
                    ext.min     = isUnscoped && isPrimDecl ? 0 : args.len;
                    ext.max     = args.len;

                    // For snippets -
                    ext.template.node.token = items[i].token;

                    Scope_set(innerScope, :id, :target, shadows: false);
                }

                // Again the _field_items thing is really messy -
                //  I think we originally got it for stuff like `fn fieldname`.
                if (isPrimDecl)
                    _scope.items ~= innerScope;
                else
                    _field_items ~= innerScope;
            }

            // Update field types.
            innerScope.len == members.len || BUG(
                "solveStructMembers_3: field lens mismatch: " ~ innerScope.len ~ " vs " ~ members.len ~ "/" ~ items.len ~ ": `struct " ~ name ~ "`.");

            for (mut i = 0; i < innerScope.len; i++)
            {
                let item = innerScope[i];
                shadow let member = members[i];
                item.id == member.value || BUG("solveStructMembers_4: field id mismatch.");

                let field_target = item.target;
                ref field = GET_mut(field_target);
                field.type = member.type;

                //
                let member_shape = getShape(member.type);

                mut memberFlatOffset = 0;
                if (!isPrimDecl)
                {
                    shape_hasher.hash(item.id);
                    shape_hasher.hash(member_shape.hash);

                    shape.declDepth = max(
                        shape.declDepth,
                        member_shape.declDepth + 1);

                    memberFlatOffset = shape.flatCount;
                    shape.flatCount += member_shape.flatCount;

                    if (member_shape.non_triv_mask)
                    {
                        non_triv_reason ||= non_triv_reason = i + 1;
                        shape.non_triv_mask |= member_shape.non_triv_mask;
                    }
                }

                //
                if (SELF_TEST)
                {
                    let expect = min(member_shape.flatCount, q_USAGE_bitsize);
                    let actual = bit::popcount(member.type.usage);

                    actual == expect
                        || member.type.isStruct // TODO FIX fails for type recursions
                        || BUG("member.type.usage popcount(" ~ actual ~ ")"
                            ~ " != member_shape.flatCount(" ~ member_shape.flatCount ~ ")");

                    if (!member.type.is_trivial != !!member_shape.non_triv_mask)
                        if (member_shape.flatCount) // ignore ZSTs
                            BUG("member.is_trivial(" ~ member.type.is_trivial ~ "),"
                                ~ " but non_triv_mask(" ~ member_shape.non_triv_mask ~ ")");
                }

                // TODO FIX no point in doing this if struct is off-module,
                //  also no point in doing it if other struct is already checked?
                //
                // Probably this along with sizeof/alignof/flatCount & company
                //  can all be done in one pass.
                //
                fn TODO_FIX_getRecursionError(s: Struct)
                {
                    for (shadow mut i = 0; i < s.items.len; i++)
                    {
                        shadow let item = s.items[i].target;
                        let itemType = item.type;
                        if (itemType.isStruct)
                        {
                            mut rec = "";
                            if (itemType.canon == out_type.canon
                                || (rec = TODO_FIX_getRecursionError(lookupUserType(itemType))))
                            {
                                return "\n\t\tvia " ~ item.explainWhichFn(fmt: FullContext)
                                                    ~ rec;
                            }
                        }
                    }

                    return "";
                }

                let recursionError = member.type.isStruct
                    && TODO_FIX_getRecursionError(tryLookupUserType(member.type));

                if (recursionError)
                    fail("Type " ~ name.qBAD ~ " is self-recursive:\n" ~ recursionError);

                //
                if (member.flags & F_USING)
                {
                    structConverts.push(item.target);

                    let m = field.type.modidOfOrigin;
                    if (m && m != module.modid)
                        structImports.set::add(m);

                    structImports.set::add(field.type.lookupTypeImports());
                }

                //
                if (!isPrimDecl)
                    field.field_packOffset(:memberFlatOffset,
                        memberFlatCount: member_shape.flatCount);
            }

            // Primitives - index enum variants & flags.
            if (isPrimDecl)
            {
                let signed      = basePrim[0] == 'i';
                let unsigned    = basePrim[0] == 'u';

                let size_str    = basePrim[1 :];
                let size: u8    = size_str == "8"   ? 8
                                : size_str == "16"  ? 16
                                : size_str == "32"  ? 32
                                : size_str == "64"  ? 64
                                : size_str == "128" ? 128
                                                    : BUG("Enum auto-incrementer: unknown prim size: " ~ size_str);

                mut last: intlit::Intlit;
                for (mut i = 0; i < innerScope.len; i++)
                {
                    ref init    = innerScope[i].target.GET_mut.solved;
                    let member  = members[i];
                    init        = member.items[LET_INIT];
                    _here       = member.token;

                    // Parse & reinit sequence.
                    if (init)
                    {
                        _here = init.token;

                        if (init.kind == "int")
                        {
                            last = intlit::Intlit(init.value);
                            if (last.error)
                                fail(last.error);

                            continue;
                        }

                        last.error = "Cannot auto-increment, please provide an explicit value.";
                    }

                    // Auto-increment.
                    last.error      && fail(last.error);
                    last.negative   && fail(
                        "Previous constant is negative, not sure how to increment, please specify an explicit value.");

                    let next = intlit::Intlit(:signed, :unsigned,
                        absval: kind == "flags"
                            ? (i ? last.absval << 1 : 1)
                            :      last.absval  + 1);

                    next.error || next.absval > last.absval || fail(
                        next.error || "Failed to auto-increment, range exhausted.");

                    let minsize = signed ? next.minsize_i : next.minsize_u;
                    if (minsize > size)
                        fail("Primitive range exhausted: requires " ~ minsize ~ " bits, got " ~ size ~ ".");

                    last = next;

                    //
                    if (signed || unsigned)
                        init = SolvedNode(kind: "int", type: primType, value: (next.negative && "-") ~ next.absval);
                    else
                        fail("Cannot auto-increment this type: " ~ basePrim);
                }
            }
        }

        //
        shape.hash = shape_hasher.u64;

        // TODO FIX I need a smarted way to deal with recursive types,
        //  we gotta study Unison's approach to cycle-hashing.
        //
        if (out_target.callers)
        {
            // println("RECURSIVE TYPE HASH FAIL " ~ out_target);
            shape.hash = lookupUserType(out_type).hash;
        }

        //
        if (non_triv_reason)
        {
            if (asserts & A_TRIVIAL)
                fail("Struct is not " ~ "trivial".qKW ~ (
                    non_triv_reason < 1
                        ? " because it is " ~ "nocopy".qKW ~ "."
                        : " because of non-trivial member "
                            ~ items.unless_oob(non_triv_reason - 1).value.qID));

            if (SELF_TEST)
                shape.non_triv_mask || non_triv_reason < 0 || BUG(
                    "Empty non_triv_mask, but some member is non-trivial.");

            // Lift one bit for this type.
            shape.non_triv_mask |= 1 << (shape.hash & 63);
        }

        // List imports in scope.
        _scope.imports.each(_ss.imports,
            |import| structImports.set::add(import));

        // Add a default constructor.
        {
            mut CHANGE = false;

            if (out_type.is_rx_copy &&
                members.some(|member| !member.type.is_rx_copy))
            {
                CHANGE      = true;
                out_type    = make_non_copyable(out_type);
            }

            //
            if (!isStruct && !isUnion)
                shape.flatCount == 1 || BUG("Bad flatCount("
                    ~ shape.flatCount ~ "): " ~ kind ~ " " ~ name);

            //
            {
                ref s       = lookupUserType_mut(out_type.canon);
                s.target    = out_target || BUG("No struct/out_target.");
                s.converts  = structConverts;
                s.imports   = structImports;

                {
                    mut shape0  = s.shape;
                    s.shape     = shape;
                    CHANGE    ||= shape0 != shape;
                }

                // fn printShape(shadow shape: Shape)
                // {
                //     mut str = "{";
                //     for (fieldname i: Shape)
                //         str ~= ' ' ~ "i" ~ ':' ~ shape.i;
                //
                //     return str ~ " }";
                // }
                //
                // if (shape0 != shape)
                //     println("SHAPE MISMATCH " ~ printShape(shape0) ~ " != " ~ printShape(shape));

                GET(s.target).status & SS_DID_START || BUG(
                    "Setting stuff but missing SS_DID_START.");

                // At this point we must be able
                //  to resolve flatCount from anywhere.
                if (SELF_TEST)
                {
                    let actual = getFlatCount(out_type);
                    if (actual != shape.flatCount)
                        BUG("getFlatCount actual=" ~ actual ~ " expect=" ~ shape.flatCount);
                }

                out_type.USAGE_setMaxUsage(:shape.flatCount);
            }

            //
            mut min = 0;
            mut args: Argument[];

            //
            if (isPrimDecl)
            {
                // TODO also list this as an explicit conversion.
                //
                args.push(
                    Argument(
                        name: "value",
                        type: basePrimType));
            }
            else
            {
                // We'll do the C89 thing for unions for starters -
                //  you can only init the first member,
                //   we'll figure the rest out later.
                //
                mut N = members.len;
                if (N && isUnion)
                    N = 1;

                for (mut i = 0; i < N; i++)
                {
                    let member = members[i];

                    let arg = Argument(
                        name:       member.value || BUG(),
                        type:       member.type  || BUG(),
                        flags:      member.flags & F_MUSTNAME,
                        default:    member.items[LET_INIT]
                            || isUnion && createDefinit(member.type));

                    if (!arg.default)
                        min++;

                    args.push(arg);
                }
            }

            let max = args.len;
            if (max && !min)
                min++;

            //
            ref ext         = EXT_mut(out_target);
            ext.min         = min;
            ext.max         = max;
            ext.args        = args;

            let mustUpdate  = CHANGE && out_target.callers.len;

            //
            ref overload    = GET_mut(out_target);
            overload.type   = out_type;

            if (mustUpdate)
                overload.status |= SS_UPDATED;
        }

        //
        lazySolveEnd(out_target);

        // We're done here, return nothing.
        return SolvedNode();
    }

    fn initStruct(
        ::kind!, shape!: Shape,
        name: string, asserts: DeclAsserts, specPat!: string)
    {
        name[0].u8 - '0'.u8 > 9.u8 || throw (
            "Bad struct name, leading digit: `" ~ name ~ "`.");

        // Alloc a slot.
        let index = module.out.types.len;
        module.out.types ~= Struct(:kind, :name, :shape);

        //
        let canon = createStructCanon(
            :kind, :shape.basePrim, :module.modid, :index, :name)
                ~ specPat;

        // if (specPat) println("SPECPAT " specPat);

        // Assume everything, we resolve disappointment.
        return Type(ValueType(:canon,
            quals: speculateStruct(:asserts, :shape.flatCount)));
    }


    //

    fn ensureLazySolved(target: Target)
    {
        TRACE_BRACKET("ensureLazySolved " ~ target.globid ~ " " ~ target);

        mut repeats = 0;
        while (lazySolveStart(target))
            repeats++ > 1000 && BUG(
                "Repeat-solved too many times: " ~ target);
    }

    fn lazySolveStart(target: Target): bool
    {
        // Isn't lazy-started?
        if (target.status & (SS_DID_START | SS_LAZY) != SS_LAZY)
            return false;

        {
            ref o = GET_mut(target);
            o.status & (SS_FINALIZED | SS_DID_START | SS_DIRTY) && BUG("SS_DID_START: non-zero solver status: " ~ o.status);
            o.status |= SS_DID_START;

            if (o.kind == "fn" || o.kind == "inline")
                doTrySpecialize(into: target, parent_idx: target.local_of);
            else if (o.kind == "type")
                __solveStruct(solve: true, :target.template.node, into: target);
            else
                BUG("lazySolveStart: kind is `" ~ o.kind ~ "`.");
        }

        // Expect changes.
        return true;
    }

    fn lazySolveEnd(t: Target): void
    {
        TRACE_BRACKET("lazySolveEnd " ~ t.globid ~ " " ~ t);

        ref o = GET_mut(t);
        mut reopen: i32[];

        let parent = t.local_of;
        if (o.status & SS_UPDATED)
        {
            o.status &= ~SS_UPDATED;

            let callers = t.EPH_mut.callers;

            :NEXT_USER
            for (mut i = 0; i < callers.len; i++)
            {
                // The shuffle here is to help stress test things better
                //  and hopefully help avoid nasty resolver patterns & worst cases.
                mut index = callers[i];

                TRACE("Looking into caller " ~ index ~ " " ~ index.localfn);

                :GO_UP
                for (;;)
                {
                    shadow let t = localfn(:index);
                    shadow ref o = GET_mut(t);

                    // If not started or dirty, means someone else will take care of us here.
                    if (o.status & (SS_DID_START | SS_DIRTY) != SS_DID_START)
                    {
                        TRACE("\tNo SS_DID_START | SS_DIRTY on " ~ t.globid ~ " " ~ t);

                        continue :NEXT_USER;
                    }

                    // If still solving somewhere up our callstack, just flag as dirty.
                    if !(o.status & SS_FINALIZED)
                    {
                        TRACE("\tSS_DIRTY " ~ t.globid ~ " " ~ t);

                        o.status |= SS_DIRTY;
                        continue :NEXT_USER;
                    }

                    // Climb up until sibling (or self) -
                    //  this is A->B->C being invalidated by A->D:
                    //   can't just reopen C here, because we don't have B in scope,
                    //    so we have to invalidate B.
                    let up = t.local_of;
                    if (up != parent) // !sibling
                    {
                        TRACE("\tNot a sibling, climbing up " ~ t.globid ~ " " ~ t);

                        up > parent || BUG("lazySolveEnd: about to climb up the wrong tree.");
                        index = up;
                        continue :GO_UP;
                    }

                    // Finally, a finalized, non-local of self,
                    //  gotta reopen & resolve now.
                    makeNote(o.kind == "type" ? N_TypeReopen : N_FnReopen);

                    o.status &= ~(SS_DID_START | SS_DIRTY | SS_FINALIZED);
                    reopen ~= index;

                    TRACE("\tREOPEN " ~ t.globid ~ " " ~ t);

                    continue :NEXT_USER;
                }
            }
        }

        //
        shadow ref o = GET_mut(t);

        if !(o.status & SS_DIRTY)
        {
            if (t.callers)
                TRACE("SS_FINALIZED " ~ t.globid ~ " " ~ t);

            o.status |= SS_FINALIZED;
        }
        else
        {
            TRACE("NOT FINALIZED because SS_DIRTY " ~ t.globid ~ " " ~ t);

            o.status & SS_FINALIZED && BUG("Stray SS_FINALIZED.");
            o.status &= ~(SS_DID_START | SS_DIRTY);
            makeNote(o.kind == "type" ? N_TypeResolve : N_FnResolve);
        }

        //
        for (mut i = 0; i < reopen.len; i++)
        {
            shadow let t = localfn(index: reopen[i]);

            lazySolveStart(t);
        }
    }

    fn detectRecursion(target: Target): void
    {
        let overload = GET(target);
        if (overload.status & (SS_FINALIZED | SS_LAZY) != SS_LAZY)
            return;

        // TODO FIX Incorrect: fns can use other fns as type annots.
        //  We need to somehow track who depends on others for type info,
        //   and who depends on others for actual compute.
        let note    = overload.kind == "type" ? N_TypeRecursion : N_FnRecursion;
        let status  = overload.kind == "type" ? SS_TYPE_RECUR   : SS_FN_RECUR;

        for (mut i = _helpers.len; i --> 0; )
        {
            let h = _helpers[i];
            if !(h.isFnOrType)
                continue;

            GET_mut(h.target).status |= status;
            makeNote(note);

            if (h.target == target)
                return;
        }

        BUG("detectRecursion: no _helpers entry for `" ~ overload.name ~ " (" ~ overload.status ~ ")`.");
    }


    //////////////////////////////////////////////////////////

    fn Lifetime_climbType(o: Overload)
    {
        o.kind == "var" || BUG("Lifetime_climbType: not a `var`: " ~ o);

        let node = o.solved;

        return node.is_ref && !(o.flags & F_ARG)
            && node.items[LET_INIT].type;
    }

    fn Lifetime_unwind(
        lifetime: Lifetime,
        locals_start!?: i32,
        locals_only!?: bool): Lifetime
    {
        return Lifetime_process(:lifetime, each:
            |locid, continue_keep, continue_climb, paths|
        {
            if (!locid)
            {
                if (locals_only)
                    continue/*discard*/;
            }
            else if (locid >= locals_start)
            {
                let init = GET(nested(locid)).Lifetime_climbType;
                if (init.is_ref)
                    continue_climb(
                        Lifetime_op_join(init.lifetime, paths));
            }

            continue_keep();
        });
    }

    fn Lifetime_F_MOVED_FROM(lifetime: Lifetime)
    {
        Lifetime_each(:lifetime): |locid, isTemp|
        {
            if !(locid) {
                isTemp || BUG("Attempting to move from a non-local, non-temporary region.");
                continue;
            }

            ref o = GET_mut(nested(locid));
            if (o.flags & F_MOVED_FROM)
                continue;

            o.flags |= F_MOVED_FROM;

            // println("MOVED FROM " ~ o.name ~ ": " ~ o.type.humanizeType);

            let init = o.Lifetime_climbType;
            if (init.is_ref)
                Lifetime_F_MOVED_FROM(init.lifetime);
        }
    }

    fn Lifetime_allowsMutrefReturn(lifetime: Lifetime, locals_start!: i32): bool
    {
        Lifetime_each(:lifetime): |locid|
        {
            if (!locid)
            {
                // TODO FIX seeing static mutrefs -
                //  appear to be related to : &mut x return annotations.
                // locid || BUG("Lifetime_allowsMutrefReturn: found a non-local.");
                continue;
            }

            if (locid < locals_start)
                break;

            let o = GET(nested(locid));
            o.type.is_mutref || BUG(
                "Lifetime_allowsMutrefReturn: found non-mutref: " ~ o);

            if (o.kind == "var" && !(o.flags & F_REF))
                return false;

            let init = o.Lifetime_climbType;
            if (!Lifetime_allowsMutrefReturn(init.lifetime, :locals_start))
                return false;
        }

        return true;
    }

    //////////////////////////////////////////////////////////

    // Note - as soon as we re-assign the return value,
    //  we want to re-iterate all the return statements,
    //   because that can change our copy/move decision.

    fn superType_neverOK(reason: string, a: Type, b: Type)
    {
        return a.is_never ? b
             : b.is_never ? a
             : superType(:reason, :a, :b);
    }

    fn superType(reason: string, a: Type, b: Type, id?: string)
    {
        return type_trySuper(a, b) || fail(
            (id && id.qID ~ ": ")
                ~ reason
                ~ "No common supertype: "
                ~ humanizeType(a, lt: true) ~ " | " ~ humanizeType(b, lt: true));
    }

    fn intersectionType(reason: string, a: Type, b: Type, id?: string)
    {
        return type_tryIntersect(a, b) || fail(
            (id && id.qID ~ ": ")
                ~ reason
                ~ "Cannot intersect types: "
                ~ humanizeType(a, lt: true) ~ " & " ~ humanizeType(b, lt: true));
    }

    fn solveJump(node: Node): SolvedNode
    {
        let h = node.kind == "return"
            ? Scope_lookupReturn(node.value, lambdaOK: !!(node.flags & F_IMPLICIT))
            : Scope_lookupLabel (node.value, cont: node.kind == "continue");

        // Deal with expression first, might noop the jump.
        let n_expr = node.items.if_only;

        mut expr = !n_expr
            ? createEmpty()

            // TODO FIX SPECPAT //
            : unorderedClassify(n_expr.kind)
                ? solveDeclExpr(n_expr,
                    TODO_FIX_useSpecPath: h.target == _current_fn.target)
            // TODO FIX SPECPAT //

            : solveNode(n_expr,
                type: h.ret_actual
                        ? clear_vfacts(h.ret_actual)
                        : h.ret_expect);

        // Dead code elim.
        if (expr.type.is_never)
            return expr;

        // Conversions.
        // TODO FIX: this error duplicates with the error in reportReturnType.
        if (h.ret_expect)
            convertIfNeeded(expr, h.ret_expect,
                "Actual return type does not match annotation");

        // Detect & shim non-local jumps.
        if (h.local_of != _current_fn.target.globid)
        {
            // println("Setting up a __far_jump from " ~ _current_fn.target ~ " to " ~ Target(:module.modid, index: h.local_of));

            // TODO FIX this forces fns with jumps in defaulted arguments
            //  into becoming inline funcs, not necessary,
            //   far jumps can be taken into account during later passes.
            _current_fn.far_jumps.set::add(h.local_of);

            // The fn will solve again as inline,
            //  return a shim here that looks jumpy.
            return SolvedNode("__far_jump", type: t_never, :node.flags, items: [ expr ], helpers: h);
        }

        return solveJump_finish(:node.flags, :expr, :h);
    }

    fn solveJump_finish(flags: Flags, expr: SolvedNode, h!: Helpers)
    {
        // Lazy labels.
        h.mask |= HM_LabelUsed;

        reportReturnType(:h, expr.type,
            NICEERR_missingReturn: !!(flags & F_IMPLICIT));

        return createJump(:h, :expr);
    }

    fn createJump(h!: Helpers, expr: SolvedNode)
    {
        return SolvedNode("jump", type: t_never, items: [ expr ], helpers: h);
    }

    fn reportReturnType(h!: Helpers, type: Type, NICEERR_missingReturn!?: bool)
    {
        // NOW, IMPORTANTLY:
        //  If we're about to return a mutref, make sure it doesn't go through an F_MUT.
        //   There's a bit of a conflict of interest here with F_REFs and templates,
        //    we can also start with non-F_REF but keep in mind that this worsens
        //     the problem of const-vs-mut templates, so the rules are a bit blurry here.
        //      We might be better off with explicit consts than explicit vars,
        //       or perhaps allow ref vars to bind to constants.
        //
        shadow let type = type.is_mutref && !type.lifetime.Lifetime_allowsMutrefReturn(:h.locals_start)
            ? clear_mutref(type)
            :              type;

        // TEMP ////////////////////////////////////////////////////////
        // I'm postponing work on lengthening temporary lifetimes -
        //  same principle as locals but i need extra stuff i dont have,
        //   so lets try to get it right without this first.
        shadow let type = type.lifetime.hasTemporary
            ? clear_refs(type)
            :            type;
        ////////////////////////////////////////////////////////////////

        // Regular block expects are best-effort type inference hints,
        //  whereas fn expects are explicit type annotations that must be enforced.
        //
        // TODO FIX: this error duplicates with the error in solveJump.
        if (h.ret_expect)
            checkAssignable(host: h.ret_expect, type,
                "Actual return type does not match annotation");

        h.ret_actual = h.ret_actual
            ? superType_neverOK(h.ret_actual, type,
                reason: NICEERR_missingReturn ? "Missing final return: " : "Subsequent return: ")
            : type;

        h.ret_actual || BUG("reportReturnType: no ret_actual.");
    }


    //////////////////////////////////////////////////////////

    fn checkAssignable(
        host: Type, guest: Type,
        err: string, id?: string, sep?: string,
        asArgument!?: bool)
    {
        isAssignable(:asArgument,
            :host   || BUG("Bad host type."),
            :guest  || BUG("Bad guest type."))
                    || fail(err ~ (id && " " ~ id.qID) ~ ": "
                                ~ host .humanizeType() ~ (sep || " <- ")
                                ~ guest.humanizeType());
    }

    fn convertIfNeeded(
        ref actual: SolvedNode, expect: Type,
        err: string, id?: string, sep?: string,
        asArgument!?: bool)
    {
        if (isAssignable(host: expect, actual.type, :asArgument))
            return;

        let conv = tryConvert(actual, :expect, local_scope: true);
        if !(conv)
            fail(err ~ (id && " " ~ id.qID) ~ ": "
                                ~ expect.humanizeType() ~ (sep || " <- ")
                                ~ actual.humanizeType());

        applyConversion(actual, conv);
    }


    // Loops.

    fn Scope_lookupReturn(id: string, lambdaOK: bool): Helpers
    {
        _helpers.reveach(_ss.helpers, |item, i|
        {
            if !(item.mask & HM_CanReturn)
                continue;
            if (item.mask & HM_Lambda && !lambdaOK)
                continue;
            if (id && item.id != id)
                continue;

            return item;
        });

        fail("No return `" ~ id ~ "` in scope.");
    }

    fn Scope_lookupLabel(id: string, cont!: bool): Helpers
    {
        mut CONTINUE_BELOW: i32;

        _helpers.reveach(_ss.helpers, |item, ref i|
        {
            // Continue into first return when possible,
            //  this comparison works because of the scope skips.
            if (i < CONTINUE_BELOW - 1)
                i++;

            if !(item.mask & HM_CanBreak)
            {
                if (!CONTINUE_BELOW)
                {
                    if (id || !(item.mask & HM_Lambda))
                        continue;

                    // Lambda break & continue.
                    if !(cont)
                    {
                        CONTINUE_BELOW = i;
                        continue;
                    }
                }
            }
            else if (!CONTINUE_BELOW)
            {
                if !(id ? item.id == id : !!(item.mask & HM_Anon))
                    continue;

                if (cont)
                {
                    i++;
                    //
                    // I had forgotten to enforce scopeSkip.helpers here,
                    //  so, depending on fn solve order,
                    //   a continue for a labelled lambda could end up
                    //    returning from the function it was passed into,
                    //     see the for_fn & :TWICE twice testcases.
                    //
                    _ss.helpers.each: |skip| {
                        if (i == skip.start)
                            i = skip.end;
                        else if (i < skip.start)
                            break;
                    }

                    i < _helpers.len || fail("Cannot " ~ ("continue :" ~ id).qBAD ~ " from here, did you mean to " ~ "break".qKW ~ "?");
                }
            }

            return _helpers[i];
        });

        fail("No label `" ~ id ~ "` in scope.");
    }

    fn solveArgID(node: Node, type: Type): SolvedNode
    {
        let expr = solveNode(node.items.only, :type);
        return solved(node, [ expr ], :expr.type);
    }

    fn solveLoop(node: Node): SolvedNode
    {
        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        // TODO really consider getting rid of this,
        //  ideally we'll only have labels on blocks -
        //   the continues-map-to-inner-block thing.
        let brk_idx     = _helpers.len;
        push(HelpersData(
            id:             node.value,
            mask:           HM_Anon | HM_CanBreak,
            local_of:       _current_fn.target.globid,
            locals_start:   GET_next_local_index(),
            ret_actual:     t_void));

        let n_init      = node.items[LOOP_INIT];
        let n_pre_cond  = node.items[LOOP_PRE_COND];
        let n_pre       = node.items[LOOP_PRE];
        let n_body      = node.items[LOOP_BODY];
        let n_post      = node.items[LOOP_POST];
        let n_post_cond = node.items[LOOP_POST_COND];

        let init        = n_init        && solveLetStatement(n_init);
        if (init.type.is_never)
        {
            makeNote(N_DeadLoopInit);
            return init;
        }

        // TODO handle deadcode everywhere
        let pre_cond    = n_pre_cond    && solveNode(n_pre_cond,  t_proposition);
        let pre         = n_pre         && solveBlock(n_pre, type: t_void, mask: HM_LoopPreheader);
        let body        = n_body        && solveBlock(n_body, type: t_void);
        let post        = n_post        && solveBlock(n_post, type: t_void);
        let post_cond   = n_post_cond   && solveNode(n_post_cond, t_proposition);

        // Control flow.
        let h           = _helpers[brk_idx];
        let type        = !pre_cond && !post_cond && !(h.mask & HM_LabelUsed)
                            ? t_never
                            : t_void;

        return SolvedNode(
            kind: "loop", :type,
            items: [ init, pre_cond, pre, body, post, post_cond ],
            helpers: h);
    }


    // Exotic loops.

    fn solveForFieldsOf(node: Node): SolvedNode
    {
        fn astReplace(shadow node: Node, mutate): Node
        {
            fn walk(shadow ref node: Node)
            {
                for (mut i = 0; i < node.items.len; i++)
                    walk(node.items[i]);

                mutate(node);
            }

            shadow mut node = node;
            walk(node);
            return node;
        }

        let placeholder     = node.value;
        let body_template   = node.items[1];

        let prefix          = placeholder ~ "_";
        let suffix          = "_" ~ placeholder;
        let inside          = "_" ~ placeholder ~ "_";

        let fields          = evalTypeAnnot(node.items[0])
                                .lookupUserType()
                                .items;

        mut items_ast: Node[];
        for (mut i = 0; i < fields.len; i++)
        {
            let field = fields[i];
            {
                items_ast ~= astReplace(body_template, |ref item: Node|
                {
                    let idx = item.value == placeholder        ? 0
                            : item.value.starts (with: prefix) ? 0
                            : item.value.ends   (with: suffix) ? item.value.len - placeholder.len
                            : item.value.find   (inside);

                    if (idx >= 0)
                    {
                        if (item.kind == "call")
                        {
                            // TODO field access syntax disables any kind of scope lookup but fields,
                            //  otherwise we risk miscellaneous stuff randomly breaking templates for no good reason.
                            //
                            // if (item.flags & F_ACCESS)
                            //     item.flags |= F_NOSCOPE;
                            //
                            item.value.splice(idx, placeholder.len, field.id);
                        }
                        else if (item.kind == "str")
                        {
                            // String literals, potentially useful for serialization.
                            item.value.splice(idx, placeholder.len, field.id);
                        }
                    }
                });
            }
        }

        // Control flow & deadcode elim.
        //  TODO break & continue.
        let items = solveNodes(items_ast, DeadBreak_Always, type_all: t_void);
        let type  = items.if_last.type.is_never ? t_never : t_void;

        return createBlock(type, items);
    }

    fn createUnwrap()
    {
        return SolvedNode(kind: "unwrap", type: t_void);
    }


    //

    fn solveLetLike_dontTouchScope(
        node: Node, specType!?: Type, primType!?: Type): SolvedNode
    {
        let n_annot = node.items[LET_TYPE];
        let annot   = n_annot && n_annot.kind != "typeunion" && evalTypeAnnot(n_annot);

        // When we're specializing with a mutref, but there's no explicit mutref annot,
        //  we allow relaxing the F_REF so that e.g. bck can resolve by temp-copy.
        mut flags   = node.flags;

        if (specType.is_mutref && !(flags & F_REF || annot.is_mutref))
            flags  |= F_RELAXABLE_REF;

        shadow let annot = specType || primType || annot;

        shadow let annot =
            annot && node.flags & F_REF
                ? add_mutref(annot, Lifetime_temporary)
                : annot;

        let n_init  = node.items[LET_INIT];
        let init    = n_init && solveNode(n_init, annot);

        // Drop defaults that don't match current spec types,
        //  this will effectively make the args non-defaulted.
        shadow let init = specType && init.type && !isAssignableAsArgument(host: specType, init.type)
            ? SolvedNode
            : init;

        _here = node.token;

        return solveLetLike_dontTouchScope(
            node.value, :flags,
            :annot, :init);
    }

    fn solveLetLike_dontTouchScope(
        id: string, mut flags: Flags,
        mut init!: SolvedNode,
        annot!?: Type): SolvedNode
    {
        annot || init.type || fail(
            "Variable declarations without type annotations must be initialized: `" ~ id ~ "`.");

        // Dead code elim.
        let init_isNever = init.type.is_never;
        if (init_isNever && !(flags & (F_ARG | F_INLINE)))
        {
            makeNote(N_DeadLet);
            return init;
        }

        if (annot && init.type && !init_isNever)
            convertIfNeeded(init, expect: annot, asArgument: !!(flags & F_ARG),
                "Type annotation does not match init expression", :id, " <- ");

        // TYPES vs VALUES //////
        // To avoid ambiguity, currently we draw a line between:
        //
        //  let X = i32
        //   call(X) gives a const-ref to a defailt-initialized i32, and:
        //
        //  type X = i32
        //   call(X) gives the Typename(i32), usable in a type annot.
        //
        // What we end up with is not amazing because there's a bit
        //  of a function coloring situation, fns that operate on types
        //   vs fns that operate on values, except its not fns but bindings.
        //
        mut t_init = clear_Typename(init.type);
        // TYPES vs VALUES //////

        // TODO FIX VFACTS //////////////////////////
        if (flags & (F_ARG | F_MUT))
            t_init.vfacts = [];
        // TODO FIX VFACTS //////////////////////////

        // Lose refs to temporaries.
        shadow let t_init = t_init.lifetime.hasTemporary
            ? clear_refs(t_init)
            : t_init;

        // Trying to unify &muts and refs.
        if (annot.is_mutref)
            flags |= F_REF;

        if (flags & F_REF)
        {
            t_init.is_mutref    || t_init.is_never && annot
                                || !init && flags & F_ARG || fail(
                "ref".qBAD ~ " variables must be initialized to a mutable reference: " ~ id.qBAD
                    ~ (t_init ? " = " ~ humanizeType(t_init) : "."));
        }

        //
        mut t_let   = annot && (flags & F_ARG || !t_init)
                        ? annot
                        : t_init.is_mutref && !(flags & F_REF)
                            ? clear_mutref(t_init)
                            : t_init;

        // TODO FIX ARG TEMPS ///////////////////////
        if (flags & F_ARG)
            ref_anonymize(t_let);

        // this was already here, needs some research,
        //  i'm seeing weird stuff, LTs on F_MUTs, etc
        if (flags & F_ARG && !(flags & F_MUT))
            t_let = add_ref(t_let, Lifetime_temporary);
        // TODO FIX ARG TEMPS ///////////////////////

        if (SELF_TEST)
        {
            t_let.vfacts & Typename && BUG(
                "solveLetLike_dontTouchScope: Ended up with a Typename");

            if (flags & F_ARG || flags & F_MUT)
                t_let.vfacts & (AlwaysTrue | AlwaysFalse) && t_let.usage && BUG(
                    "solveLetLike_dontTouchScope: Ended up with an AlwaysTrue/False");
        }

        // TODO clean this up, annots not needed.
        //  We could move init out of here?
        //   So we can edit out of order maybe?
        return SolvedNode(
            kind: "let", value: id, :flags,
            type: t_let, items: [ SolvedNode, init ]);
    }

    fn solveLet(node: Node, specType!?: Type, letdefType!?: Type): SolvedNode
    {
        if (node.flags & F_TYPENAME)
            return solveTypedef(node, :specType);

        mut out = solveLetLike_dontTouchScope(node, :specType);
        let id  = out.value;
        return solveLet_createBindingAndGetLetdef(:out, :id, setScope: true, :letdefType);
    }

    fn solveLet_createBindingAndGetLetdef(
        mut out!: SolvedNode, id!: string, setScope!: bool, letdefType!?: Type): SolvedNode
    {
        // Dead code elim.
        if (out.kind != "let")
        {
            out.type.is_never || BUG(
                "solveLet: results in a `" ~ out.kind ~ ": " ~ id ~ "`.");

            return out;
        }

        mut shadows     = !!(out.flags & F_SHADOW);
        let isArg       = out.flags & F_ARG;

        shadow let id   = out.flags & F_COMPOUND_ID
            ? cleanID(id)
            :         id;

        if (out.type.isAddrOfFn)
        {
            // Shadowing & addroffns are broken,
            //  we'll just get rid of addroffns,
            //   it was a bad idea.
            //
            shadow let shadows = true;

            if (setScope)
                unpackAddrOfFn(out.type.canon, |target|
                    Scope_set(_scope.items, :id, :target, :shadows));
        }
        else
        {
            fn Scope_set(target: Target)
            {
                if (!setScope)
                    return;

                Scope_set(_scope, :id, :target, :shadows);

                if (out.flags & F_IMPLICIT)
                    Scope_set(_scope.implicits, :id, :target, :shadows);

                if (out.flags & F_USING)
                    _scope.usings.push(target);
            }

            ////////////////////////////////////////////////////////////////
            // TODO we need this to happen at a much later stage.
            //  Can we keep this var here and then just codegen it
            //   as a ref to the original?
            //
            if (OPTI_dedupe_vars && !isArg && !(out.flags & (F_PUB|F_MUT)))
            {
                let init = out.items[LET_INIT];
                if (init.kind == "call" && !init.items)
                {
                    let target  = init.target;
                    let other   = GET(target);

                    if (other.kind == "var")
                    {
                        if (isAssignable(host: other.type, out.type))
                        {
                            // println("VARFOLD " ~ id ~ ": " ~ humanizeType(out.type)
                            //                    ~ " := " ~ other.name ~ ": " ~ humanizeType(other.type));

                            Scope_set(:target);
                            out = createEmpty(:target); // Inliner: needed to put argdefs into letdefReplicas
                            return out;
                        }
                    }
                }
            }
            ////////////////////////////////////////////////////////////////

            let target = out.target = Binding(:id, :out.flags, :out.type, :shadows);

            //
            if (SELF_TEST)
            {
                !out.type.lifetime.hasTemporary || isArg || BUG(
                    "solveLet_createBindingAndGetLetdef: Non-argument lifetime.hasTemporary");

                out.type.vfacts & Typename && BUG(
                    "solveLet_createBindingAndGetLetdef: Ended up with a Typename");
            }

            //
            target.solved_set(out);

            // List.
            Scope_set(:target);

            //
            return createLetDef(:target, :letdefType);
        }

        // TODO FIX: these are the addrofn target-less lets,
        //  which aren't runtime arguments, we need them cleaned up during spec
        //   so we don't have to deal with them all over the place like this
        //
        if (isArg)
        {
            // TODO FIX seeing Lifetime_temporaries here,
            //  these just got real messy.
            if (out.type.isAddrOfFn)
                out.type = out.type.clear_refs();

            return out;
        }

        return createEmpty();
    }

    fn createLetDef(target: Target, letdefType?: Type)
    {
        return SolvedNode(kind: "letdef", :target,

            // TODO FIX if (lets ) started complaining about the t_void here,
            //  which is totally legit, this needs to be formalized.
            //
            // TODO FIX needed to fix this up, makes NO SENSE AT ALL.
            //  we need this for if (let)s, gotta replace this mess with
            //   a parser transform to { let x; if (x) ... },
            //    and we can recognize and reverse this during cg.
            //
            type: letdefType == t_proposition
                ? t_bool
                : t_void);
    }

    fn createLet(id: string, flags: Flags, init: SolvedNode, setScope!: bool)
    {
        mut out = solveLetLike_dontTouchScope(:flags, :id, :init);
        return solveLet_createBindingAndGetLetdef(:out, :id, :setScope);
    }


    //

    fn solveLetStatement(node: Node): SolvedNode
    {
        node.kind == "let" || BUG("Expected a `let` statement, got: `" ~ node.kind ~ "`.");
        return solveNode(node, t_void);
    }

    fn solveTryCatch(node: Node): SolvedNode
    {
        node.items.len == 3 || BUG();

        /////////////////////////////////
        let scope0  = Scope_snap(_scope);
        /////////////////////////////////

        let try     = solveNode(node.items[0], t_void);

        ///////////////////////////////////////
        Scope_pop(_scope, scope0);
        shadow let scope0 = Scope_snap(_scope);
        ///////////////////////////////////////

        let err     = solveLetStatement(node.items[1]);
        let catch   = solveNode(node.items[2], t_void);

        //////////////////////////
        Scope_pop(_scope, scope0);
        //////////////////////////

        err.kind == "letdef" && isAssignableAsArgument(
            host: err.target.solved.type, t_string) || fail(
                "catch: exceptions are strings,"
                    ~ " consider dropping the annotation.");

        let type    = try.type.is_never && catch.type.is_never
                        ? t_never
                        : t_void;

        return solved(node, type, [ try, err, catch ]);
    }

    fn findModule(fuzimport: string): &Module
    {
        let fname = resolveFile_x(fuzimport);

        let modules = ctx.modules;
        for (mut i = 1; i < modules.len; i++)
        {
            let m = modules[i];
            if (m.fname == fname)
                return m;
        }

        BUG("findModule: cannot locate: " ~ fname);
    }

    fn solveImport(node: Node): SolvedNode
    {
        fn visit(modid: i32)
        {
            if (!Scope_import(modid))
                return;

            // Follow pubs imports.
            let s = ctx.modules[modid].out.solve.scope;
            for (mut i = 0; i < s.imports.len; i++)
                visit(s.imports[i]);
        }

        let m = findModule(fuzimport: node.value);

        visit(m.modid);

        // Pub imports.
        if (node.flags & F_PUB)
        {
            _current_fn.scope0 && fail("Cannot pub import from here.");
            _pub_imports.set::add(m.modid);
        }

        //
        return createEmpty();
    }

    fn solveDefer(node: Node): SolvedNode
    {
        ////////////////////////////////////////////
        // TODO unless defer:ok, must be noexcept //
        ////////////////////////////////////////////

        let item = solveNode(node.items.only, t_void);
        return solved(node, t_void, [ item ]);
    }


    //

    fn evalTypeParam(id: string): Type
    {
        return _typeParams.map::get(id).matched
            || Scope_lookupType(id || fail("Falsy type param id."))
            || fail("No type param " ~ id.qID ~ " in scope.");
    }

    fn solveTypeParam(node: Node): SolvedNode
    {
        return solved(node, evalTypeParam(node.value));
    }

    fn solveAddrOfFn(node: Node): SolvedNode
    {
        let id   = node.value;
        let type = X_addrofTarget(targets: solveAddrOfFn(:id, :node.flags));
        return createEmpty(:type);
    }

    fn solveAddrOfFn(mut id: string, flags?: Flags): Target[]
    {
        mut shadow = false;
        mut result: Target[];

        // Visit local scope.
        fn visitScope(local_scope!: bool, items?: [ScopeItem])
        {
            mut scope_iterator: i32;
            mut target: Target;
            mut shadows: bool;
            while (!shadow && (target =
                local_scope
                    ? _scope.items.search(:id, :scope_iterator, scope_skip: _ss.items, :shadows)
                    :        items.search(:id, :scope_iterator)))
            {
                // Can't shadow here -
                //  shadowing works per signature,
                //   we can't just shadow everything by the same name in scope.
                result.set::add(target);
            }
        }

        let qualified = flags & F_COMPOUND_ID;

        // TODO FAILCASE forgot to limit qualified lookup to public items
        visitScope(
            local_scope: !qualified,
            items: qualified && dequalify_andGetScope(id).items);

        return result || fail("No `fn " ~ id ~ "` in scope.");
    }


    //

    fn evalTypeAnnot(node: Node, TODO_FIX_typeof_dontStripRefs!?: bool): Type
    {
        fn T = evalTypeAnnot(node.items.only);

        /////////////////////////
        let here0   = _here;
        defer _here = here0;
        _here       = node.token;
        /////////////////////////

        if (node.kind == "call")
        {
            let items = node.items;

            if (items.len == 1)
            {
                if (node.value == "&")
                    return add_ref(T, Lifetime_temporary);

                if (node.value == "&mut")
                    return add_mutref(T, Lifetime_temporary);

                if (node.value == "[]")
                    return createArray(T);

                if (node.value == "[:]")
                    return createSlice(T);

                if (node.value == "typeof")
                {
                    mut type = solveNode(node.items.only).type;

                    if (type.vfacts & Typename)
                    {
                        _here = node.items.only.token;
                        fail("Redundant " ~ "typeof".qBAD  ~ ", this is a type, not a value: " ~ humanizeType(type));
                    }

                    if (!TODO_FIX_typeof_dontStripRefs)
                    {
                        // This looks really stupid & redundant, but it's kinda sorta future-proof,
                        //   clears refs, vfacts, etc, consistently with type parameter matching.
                        type = relax_typeParam(type).clear_Typename();
                    }

                    return type;
                }
            }
        }
        else if (node.kind == "arrlit" && node.items.len == 1)
        {
            // TODO FIX REMOVE OLD SLICE SYNTAX
            return createSlice(T);
        }
        else if (node.kind == "definit")
        {
            return t_zeroes;
        }

        //
        let exprType = node.kind == "typeparam"
            ? evalTypeParam(node.value)
            : solveNode(node).type;

        if !(exprType.vfacts & Typename)
            fail("Invalid type annotation: evaluates to a value, not a type."
                ~ " Consider wrapping it in typeof().");

        return clear_Typename(exprType);
    }

    fn trySolveTypeParams(
        node: Node, mut type: Type, ref errout: Warning[], mut invariant!: bool): bool
    {
        fn matchFail(inline err: string)
        {
            if (errout)
                errout ~= Warning(node.token, err);

            return :trySolveTypeParams false;
        }

        if (node.kind == "call")
        {
            let items = node.items;

            :UNARY
            if (items.len == 1)
            {
                let t   = node.value == "&"    ? tryClear_ref(type)     || matchFail("Not a reference: " ~ type.humanizeType)
                        : node.value == "&mut" ? tryClear_mutref(type)  || matchFail("Not a mutref: " ~ type.humanizeType)
                        : node.value == "[]"   ? tryClear_array(type)   || matchFail("Not an array: " ~ type.humanizeType)
                        : node.value == "[:]"  ? tryClear_sliceable(type) || matchFail("Not sliceable: " ~ type.humanizeType)
                        : { break :UNARY; };

                if (node.value == "[]" || node.value == "[:]")
                    invariant = true;

                return trySolveTypeParams(
                    node.items[0] || BUG(), t || BUG(), :errout,
                    :invariant);
            }
        }
        else if (node.kind == "typeparam") :TYPEPARAM
        {
            let id = node.value || BUG();

            type = relax_typeParam(type);

            ref param = _typeParams.map::ref(id);
            if (param)
            {
                // TODO FIX arg spec types are not Typenames,
                //  and we can let them just fall through to the evalTypeAnnot below:
                //   - we don't want to change their .matched type here,
                //   - we want a typeof(x) around them for consistency.
                if (param.flags & TP_isArgSpec)
                    break :TYPEPARAM;

                //
                if (invariant)
                {
                    if (!isAssignable(host: type, param.matched, :DONT_match_zeroes))
                        matchFail("Incompatible types for " ~ id.qBAD ~ ": " ~ explainTypeDiff(param.matched, type, "->"));
                }
                else
                {
                    let union = type_trySuper(param.matched, type, :DONT_match_zeroes);
                    if (!union)
                        matchFail("Incompatible types for " ~ id.qBAD ~ ": " ~ explainTypeDiff(param.matched, type, "<->"));

                    type = union;
                }

                if (param.invariant)
                    if (!isAssignable(host: param.invariant, type, :DONT_match_zeroes))
                        matchFail("Incompatible types for " ~ id.qBAD ~ ": " ~ explainTypeDiff(param.invariant, type, "<-"));
            }

            param.matched = type;

            if (invariant)
                param.invariant = type;

            return true;
        }
        else if (node.kind == "arrlit" && node.items.len == 1)
        {
            // TODO FIX REMOVE OLD SLICE SYNTAX
            invariant = true;

            // Slice.
            let t = tryClear_sliceable(type) || matchFail("Not sliceable: " ~ type.humanizeType);
            return trySolveTypeParams(
                node.items[0] || BUG(), t, :errout,
                :invariant);
        }
        else if (node.kind == "typeunion")
        {
            let errout0     = errout.len;
            mut typeParams0 = _typeParams;

            for (mut i = 0; i < node.items.len; i++)
            {
                if (trySolveTypeParams(node.items[i], :type, :errout, :invariant))
                {
                    errout.shrink(errout0);
                    return true;
                }

                _typeParams = typeParams0;
            }

            return false;
        }

        // TODO FIX the branch on F_TEMPLATE here,
        //  already having problems with typeof().
        //
        if (node.kind == "call" && node.flags & F_TEMPLATE
                                && node.value != "typeof")
        {
            mut targets = solveAddrOfFn(node.value);
            if (!targets)
                matchFail(node.value.isNotDefinedHere);

            let pattern = type.canon.canon::tryGetPattern();
            if (pattern)
            {
                :NEXT_SUB_PATTERN
                pattern.canon::eachSubPattern(|shadow pattern, spec_of!target|
                {
                    fn patternFail(inline err: string)
                    {
                        if (errout)
                            errout ~= Warning(node.token, err);

                        continue :NEXT_SUB_PATTERN;
                    }

                    let targetsIdx = targets.find(target);
                    if (targetsIdx < 0)
                        continue :NEXT_SUB_PATTERN;

                    targets.splice(targetsIdx, 1);

                    mut numArgs = 0;
                    pattern.canon::eachArgSpecType: |argSpecType|
                    {
                        let argIdx = numArgs++;
                        if (argIdx >= node.items.len)
                            patternFail("Missing type argument for " ~ target ~ ": " ~ target.args[argIdx]);

                        shadow let node = node.items[argIdx];
                        shadow let type = Type(parseType(argSpecType));

                        if (!trySolveTypeParams(:node, :type, :errout, invariant: true))
                            continue :NEXT_SUB_PATTERN;
                    }

                    if (numArgs != node.items.len)
                        patternFail("Too many type arguments for " ~ target ~ ".");

                    // It's a match! We're done here.
                    return true;
                });
            }

            if (errout && targets)
                for (mut i = 0; i < targets.len; i++)
                    errout ~= Warning(node.token, "Not produced by " ~ targets[i] ~ ": " ~ humanizeType(type));

            return false;
        }

        // Everything else is a regular type annotation.
        let expect = evalTypeAnnot(node);
        if (!isAssignable(expect, type, :DONT_match_zeroes))
            matchFail("Incompatible types: " ~ explainTypeDiff(expect, type, "<-"));

        return true;
    }

    fn evalTypePattern(node: Node): bool
    {
        if (node.kind == "and")
        {
            for (mut i = 0; i < node.items.len; i++)
                if (!evalTypePattern(node.items[i]))
                    return false;

            return true;
        }
        else if (node.kind == "or")
        {
            mut undo = _typeParams;
            for (mut i = 0; i < node.items.len; i++)
            {
                if (evalTypePattern(node.items[i]))
                    return true;

                _typeParams = undo;
            }

            return false;
        }
        else if (node.kind == "typeassert")
        {
            let left  = node.items[0] || BUG();
            let right = node.items[1] || BUG();

            let actual  = evalTypeAnnot(left,

                // We don't want refs to seep through into type params and such,
                //  but for simple type asserts it just makes no sense for
                //   (x -> ref i32) not to report if x is a mutref.
                //
                TODO_FIX_typeof_dontStripRefs: true);

            // We'll have to figure out the type tag nonsense at some point.
            //  Perhaps when we have an `any` type,
            //   we could subtype it with the desired quals.
            if (right.kind == "typetag")
            {
                return actual.type_has(
                    right.value || fail("Falsy type tag."));
            }
            else
            {
                mut errout: Warning[];
                let ok = trySolveTypeParams(
                    type: actual, node: right,
                    :errout,
                    invariant: false);

                errout && BUG("Inefficient: trySolveTypeParams pushing errors when told not to (falsy errout).");

                ////////////////////////////////////
                // NATIVE RELAXER             [1] //
                //  if the TP_needsConsumedType is set
                //   in NATIVE RELAXER [0] -
                //
                // We "relax" arg types
                //  based on whatever you match in type patterns,
                //   which is a hack but the only thing we can really do
                //    given that we don't see the fn body.
                //
                if (ok)
                {
                    // TODO FIX this used to work without the case(typeof(a) -> ...)
                    //  that's around everything in prelude right now,
                    //   and now having this here goes to show that
                    //    this just doesn't make any sense at all.
                    //
                    shadow let left =
                        left.kind  == "call"    &&
                        left.value == "typeof"  &&
                        left.items.if_only      || left;

                    if (left.kind == "typeparam")
                    {
                        let id = left.value;
                        if (_typeParams.map::get(id).flags & TP_needsConsumedTypes)
                        {
                            let expect  = evalTypeAnnot(right);

                            ref tp      = _typeParams.map::ref(id);
                            tp.consumed = tp.consumed
                                ? type_tryIntersect(tp.consumed, expect) || fail("typeassert intersect fail.")
                                : expect;
                        }
                    }
                }
                // NATIVE RELAXER                 //
                ////////////////////////////////////

                return ok;
            }
        }
        else if (node.kind == "not")
        {
            return !evalTypePattern(node.items.only);
        }

        return fail("Invalid type pattern.");
    }

    fn type_has(type: Type, tag: string)
    {
        if (tag == "trivial")
            return type.is_trivial;

        if (tag == "copy")
            return type.is_rx_copy;

        if (tag == "arithmetic")
            return type.is_arithmetic;

        if (tag == "primitive")
            return type.is_primitive;

        if (tag == "bitfield")
            return type.is_bitfield;

        if (tag == "integral")
            return type.is_integral;

        if (tag == "unsigned")
            return type.is_unsigned;

        if (tag == "floating_point")
            return type.is_floating_pt;

        if (tag == "mutref")
            return type.is_mutref;

        if (tag == "enum")
            return type.is_enum;

        if (tag == "flags")
            return type.is_flags;

        if (tag == "reinterpretable")
            return type.is_reinterpretable;

        return BUG("Unknown type tag: `" ~ tag ~ "`.");
    }


    //

    fn createRead(id: string): Node
    {
        return Node(
            kind:   "call",
            value:  id,
            token:  (_here || BUG()));
    }

    fn dequalify_andGetScope(ref id: string): &Scope
    {
        let split = id.find('\t');
        split >= 0 || BUG();

        let fname = id.slice(0, split);
        id        = id.slice(split + 1);

        let other = findModule(fuzimport: fname);
        if (other.modid != module.modid)
            return other.out.solve.scope;

        fail("Qualified " ~ id.qBAD ~ ":: access current module.");
    }

    fn solveCall(node: Node, target!?: Target): SolvedNode
    {
        let args = solveNodes(node.items,

            // Can't dead code elim naively -
            //  A] Order of eval depends on target right now, can't be assumed here.
            //  B] Fns with inline arguments can sink nevers inside their bodies.
            DeadBreak_Only_WhileSolvingRecursion);

        if (args.if_last.is_AssumeNever_WhileSolvingRecursion)
            return args.last;

        //
        return solveCall(id: node.value, args, :node.flags, :target);
    }

    fn solveCall(
        mut id: string, mut args?: SolvedNode[],
        flags!?: Flags, target!?: Target): SolvedNode
    {
        id || target || BUG("solveCall: No id, no target.");

        // Qualified?
        let qualified = flags & F_COMPOUND_ID;
        let misc_scope = qualified && dequalify_andGetScope(id);

        //
        mut reorder: Reorder;
        mut conversions: Target[][];
        let callTargIdx = match__mutargs(
            :misc_scope, local_scope: !qualified,
            :id, :args, :reorder, :conversions, :flags, :target);

        //
        return CallerNode(id, callTargIdx, args, :reorder, :conversions);
    }

    fn deadCall(args: SolvedNode[]): SolvedNode
    {
        // TODO FIX deadCall order of eval is kinda broken -
        //  a dead default arg will respect LTR but not RTL order of eval,
        //   a dead arg pre-match won't respect any order at all.
        //
        // This would be kinda solved if we decide that order of eval
        //  is as written at each callsite, and not dependent on the target fn,
        //   and we'll enforce RTL for assignments just because that's what's written,
        //    e.g. if invoked as a regular fn it'd be LTR.
        //
        makeNote(N_DeadCall);
        return createBlock(t_never, args);
    }


    // TODO we have to get rid of this.

    fn Scope_lookupType(id: string, flags?: Flags): Type
    {
        let callsite = solveCall(id, :flags);
        if (callsite.target.kind != "type")
            return fail("No type " ~ id.qBAD ~ " in scope.");

        if (callsite.items)
            return fail("Scope_lookupType: Wasting time setting up callargs.");

        return callsite.target.type;
    }


    // I feel this should be a fncall instead of this here.
    //  It's varargs - so is it a template or what?

    fn solveArrlit(node: Node, type: Type): SolvedNode
    {
        mut itemType = type && tryClear_sliceable(type);

        // Default constructor calls.
        if (!itemType && type.isStruct)
            return solveCall(node,
                target: lookupUserType(type).target);

        // Dead code elim.
        mut args = solveNodes(node.items, DeadBreak_Always, itemType);
        if (args.if_last.type.is_never)
        {
            makeNote(N_DeadArrlit);
            return createBlock(t_never, args);
        }

        //
        if !(node.flags & F_NAMED_ARGS)
            return createArrlit(args, itemType);

        fail("TODO: solveArrlit: tryMatch by [ argnames: ... ] without function name.");
    }

    fn solveArrlit_itemType_init(head!: Type)
    {
        // Super trivial, just don't want to hardcode this here.
        return clear_refs(head) || BUG();
    }

    fn solveArrlit_itemType(items: [SolvedNode], mut itemType?: Type, mut start = 0)
    {
        // Init.
        if (!itemType)
        {
            if (start == items.len)
                return fail("Cannot infer empty arraylit.");

            itemType = solveArrlit_itemType_init(head: items[start++].type);
        }
        else if (itemType.is_ref)
        {
            fail("Array items cannot be refs. TODO Why an error? Should this not just clear_refs?");
        }

        // Rest is simple inter.
        for (mut i = start; i < items.len; i++)
            itemType = superType("Array literal: ", itemType, items[i].type);

        return itemType;
    }

    fn solveArrlit_done(itemType!: Type, itemCount! = -1)
    {
        mut arrayType = createArray(itemType);

        if (itemCount >= 0 && !(options.dev & options::DEV_DontFoldLiterals))
            arrayType.vfacts = itemCount
                ? AlwaysTrue
                : AlwaysFalse;

        return arrayType;
    }

    fn createArrlit(mut items: SolvedNode[], itemType?: Type)
    {
        shadow let itemType = solveArrlit_itemType(items, itemType);

        return SolvedNode("arrlit", :items, type:
            solveArrlit_done(:itemType, itemCount: items.len));
    }


    //

    fn createLet_implicitArg(id: string, type: Type, flags: Flags, ref shadows!: bool)
    {
        let target  = Binding(id, type, :flags, :shadows);
        let ret     = SolvedNode(
            kind: "let", :flags,
            value: target.name, :target.type, :target);

        target.solved_set(ret);
        return target;
    }

    fn injectForeignLocal(target: Target): Target
    {
        // CLOSURE-ID-HACK
        if (SELF_TEST)
        {
            target.kind == "var" || BUG(
                "injectForeignLocal: trying to inject a non-var: " ~ target);

            let noClID = hacks::tryParseClosureID(id: target.name);
            if (noClID)
                BUG("injectForeignLocal: Unexpected closure-id: " ~ noClID.target);
        }

        // Closures over implicit lets & args risk bck later complaining about aliasing,
        //  as we can end up passing the implicit & closed-over arguments twice,
        //   so in case this is an implicit let, pass it in as an implicit (no closure id).
        //
        if (target.flags & F_IMPLICIT)
        {
            return injectImplicitArg(
                id:     target.name,
                type:   target.type, becauseOf: target);
        }

        //
        let clID = hacks::ClosureID(:target,
            target.parent.revision || BUG("injectForeignLocal: About to serialize at rev 0: " ~ target));

        return injectImplicitArg(
            id:     clID.serialize(),
            type:   target.type, becauseOf: target);
        // CLOSURE-ID-HACK
    }

    fn injectImplicitArg(id: string, type: Type, becauseOf!: Target): Target
    {
        if (!_current_fn.items || _current_fn.out.flags & F_EXTERN)
            fail("No implicit " ~ id.qBAD ~ ": " ~ humanizeType(type) ~ " in scope, needed to call " ~ becauseOf ~ ":\n"
                ~ qSTACK_implicit(target: becauseOf,
                        :id, :type, node: becauseOf.solved));

        // Reuse existing or add new argnode.
        for (mut i = 0; i < _current_fn.items.len + FN_ARGS_BACK; i++)
        {
            ref arg     = _current_fn.items[i];
            let target  = arg.target;

            shadow ref arg = arg.kind == "letdef"
                ? target.GET_mut.solved
                : arg;

            if (arg.flags & F_IMPLICIT &&
                arg.value == id)
            {
                if (SELF_TEST)
                {
                    // Got this when there was a missing F_IMPLICIT check here,
                    //  and we started matching regular arguments which were ref2temps on the out.solved,
                    //   same thing for implicits, but they match from scope where they get the ref2binding.
                    //
                    arg.type == target.type || BUG(
                        "injectImplicitArg: arg.type != target.type:\n\n\t    "
                            ~ explainTypeDiff(arg.type, target.type));
                }

                mut super = intersectionType(
                    :id, "Implicit argument collision: ",
                    add_ref(type, arg.type.lifetime), arg.type);

                //////////////////////////////////////////////////////////
                // TODO FIX just let the stuff below rerun?             //
                //  Here we're monkey patching, this is just not good.  //
                arg.type                = super;                        //
                target.GET_mut.type     = super;                        //
                //////////////////////////////////////////////////////////

                return target || BUG();
            }
        }

        // We'll be adding a new thing here.
        mut shadows: bool;
        mut flags = F_INJECTED | F_IMPLICIT
                  | F_ARG | F_LAX/* might get removed, dont want warnings */;

        if (type.is_mutref)
            flags |= F_REF | F_RELAXABLE_REF;

        let newArgTarget    = createLet_implicitArg(id, type, :flags, :shadows);
        let newArgIdx       = _current_fn.items.len + FN_ARGS_BACK;
        let newLetDef       = createLetDef(newArgTarget);

        _current_fn.items.insert(newArgIdx, newLetDef);

        return newArgTarget;
    }

    fn bindImplicitArg(name: string, type: Type, becauseOf!: Target): SolvedNode
    {
        let id = name;

        // CLOSURE-ID-HACK
        {
            let using _ = hacks::tryParseClosureID(:id);
            if (target.isLocal && target.localOf == _current_fn.target.globid)
            {
                revision == _current_fn.target.revision || BUG(
                    "ClosureID.revision mismatch: " ~ target
                        ~ "\n\tCaptured at: " ~ revision
                        ~ "\n\tCurrent rev: " ~ _current_fn.target.revision);

                target.kind == "var" || BUG(
                    "ClosureID.target is not a var: " ~ target);

                return CallerNode("__closure", target);
            }
        }
        // CLOSURE-ID-HACK

        PROFILE(.TryMatch_Implicit);

        mut error: string;
        mut reorder: Reorder;
        mut conversions: Target[][];
        let target = tryMatch__mutargs(local_scope: true, :id, :reorder, :conversions, flags: F_IMPLICIT, :error)
            || injectImplicitArg(:id, :type, :becauseOf)
            || BUG();

        let call = CallerNode("__implicit", :target, :reorder, :conversions);
        checkAssignable(host: type, call.type, "Implicit " ~ name.qBAD ~ " type mismatch", asArgument: true);
        return call;
    }


    //

    fn convertToSuperType(topic: string, ref a: SolvedNode, ref b: SolvedNode): Type
    {
        {
            let super = type_trySuper(a, b);
            if (super)
                return super;
        }

        let b_T = clear_vfacts(b.type);
        let a_T = clear_vfacts(a.type);

        :TRY_RETYPE
        {
            let aRetype = tryRetyping(a, b_T);
            let bRetype = tryRetyping(b, a_T);

            if (aRetype)
            {
                if (bRetype)
                    fail(topic ~ ": Type ambiguity, literals can be retyped both ways: "
                        ~ a.humanizeType ~ " <-> "
                        ~ b.humanizeType);

                let super = type_trySuper(aRetype, b);
                if (super)
                {
                    applyRetype(a, aRetype);
                    return super;
                }
            }

            if (bRetype)
            {
                let super = type_trySuper(bRetype, a);
                if (super)
                {
                    applyRetype(b, bRetype);
                    return super;
                }
            }
        }

        :TRY_CONVERT
        {
            let aConv = tryConvert(a, expect: b_T, local_scope: true);
            let bConv = tryConvert(b, expect: a_T, local_scope: true);

            if (aConv)
            {
                if (bConv)
                {
                    mut error = topic ~ ": Type ambiguity, conversions exist both ways:\n";

                    fn explain(shadow a: Type, shadow b: Type, chain: Target[])
                        error ~= "\n\t" ~ explainTypeDiff(a, b, "->") ~ ":"
                                        ~ explainConversion(chain);

                    explain(a, b, aConv);
                    explain(b, a, bConv);

                    fail(error);
                }

                applyConversion(a, aConv);
                return type_trySuper(a, b) || BUG("convertToSuper: aConv super");
            }

            if (bConv)
            {
                applyConversion(b, bConv);
                return type_trySuper(a, b) || BUG("convertToSuper: bConv super");
            }
        }

        fail(topic ~ ": No common supertype: "
            ~ a.humanizeType ~ " <-> "
            ~ b.humanizeType);
    }

    fn tryAbstractEvalAsBool(cond: SolvedNode, voidOk!?: bool): StaticEval
    {
        if (cond.vfacts & (AlwaysTrue | AlwaysFalse))
            return !(cond.vfacts & AlwaysTrue)  ? SE_False
                 : !(cond.vfacts & AlwaysFalse) ? SE_True
                 : BUG("Expression both AlwaysTrue and AlwaysFalse.");

        if (cond.type.isIrrelevant)
        {
            voidOk || warn("Condition is " ~ humanizeType(cond.type)
                ~ (cond.kind == "call"
                    ? ", returned from " ~ cond.target.explainWhichFn(fmt: FullContext)
                    : ", not meaningful in a boolean context."));

            return SE_False;
        }

        return SE_Unknown;
    }

    fn solveIf(node: Node, type: Type): SolvedNode
    {
        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        mut cond    = solveNode(node.items[0], t_proposition);

        // Dead code elim.
        if (cond.type.is_never)
            return cond;

        // Abstract eval.
        let ae_cond = tryAbstractEvalAsBool(cond);
        if (ae_cond)
            return createBlock(cond,
                solveNode(node.items[ae_cond == SE_True ? 1 : 2], :type));

        // `a && THROWS ? b : c` is the same as `a ? THROWS : c`
        let cons    = solveNode(node.items[1], :type);

        ////////////////////////////////
        // Can't use anything introduced
        //  in the cond or cons.
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        let alt     = solveNode(node.items[2], :type);

        _here       = node.token;
        return createIf(cond, cons, alt, :type);
    }

    fn createIf(cond: SolvedNode, mut cons: SolvedNode, mut alt: SolvedNode, mut type?: Type): SolvedNode
    {
        // Control flow.
        if (SELF_TEST)
            cond.type.is_never && BUG("createIf: cond.is_never");

        // Unfortunately, we gotta do the abstract eval again,
        //  otherwise stuff using createIf directly fails to benefit.
        //
        // Could use a defaulted argument for this,
        //  and pass the ae_cond from solveIf above to avoid this.
        //
        if (let ae_cond = tryAbstractEvalAsBool(cond))
            return createBlock(cond,
                ae_cond == SE_True ? cons :
                ae_cond == SE_False ? alt : BUG("createIf: ae_cond, neither True nor False."));

        //
        let cons_isNever = cons.type.is_never;
        let  alt_isNever =  alt.type.is_never;

        if (cons_isNever && alt_isNever)
            type = t_never;
        else if (!type.is_void)
            type = cons_isNever ?  alt.type
                 :  alt_isNever ? cons.type
                 : convertToSuperType("if/else", cons, alt);

        // TODO FIX this is messy and error-prone.
        // Best see why it happens in the first place, probably deadcode elim.
        {
            cond && cond.kind != "empty" || BUG("!cond || cond.empty");
            cons || BUG("!cons");
            alt  || BUG("!alt");

            if (cons.kind == "empty")
            {
                if (alt.kind == "empty")
                    return createBlock(:type, [ cond ]);

                return createOr(:type, [ cond, alt ]);
            }
            else if (alt.kind == "empty")
            {
                return createAnd(:type, [ cond, cons ]);
            }
        }

        //
        return SolvedNode("if", type || BUG(), items: [ cond, cons, alt ]);
    }


    //////////////////////////////////////////////////
    // Logic                  .                     //
    //////////////////////////////////////////////////

    fn solveOr(node: Node, type: Type): SolvedNode
    {
        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        let items = solveNodes(
            node.items,
            type_last:          type,
            use_type_last:      true,
            static_eval_brk:    SE_True,
            type_all:           type.is_void ? t_proposition : type,
            DeadBreak_Always);

        return createOr(items, :type);
    }

    fn createOr(mut items: SolvedNode[], mut type: Type): SolvedNode
    {
        createAndOr_staticEvalFold(items, static_eval_fold: SE_False)
            .createAndOr_staticEvalTrim(items, type, AlwaysTrue):
                |only| return only;

        // Unless this is an explicit bool context:
        if !(type.propositionOK || type.is_void) :RESOLVE_SUPERTYPE
        {
            mut sumType: Type;

            // Sum types, ignoring never.
            for (mut i = items.len; i --> 0; )
            {
                ref item = items[i];
                if (item.type.is_never)
                    continue;

                //
                if (sumType)
                {
                    sumType = type_trySuper(sumType, item.type) ||
                    {
                        // EXPERIMENTAL & doesnt feel really robust:
                        //  Allow incompatible types so long as one of the operands is a bool.
                        //
                        items.each: |shadow item|
                        {
                            if (item.type.canon == t_bool.canon)
                            {
                                type = t_bool;
                                break :RESOLVE_SUPERTYPE;
                            }
                        }

                        fail("Ambiguous ||, incompatible operands in a non-bool context: "
                            ~ humanizeType(item.type) ~ " || " ~ humanizeType(sumType));
                    };
                }
                else
                {
                    sumType = item.type;
                }
            }

            if (!sumType)
                type = t_bool;
            else
                type = sumType;
        }
        else
        {
            type = t_bool;
        }

        //
        if (items.last.is_never)
            type.vfacts = AlwaysTrue;

        return SolvedNode("or", type, :items);
    }

    fn solveAnd(node: Node, type: Type): SolvedNode
    {
        ////////////////////////////////
        let scope0 = Scope_snap(_scope);
        defer Scope_pop(_scope, scope0);
        ////////////////////////////////

        //
        let staticEvalBrk =
            type == t_void || type.propositionOK;

        let items = solveNodes(
            node.items,
            type_last:          type,
            use_type_last:      true,
            static_eval_brk:    staticEvalBrk && SE_False,
            type_all:           t_proposition,
            DeadBreak_Always);

        return createAnd(items, :type);
    }

    fn createAnd(mut items: SolvedNode[], mut type: Type): SolvedNode
    {
        let trim = createAndOr_staticEvalFold(items,
            static_eval_fold: SE_True);

        // Unless this is an explicit bool context:
        if (items.len > 1 && !(type.propositionOK || type.is_void))
        {
            mut sumType: Type;

            // Last item type wins -
            //  unless it's never, which we can safely ignore.
            for (mut i = items.len; i --> 0; )
            {
                let item = items[i];
                if (item.type.is_never)
                    continue;

                if (sumType)
                {
                    sumType = type_trySuper(sumType, item.type);
                    if (!sumType.is_ref)
                        break;
                }
                else
                {
                    type    = item.type;
                    sumType = item.type;

                    // Stop summing up if we've got zeroinit -
                    //  it gets lost in the type union.
                    if (type.is_zeroes)
                        break;
                }
            }

            if (!sumType.is_ref)
            {
                let cond = items.slice(0, items.len - 1);
                let cons = items.last;

                // We'll use the type of the last operand,
                //  and generate a falsy default for the rest.
                return createIf(
                    cond: createAnd(cond, t_bool),
                    :cons,
                    alt: solveDefinit(type));
            }
            else
            {
                type = sumType;
            }
        }
        else
        {
            type = t_bool;
        }

        trim.createAndOr_staticEvalTrim(items, type, AlwaysFalse): |only|
            return only;

        //
        if (items.last.is_never)
            type.vfacts = AlwaysFalse;

        return SolvedNode("and", type, :items);
    }

    fn createAndOr_staticEvalFold(
        ref items: SolvedNode[],
        static_eval_fold!: StaticEval)
    {
        mut trim = 0;

        for (mut i = items.len - 1; i --> 0; )
        {
            let se = tryAbstractEvalAsBool(items[i]);
            if (se == static_eval_fold)
            {
                let cond = items[i];
                items.splice(i, 1);
                if (trim)
                    trim--;

                ref cons = items[i];
                cons = createBlock(cond, cons);
            }
            else if (se)
            {
                trim = i + 1;
            }
        }

        return trim;
    }

    fn createAndOr_staticEvalTrim(
        trim: i32,
        ref items: SolvedNode[],
        ref type: Type,
        vfacts: VFacts,
        if_only)
    {
        if (trim)
        {
            items.shrink(trim);
            type.vfacts |= vfacts;
        }

        if (items.len < 2)
            if_only(items.only);
    }


    //

    fn solveNot(node: Node)
    {
        let item = solveNode(
            node.items.only, type: t_proposition);

        _here = node.token;
        return createNot(item);
    }

    fn createNot(item: SolvedNode)
    {
        // TODO we shouldn't need this kind of stuff
        //  when we get the hang of vfacts.
        if (item.kind == "bool")
        {
            if (item.value == "true")   return createBool(false);
            if (item.value == "false")  return createBool(true);

            BUG("Invalid bool literal: " ~ item.value.qBAD);
        }

        mut type = t_bool;
        let ae = tryAbstractEvalAsBool(item);
        if (ae)
            type.vfacts = ae == SE_True
                        ? AlwaysFalse
                        : AlwaysTrue;

        return SolvedNode("not", :type, items: [ item ]);
    }


    //

    fn addr_and_snippet(using token: TokenIdx, fmt?: CodeFmt, backtrack!?: string)
    {
        mut tokens = [ token ];
        if (backtrack)
        {
            let other = tryBacktrack(token, backtrack);
            if (other)
                tokens.unshift(other);
        }

        return formatCodeSnippet(:tokens, from: module.modid, :fmt);
    }


    //

    fn isNoVec(t: Type)
        t.is_trivial || !(t.is_rx_copy || t.is_rx_resize);

    fn SLOW_traverse(node: SolvedNode, visit)
    {
        mut stack = [ node ];

        fn TODO_FIX_pop(arr: $T[])
        {
            mut item: $T; ////////////////////
            swap(item, arr[arr.len - 1]); //// we need a nice pop()
            arr.pop(); ///////////////////////  so lame we dont have it
            return item;
        }

        while (stack)
        {
            shadow let node = stack.TODO_FIX_pop();

            // INDIRECTION !!!!
            shadow let node = node.kind == "letdef"
                ? node.target.solved
                : node;
            // INDIRECTION !!!!

            // INDIRECTION !!!!
            shadow let node = node.kind == "__preceding_ref_arg"
                ? _current_fn.preceding_ref_args[node.helpers.index].arg
                : node;
            // INDIRECTION !!!!

            visit(node);

            for (mut i = node.items.len; i --> 0; )
                stack ~= node.items[i];
        }
    }

    fn qSTACK(callsite: SolvedNode, write!: i32)
    {
        let args        = callsite.items;
        let host_args   = callsite.kind == "call" && callsite.target.args;
        if (args.len == host_args.len) for (mut i = 0; i < host_args.len; i++)
        {
            let host_arg = host_args[i];
            if !(host_arg.flags & F_WRITTEN_TO)
                continue;

            let arg = args[i];
            if !(arg.type.lifetime.Lifetime_has(locid: write))
                continue;

            return qSTACK(:callsite.target, position: i);
        }

        return "";
    }

    fn qSTACK(target: Target, position!: i32, seen!?: Target[], query!?: ArgQuery)
    {
        return qSTACK(:target, :seen, :query,
            :target.args[position].target.locid);
    }

    fn qSTACK(target: Target, locid!: i32, seen!?: Target[], query!?: ArgQuery)
    {
        return qSTACK(target, target.solved, :locid, :seen, :query);
    }

    fn qSTACK(target: Target, node: SolvedNode, locid!: i32, seen!?: Target[], query!?: ArgQuery)
    {
        //////////////////////////////////////////////////
        let nestingFnort0   = _nestingFnort.exchange(target);
        defer _nestingFnort = nestingFnort0;
        //////////////////////////////////////////////////

        shadow let seen = seen ~ target;
        SLOW_traverse(node): |callsite|
        {
            if (callsite.kind != "call")
                continue;

            if (seen.has(callsite.target))
                continue;

            let args        = callsite.items;
            let host_args   = callsite.target.args;
            if (args.len == host_args.len) for (shadow mut i = 0; i < host_args.len; i++)
            {
                let host_arg = host_args[i];

                if (query == AQ_WhyNotNovec)
                {
                    if (host_arg.isNoVec())
                        continue;
                }
                else
                {
                    if !(host_arg.flags & F_WRITTEN_TO)
                        continue;
                }

                let arg = args[i];
                let unwound = Lifetime_unwind(arg.type.lifetime);
                if !(unwound.Lifetime_has(:locid))
                    continue;

                let peek = qSTACK(callsite.target, position: i, :seen, :query);
                if (!peek && callsite.target.kind == "fn")
                    continue;

                return "\n            "
                     ~ "via " ~ callsite.target
                     ~ " at " ~ callsite.token.addr_and_snippet
                     ~ peek;
            }
        }

        return "";
    }

    fn qSTACK(target: Target, node: SolvedNode, fx_mask: FxMask, seen!?: Target[])
    {
        //////////////////////////////////////////////////
        let nestingFnort0   = _nestingFnort.exchange(target);
        defer _nestingFnort = nestingFnort0;
        //////////////////////////////////////////////////

        shadow let seen = seen ~ target;
        SLOW_traverse(node): |callsite|
        {
            if (callsite.kind != "call" || callsite.target.isLocal)
                continue;

            if (seen.has(callsite.target))
                continue;

            if !(callsite.target.fx_mask & fx_mask)
                continue;

            let peek = qSTACK(callsite.target, callsite.target.solved, :fx_mask, :seen);
            if (!peek && callsite.target.kind == "fn")
                continue;

            return "\n            "
                 ~ "via " ~ callsite.target
                 ~ " at " ~ callsite.token.addr_and_snippet
                 ~ peek;
        }

        return "";
    }

    fn qSTACK_implicit(target: Target, node: SolvedNode, id: string, type: Type, seen!?: Target[])
    {
        //////////////////////////////////////////////////
        let nestingFnort0   = _nestingFnort.exchange(target);
        defer _nestingFnort = nestingFnort0;
        //////////////////////////////////////////////////

        mut candidates = "";

        shadow let seen = seen ~ target;
        SLOW_traverse(node): |callsite|
        {
            // Try to report places where you might be
            //  missing an `implicit` or some such.
            //
            if (callsite.kind == "let")
            {
                let candidate = callsite.target;
                if ( !(candidate.flags & F_INJECTED)
                    && candidate.name == id
                    && isAssignableAsArgument(host: type, candidate.type))
                {
                    candidates ~= "\n        Possible candidate in " ~ target ~ ": ";
                    if !(candidate.flags & F_IMPLICIT)
                        candidates ~= "NOT implicit ".qBAD;

                    candidates ~= explainWhichFn(candidate, fmt: FullContext);
                }
            }

            if (callsite.kind != "call" || callsite.target.isLocal)
                continue;

            if (seen.has(callsite.target))
                continue;

            :TRY_FIND_IMPLICIT_ARG
            {
                let host_args = callsite.target.args;
                for (mut i = 0; i < host_args.len; i++)
                {
                    let host_arg = host_args[i];
                    if (host_arg.flags & F_IMPLICIT &&
                        host_arg.name == id &&
                        isAssignableAsArgument(host: host_arg.type, type))
                    {
                        break :TRY_FIND_IMPLICIT_ARG;
                    }
                }

                continue;
            }

            let peek = qSTACK_implicit(callsite.target, callsite.target.solved, :id, :type, :seen);

            return "\n            "
                 ~ "because of call to " ~ callsite.target
                 ~ " at " ~ callsite.token.addr_and_snippet
                 ~ peek
                 ~ candidates;
        }

        // Alternatively, output the declaration.
        let host_args = target.args;
        for (mut i = 0; i < host_args.len; i++)
        {
            let host_arg = host_args[i];
            if (host_arg.flags & F_IMPLICIT &&
                host_arg.name == id &&
                isAssignableAsArgument(host: host_arg.type, type))
            {
                return "\n            "
                     ~ "because of " ~ explainWhichFn(host_arg.target, fmt: FullContext);
            }
        }

        //
        return "";
    }

    fn qSTACK_cow_inside(target: Target, node: SolvedNode, host_arg: Argument, cow_inside: TokenIdx, seen!?: Target[])
    {
        //////////////////////////////////////////////////
        let nestingFnort0   = _nestingFnort.exchange(target);
        defer _nestingFnort = nestingFnort0;
        //////////////////////////////////////////////////

        let locid = host_arg.target.locid;

        mut candidates = "";

        shadow let seen = seen ~ target;
        SLOW_traverse(node): |callsite|
        {
            if (callsite.kind == "copy" && callsite.items.only.token == cow_inside)
                return "\n            "
                     ~ "in " ~ target ~ " at " ~ cow_inside.addr_and_snippet;

            if (callsite.kind != "call" || !callsite.items)
                continue;

            if (seen.has(callsite.target))
                continue;

            let host_args = callsite.target.args;
            for (mut i = 0; i < host_args.len; i++)
            {
                shadow let host_arg = host_args[i];
                if (host_arg.flags & F_COW_INSIDE
                     && callsite.target.cows_inside.some(
                        |cow| cow.argTarget == host_arg.target.locid
                               && cow.token == cow_inside)
                     && Lifetime_unwind(callsite.items[i].lifetime)
                            .Lifetime_has(:locid))
                {
                    let peek = qSTACK_cow_inside(
                        callsite.target, callsite.target.solved,
                            :host_arg, :cow_inside, :seen);

                    return "\n            "
                         ~ "in " ~ target ~ " via " ~ callsite.target
                         ~ " at " ~ callsite.token.addr_and_snippet
                         ~ peek
                         ~ candidates;
                }
            }
        }

        //
        return "";
    }


    //

    fn applyConversion(ref arg: SolvedNode, conversion: Target[]): bool
    {
        for (mut i = 0; i < conversion.len; i++)
        {
            let t = conversion[i];
            if (t.min || t.max && arg)
            {
                arg = CallerNode("__using.a", t, [ arg ]);
            }
            else
            {
                i   && fail("Bad conversion chain, non-leading nullary: `" ~ t.name ~ "`.");
                arg && fail("Bad conversion chain, about to throw away an argnode.");
                arg = CallerNode("__using.b", t);
            }

            if (arg.is_never)
                return true; // N_DeadConv!
        }

        return false;
    }

    fn inlineExpression(
        from: Target,
        mut expr: SolvedNode,
        mut letdefReplicas?: Target[],
        locals_start!?: i32,
        must_not_call!?: Target)
    {
        PROFILE(.InlineExpr);

        from || BUG("TODO inlining from global scope, never happened before, might work, remove assert as needed.");

        // println("inlineExpression " ~ expr.kind ":" ~ expr.value " in " _current_fn);

        // TODO FAILCASE: used to do nothing if from == self,
        //  which breaks jumps, references to locals, etc.
        //
        {
            let helpers0 = _helpers.len;
            defer _helpers.shrink(helpers0);

            //
            let globidExpect = from.globid;
            let minLocalIdx  = GET_next_local_index();

            mut helpersReplicas: Helpers[];

            //
            fn matchReplicaOrInjectForeignLocal(target: Target, slot?: Type)
            {
                if (target.globid != globidExpect)
                    BUG("matchReplicaOrInjectForeignLocal: target.globid != globidExpect"
                        ~ ", will mess up the letdefReplicas minimap.");

                let replica = letdefReplicas.unless_oob(target.locid);
                if (replica)
                    return replica;

                // Local of self?
                if (from == _current_fn.target)
                {
                    target.locid < minLocalIdx || BUG("Missing a local replica for: " ~ target);
                    return target;
                }

                let o = GET(target);
                if (o.flags & F_IMPLICIT)
                    return bindImplicitArg(o.name,
                        type: slot || o.type,       // Use slot type if available,
                        becauseOf: from).target;    //  might refer to unused implicit via arg default expr, etc.

                if (from.modid != module.modid)
                    BUG("inlineExpression: about to use injectForeignLocal with an off-module target: " ~ o);

                return injectForeignLocal(target);
            }

            // println("    from " from);

            // TODO it'd be nice if we can skip this by looking at the expr node flags,
            //  something like F_NO_LOCALS or something that tells us
            //   there's nothing here that needs relinking.
            //
            fn visitNode(shadow ref expr: SolvedNode, shadow locals_start!?: i32)
            {
                // We need to setup _helpers & co before we visit the jump nodes inside.
                if (expr.kind == "block" || expr.kind == "loop")
                {
                    let foreign = expr.helpers;
                    if (foreign)
                    {
                        let local = push(
                            HelpersData(
                                local_of:       _current_fn.target.globid,
                                locals_start:   locals_start || GET_next_local_index(),
                                ret_actual:     expr.type,
                            ));

                        helpersReplicas.grow_if_oob(foreign.index) = local || BUG();

                        // println("inlineExpression: REPLICATE block/loop #" foreign.index " -> #" local.index);

                        expr.helpers = local;
                    }
                }

                // Descend.
                for (mut i = 0; i < expr.items.len; i++)
                    visitNode(expr.items[i]);

                // This is unpleasant -
                //  when inlining expressions we can encouter new let definitions,
                //   potentially cross-module.
                //
                // What we need to do here is to maintain a clone these bindings in the local fn,
                //  and keep a mapping of the targets that need to be replaced down the line.
                //
                if (expr.kind == "letdef")
                {
                    if (expr.target.globid != globidExpect)
                        BUG("inlineExpression: letdef doesn't match globidExpect");

                    //
                    let foreign = GET(expr.target);
                    let local   = Scope_create(_scope, nest: _current_fn.target.globid);

                    letdefReplicas.grow_if_oob(expr.target.locid) = local || BUG();

                    //
                    lax fn TEST_LifetimeEqual(
                        lax a: Lifetime, lax aa: string,
                        lax b: Lifetime, lax bb: string)
                    {
                        if (!SELF_TEST || a == b)
                            return;

                        BUG("visitNode TEST_LifetimeEqual:"
                            ~ "\n\n\t    " ~ aa ~ ":\t" ~ "(" ~ a ~ ")"
                            ~ "\n\n\t    " ~ bb ~ ":\t" ~ "(" ~ b ~ ")");
                    }

                    //
                    mut type = foreign.type;

                    if (type.lifetime == Lifetime_static)
                    {
                        TODO_FIX_static_ZSTs && type.is_zst || BUG(
                            "Unexpected static lifetime on " ~ foreign);
                    }
                    else
                    {
                        let flatCount = type.getFlatCount();

                        TEST_LifetimeEqual(
                            type.lifetime,                                  "foreign.type.lifetime",
                            Lifetime_fromBinding(expr.target, :flatCount),  "Lifetime_fromBinding");

                        type.lifetime = Lifetime_fromBinding(local, :flatCount);
                    }

                    //
                    mut solved = foreign.solved;
                    solved.kind == "let" && solved.target == expr.target || BUG();
                    solved.target = local;

                    visitNode(solved);

                    GET_mut(local) = Overload(
                        :foreign.kind,
                        :foreign.name,
                        :foreign.status & SS_MATCHED,
                        :type,
                        :solved,

                        // Untested: not sure what this implies / entails,
                        //  and if this is the only flag that needs juggling here.
                        flags: foreign.flags &~ F_ARG);

                    // println("inlineExpression: introducing a letdef: " ~ local " <- " ~ foreign);

                    expr.target = local;
                }
                else if (expr.kind == "call")
                {
                    // Replace references to foreign locals with implicit closure args.
                    if (expr.target.isLocal)
                    {
                        let local = matchReplicaOrInjectForeignLocal(expr.target, expr.type);

                        if (SELF_TEST)
                        {
                            let foreign = GET(expr.target);

                            isAssignable(host: foreign.type, local.type)
                                || local.type.is_never && local.flags & F_INLINE
                                || BUG("matchReplicaOrInjectForeignLocal botching the type of " ~ foreign ~ ":\n"
                                    ~ "\n\t\tExpect: " ~ foreign.type.humanizeType
                                    ~ "\n\t\tActual: " ~   local.type.humanizeType);

                            // println("inlineExpression: CALL.REPLACE " foreign " with " local);
                        }

                        expr.target = local;

                        local.GET_mut.status |= SS_MATCHED;

                        // TODO FIX VFACTS /////////////////////////////////////////////
                        expr.type.vfacts = local.type.vfacts;
                        // TODO FIX VFACTS /////////////////////////////////////////////
                    }
                    else if (expr.target == must_not_call)
                    {
                        fail("Cannot inline self-recursive fns: " ~ expr.target);
                    }
                }
                else if (expr.kind == "jump" || expr.kind == "__far_jump") :REPLICATE_JUMP
                {
                    if (expr.kind == "jump")
                    {
                        let foreign = expr.helpers;
                        let local   = helpersReplicas.unless_oob(foreign.index);
                        if (local)
                        {
                            // println("inlineExpression: REPLICATE jump #" foreign.index " -> #" local.index);

                            expr.helpers = local;
                            local.mask |= HM_LabelUsed;

                            break :REPLICATE_JUMP;
                        }

                        expr.kind = "__far_jump";
                    }

                    // println("Found a __far_jump: " ~ expr);

                    if (expr.helpers.local_of == _current_fn.target.globid)
                    {
                        // println("Fixing up a __far_jump: " ~ expr);
                        expr = solveJump_finish(:expr.flags, h: expr.helpers, expr: expr.items.only);
                    }
                    else
                    {
                        // TODO FIX these should be collected in later passes
                        _current_fn.far_jumps.set::add(expr.helpers.local_of);
                    }
                }

                // Replace foreign lifetimes with lifetimes to implicit closure args.
                visitType(expr.type);

                if (expr.kind == "call")
                {
                    // INLINE ARGUMENTS ////////////////////////////////////////////
                    if (expr.target.isLocal && expr.target.flags & F_INLINE)
                        expr = expr.target.solved.items[LET_INIT] || BUG(
                            "inlineExpression: F_INLINE local has no LET_INIT.");
                    // INLINE ARGUMENTS ////////////////////////////////////////////
                }
                else if (expr.helpers)
                {
                    if (expr.kind == "block" || expr.kind == "loop")
                    {
                        if (expr.helpers.ret_actual)
                        {
                            mut ret_actual: Type;

                            // TODO FAILCASE
                            // TODO FAILCASE test_node & co didn't notice this was missing, so ret_actuals had rogue lifetimes.
                            // TODO FAILCASE

                            // Appeasing bck.
                            swap(ret_actual, expr.helpers.ret_actual);
                            visitType(ret_actual);
                            swap(ret_actual, expr.helpers.ret_actual);
                        }
                    }
                    else if (expr.kind != "jump" && expr.kind != "__far_jump")
                    {
                        BUG("inlineExpression: TODO handle .helpers on a " ~ expr.kind);
                    }
                }
            }

            fn visitType(ref type: Type)
            {
                type.lifetime = type.lifetime.Lifetime_process(
                    |locid!index, continue_keep, continue_replace, paths|
                    {
                        if (!index)
                            continue_keep;

                        let foreign = nested(:index, :from);
                        let local   = matchReplicaOrInjectForeignLocal(foreign);

                        // INLINE ARGUMENTS ////////////////////////////////////////////
                        if (local.flags & F_INLINE)
                        {
                            let init = local.solved.items[LET_INIT] || BUG(
                                "inlineExpression: F_INLINE local has no LET_INIT.");

                            continue_replace(
                                init.type.lifetime
                                    ? Lifetime_op_join(init.type.lifetime, paths)
                                    : Lifetime_temporary);
                        }
                        // INLINE ARGUMENTS ////////////////////////////////////////////
                        else
                        {
                            // println("inlineExpression: LT.REPLACE " foreign " with " local);

                            continue_replace(
                                local.type.lifetime
                                    ? Lifetime_op_join(local.type.lifetime, paths)
                                    : BUG("visitType: !local.type.lifetime"));
                        }
                    });
            }

            visitNode(expr, :locals_start);
        }

        return expr;
    }

    fn CallerNode(
        debug: string,
        mut target: Target, mut args?: SolvedNode[], reorder?: Reorder, conversions?: Target[][])
            : SolvedNode
    {
        // Do reorder.
        if (reorder)
        {
            // TODO FIX this can be done in place, a neat little algo with swaps
            mut args_out: SolvedNode[];
            args_out.resize(reorder.map.len);

            for (mut i = 0; i < reorder.map.len; i++)
            {
                let idx = reorder.map[i];
                if (idx >= 0)
                    args_out[i] = steal(args[idx]);
            }

            args = args_out;
        }

        // `using` codegen.
        for (mut argIdx = 0; argIdx < conversions.len; argIdx++)
        {
            let conversion = conversions[argIdx];

            // Dead code elim.
            if (applyConversion(args[argIdx], :conversion))
            {
                // This is a bit dangerous -
                //  we're discarding these args after the fact.
                args.shrink(argIdx + 1);

                //
                makeNote(N_DeadConv);
                return createBlock(t_never, args);
            }
        }

        // Rest params.
        let REST_START = target.findRestStart();
        if (REST_START < args.len)
        {
            mut rest: SolvedNode[];
            rest.resize(args.len - REST_START);

            for (mut i = args.len; i --> REST_START; )
            {
                swap(rest[i - REST_START], args[i]);
                if (i > REST_START)
                    args.splice(i, 1);
                else
                    args[i] = createArrlit(rest);
            }
        }

        // This was previously part of tryMatch,
        //  but we can just as easily do it here.
        let kind = target.kind;
        let isZeroInit = kind == "type" && !args.len;
        if (!isZeroInit)
        {
            // Defaults & implicit argument injection.
            let host_args = target.args;
            args.resize(host_args.len);
            for (mut i = 0; i < args.len; i++)
            {
                let host_arg = host_args[i];

                if (!args[i])
                {
                    if (host_arg.default)
                    {
                        args[i] = inlineExpression(
                            expr: host_arg.default,
                            from: target);
                    }
                    else
                    {
                        host_arg.flags & F_IMPLICIT || BUG(
                            "tryMatch: about to implicit-bind a non-implicit argument: `"
                                ~ host_arg.name ~ ": " ~ humanizeType(host_arg.type) ~ "`.");

                        args[i] = bindImplicitArg(
                            :host_arg.name,
                            :host_arg.type, becauseOf: target);
                    }
                }

                // Dead code elim.
                if (args[i].is_never && !(host_arg.flags & F_INLINE))
                {
                    args.shrink(i + 1);
                    return deadCall(args);
                }
            }
        }

        mut type = target.type;

        // HACK -
        //  TBD how we make this stuff work in real life.
        //   OR alternatively, do this for arrays too.
        if (kind == "field")
            type = make_field_reference(
                from: args.only.type || BUG(), target);

        // So we're turning closeovers into implicit arguments -
        //  previously we tracked them separately but we're making everything more samey.
        else if (kind == "var")
        {
            TEST_varLifetime(type.lifetime, staticOK: true);

            // Track deps.
            if (target.locid ||
                target.modid == module.modid && !(target.flags & F_PUB))
            {
                // Suppress unused warnings,
                //  even if we end up throwing out this piece of code.
                GET_mut(target).status |= SS_MATCHED;
            }

            //
            if (target.isLocal &&
                target.localOf != _current_fn.target.globid)
            {
                target  = injectForeignLocal(target);
                type    = GET(target).type || BUG(
                    "CallerNode: !type on var " ~ target.name);
            }
        }

        // Funcs & co.
        else
        {
            // Track deps.
            if (target.modid == module.modid)
            {
                // Tracking call graph & type annotations.
                if (kind == "fn" || kind == "type" || kind == "inline")
                {
                    if (_solvingFnort)
                    {
                        if (EPH_mut(target).callers.set::add(_solvingFnort.globid))
                            EPH_mut(_solvingFnort).calls.set::add(target.globid);

                        detectRecursion(target);
                    }
                }
            }

            // Tag copies and moves.
            if (args)
            {
                // Non-zero-filled type-inits.
                if (kind == "type")
                    type.vfacts &= ~Typename;

                //
                let host_args = target.args || BUG("CallerNode: no host args: " ~ target);
                host_args.len == args.len || BUG("CallerNode: host_arg.len mismatch: " ~ target);

                for (mut i0 = 0; i0 < args.len; i0++)
                {
                    let host_arg = host_args[i0];

                    /////////////////
                    // Literal fixup.

                    // Drop argids at this point, not useful.
                    ref arg = args[i0];
                    if (arg.kind == "argid")
                        arg = arg.items.only;

                    let expect = host_arg.type;
                    {
                        let retype = tryRetyping(arg, expect);
                        if (retype && isAssignableAsArgument(expect, retype))
                            applyRetype(arg, retype);
                    }
                    //        /LITFIX
                    /////////////////
                }
                /////////////////////////////////////////////////////////////////////////////////
            }

            // Inliner.
            if (kind == "inline") :INLINE_ATTEMPT
            {
                if (SELF_TEST)
                {
                    target.modid != module.modid || target.revision > 0 || BUG(
                        "Inlining " ~ target ~ " at revision 0.");

                    TODO_FIX_inline_safety++ < 24 || BUG(
                        "Inliner recursion, something is off: " ~ target);
                }

                defer if (SELF_TEST) TODO_FIX_inline_safety--;

                //
                if (target.status & (SS_DID_START | SS_FINALIZED) == SS_DID_START)
                    break :INLINE_ATTEMPT;

                // For each argument, we collect:
                //  - letdefs we can unshift them in the inlined expression,
                //  - the letdef mapping for ref replacement.
                mut argdefs: SolvedNode[];
                mut letdefReplicas: Target[];
                let locals_start = GET_next_local_index();

                let host_args = target.args;
                host_args.len == args.len || BUG("inline: arglen mismatch");

                let RTL = target.isRTL;
                argsForward(:RTL, :host_args): |i|
                {
                    let host_arg = host_args[i];

                    // TODO FIX the let vs letdef mess
                    if (!host_arg.target)
                        continue;

                    let argdef = createLet(
                        id:     host_args[i].name,
                        init:   args[i],
                        flags:  host_arg.flags  &~ F_ARG
                                                &~ F_COMPOUND_ID

                                                // TODO FIX mutrefs lost in translation
                                                | (host_arg.flags & F_INJECTED && host_arg.is_mutref && F_REF)
                                                ,
                        setScope: false);

                    if (SELF_TEST)
                    {
                        argdef.kind == "empty" || argdef.kind == "letdef" || BUG(
                            "Inliner: argdef neither letdef nor empty: " ~ argdef);
                        argdef.target || BUG(
                            "Inliner: no argdef.target: " ~ argdef);
                    }

                    if (argdef.kind != "empty" && !(argdef.target.flags & F_INLINE))
                        argdefs ~= argdef;

                    // Watch it, cross-module locals.
                    let foreign = host_arg.target;
                    letdefReplicas.grow_if_oob(foreign.locid) = argdef.target || BUG();
                    lax shadow let foreign = GET(foreign);

                    if (SELF_TEST)
                        isAssignable(host: foreign.type, argdef.target.type)
                            || argdef.target.type.is_never && argdef.target.flags & F_INLINE
                            || BUG("Inliner botching the argdef type of " ~ foreign ~ ":\n"
                                ~ "\n\t\tExpect: " ~       foreign.type.humanizeType
                                ~ "\n\t\tActual: " ~ argdef.target.type.humanizeType);

                    // println("inline: ARGDEF.REPLACE " foreign " with " argdef);
                }

                //
                let n_body = target.solved.items.last;
                mut s_body = inlineExpression(
                    from: target, expr: n_body, :letdefReplicas, :locals_start,
                    must_not_call: target);

                if (argdefs)
                {
                    s_body.kind || BUG("inline: no s_body.kind");
                    if (s_body.kind != "block")
                        s_body = createBlock(argdefs ~ s_body, type: s_body.type);
                    else
                        s_body.items.splice(0, 0, argdefs);
                }

                return s_body;
            }

            // Not relevant for inline fns.
            if (args && type.is_ref)
                type.lifetime = TEST_Lifetime(:type,
                    Lifetime_replaceArgsAtCallsite(target, args),
                    tempsOK: true);
        }

        return SolvedNode(
            "call", flags: [], value: debug,
                    :type, args, :target);
    }

    fn definitWrap(ref node: SolvedNode, slot: Type)
    {
        CANNOT_definit_mutrefs && slot.is_mutref && BUG(
            "Trying to definitWrap a mutref: " ~ slot.humanizeType(lt: true));

        if (slot.is_ref && !slot.lifetime.hasStatic)
        {
            // TODO FIX this is questionable stuff,
            //  should get resolved by createTemporary
            if (slot.lifetime.hasTemporary)
                return definitWrap(node, clear_refs(slot));

            BUG("Trying to definitWrap a non-static reference: " ~ slot.humanizeType(lt: true))
        }

        if (node.kind == "definit")
            node.type = slot;
        else
            node = createBlock(node, createDefinit(slot));
    }

    fn maybeCopyOrMove(ref node: SolvedNode, slot: Type, isArgument! = false, debug!?: string): void
    {
        if (slot.isIrrelevant)
            return;

        if (SELF_TEST && slot.is_never && slot.usage)
            BUG("maybeCopyOrMove: slot.is_never but some usage bits set");

        if (!node.canon.canon::isCanonAssignable(host: slot.canon)
                && !node.is_never)
        {
            if (node.type.is_zeroes && !(slot.is_mutref && CANNOT_definit_mutrefs))
                return definitWrap(node, slot);

            BUG("Considering copy or move for incompatible types: "
                ~ humanizeType(slot) ~ " <- "
                ~ humanizeType(node));
        }

        // No copy needed when the slot is a reference.
        if (slot.is_ref)
        {
            // TODO move this to codegen
            if (node.type.is_trivial)
            {
                // Except if we're talking a fnarg,
                //  in which case we're better off binding a temporary,
                //   else we risk cache missing on the useless global defval.
                //
                // We only do it for trivial types because
                //  we don't want to add a destructor call here.
                //
                if (node.kind == "definit" && isArgument)
                    node.type = clear_refs(node.type);
            }

            return;
        }

        // Also, no copy needed when the expression is a value.
        if (!node.type.is_ref)
            return;

        // Definits can just as well emit values.
        if (node.kind == "definit")
        {
            node.type = clear_refs(node.type);
            return;
        }

        // Getting messier by the minute.
        if (node.is_zeroes)
            return definitWrap(node, slot);

        // Copy line:col attrib.
        let here0   = _here;
        defer _here = here0;
        _here       = node.token;

        // This may convert to a move during relaxAll.
        node = SolvedNode(
            kind:   "copy",
            value:  debug,
            items:  [ node ],
            type:   clear_refs(node.type));
    }


    //

    fn solveNodes(
        nodes: Node[],
        dead_brk: DeadBreak,
        type_all?: Type,
        type_last!?: Type,
        use_type_last!?: bool,
        static_eval_brk!?: StaticEval,
        TODO_FIX_useSpecPath!?: bool): SolvedNode[]
    {
        mut result: SolvedNode[];

        ////////////////////
        let here0   = _here;
        defer _here = here0;
        ////////////////////

        for (mut i = 0; i < nodes.len; i++)
        {
            let node = nodes[i];
            if (!node)
                continue;

            // Regular solve.
            let unorderedClass = unorderedClassify(node.kind);
            if (!unorderedClass)
            {
                HERE(node);

                let last            = i == nodes.len - 1;
                let type            = last && use_type_last ? type_last : type_all;

                //
                let solved = solveNode(:node, :type);

                result ~= solved;

                // Dead code elim.
                if (solved.type.is_never && dead_brk
                        && (dead_brk != DeadBreak_Only_WhileSolvingRecursion ||
                            solved.type.is_AssumeNever_WhileSolvingRecursion))
                {
                    if (i < nodes.len - 1)
                        makeNote(N_DeadCode);

                    break;
                }

                // Static eval.
                if (static_eval_brk)
                {
                    let ae_item = tryAbstractEvalAsBool(solved, voidOk: i == nodes.len - 1);
                    if (ae_item == static_eval_brk)
                        break;
                }

                continue;
            }

            // Unordered solve -
            //  batches multiple potentially recursive declarations,
            //   so we can expose them all in scope prior to solving types.

            // This allows us to have groups of mutually recursive types & functions,
            //  without risking stuff depending on constants & variables
            //   introduced halfway through.
            let i0 = i;
            mut i1 = nodes.len;

            let offset = result.len - i0;

            // First pass, expose stuff in scope
            //  without doing type checking when possible.
            for (shadow mut i = i0; i < nodes.len; i++)
            {
                shadow let node = nodes[i] || BUG("solveNodes, prep-a: falsy node");
                if (unorderedClassify(node.kind) != unorderedClass)
                {
                    i1 = i;
                    break;
                }

                HERE(node);
                result ~= unorderedPrep_A(node, :TODO_FIX_useSpecPath);
            }

            // Later we'll continue from group end.
            i1 > i0 || BUG();
            i = i1 - 1; // <- loop++

            // Second prep pass, limit access to scope
            //  of all newly generated entries to what we have right now.
            //
            unorderedPrep_B(
                nodes[i0 : i1],
                result[i0 + offset : i1 + offset],
                unorderedClass);

            // TODO REMOVE, solve all.
            mut repeat = true;
            while (repeat)
            {
                repeat = false;

                for (shadow mut i = i0; i < i1; i++)
                {
                    shadow let node = nodes[i] || BUG("solveNodes, solve: falsy node");
                    HERE(node);

                    // TODO do this while listing exports instead, expect trouble with prelude.
                    let into = result[i + offset].target;
                    if (lazySolveStart(into))
                        repeat = true;
                }
            }
        }

        //
        return result;
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //
    // Borrow checker, runs. after relaxer, but before AAR (ideally) -
    //  This means everything solved, fully relaxed, a lot of mutrefs now refs, etc.

    fn willPassByValue(arg: Argument)
    {
        return arg.acceptsTempCopies()
            && arg.type.isPassByValue();
    }

    fn willPassByValue(o: Overload)
    {
        return o.acceptsTempCopies()
            && o.type.isPassByValue();
    }

    fn rejectsTempCopies(arg: Argument)
    {
        return arg.flags & F_IMPLICIT   ? CantTempCopy_HostArg_Implicit
             : arg.flags & F_REF        ? CantTempCopy_HostArg_Ref
             : arg.type.is_mutref       ? CantTempCopy_HostArg_MutRef
             : [];
    }

    fn acceptsTempCopies(arg: Argument)
    {
        return !arg.rejectsTempCopies();
    }

    fn acceptsTempCopies(o: Overload)
    {
        return   o.kind == "var"
            && !(o.flags & (F_IMPLICIT | F_REF))
            &&  !o.type.is_mutref;
    }

    fn acceptsSoftRisk(arg: Argument)
    {
        return !arg.acceptsTempCopies();
    }

    fn acceptsSoftRisk(o: Overload)
    {
        return o.flags & F_ARG && !o.acceptsTempCopies();
    }

    fn isFieldChain(arg: SolvedNode)
    {
        if (arg.kind != "call")
            return false;

        let t = arg.target.kind;
        return t == "var" || t == "field" && isFieldChain(arg.items.only);
    }

    fn PASS_borrowCheck(ref root: SolvedNode, pass: BorrowCheckPass)
    {
        // Now bck does two passes:
        //
        //  - AAR = false:  this is the fn-local first bck pass.
        //  - AAR = true:   this is the second ARGUMENTS AT RISK pass.
        //
        inline fn AAR = pass == BCK_aar;
        inline fn BCK = pass == BCK_bck;

        fn cannotFailAfterBCK(reason: string)
            BCK && fail(reason)
                || BUG(pass ~ " is trying to emit an error:\n\n\t" ~ reason);

        shadow let fail = fn cannotFailAfterBCK;


        //

        fn tokenHash(token: TokenIdx)
            (token.modid.u32 * 9973 ^ token.tokidx.u32) << 20;

        fn WriteID(locid: i32, token: TokenIdx)
            WriteID(locid.u32 | (BCK && token.tokenHash));

        fn locid(w: WriteID)
            (w._locid_and_hash & 0xfffff).i32;

        fn tokenHash(w: WriteID)
            w._locid_and_hash & 0xfff00000;


        //

        fn ArgRationale_explain(r: ArgRationale, callee: Target, arg: SolvedNode, host_arg: Argument)
        {
            if (r == CantTempCopy_FastFn)
                return "Temporary copies not allowed in fast fns.";
            if (r == CantTempCopy_NonCopiable)
                return host_arg ~ " is non-copyable: " ~ humanizeType(arg);

            if (r == CantTempCopy_HostArg_Ref)
                return host_arg ~ " is " ~ "ref".qBAD;
            if (r == CantTempCopy_HostArg_Implicit)
                return host_arg ~ " is " ~ "implicit".qBAD;
            if (r == CantTempCopy_HostArg_MutRef)
                return host_arg ~ " is a mutref: " ~ humanizeType(arg);

            if (r == CantTempCopy_ReturnedFromFn)
                return host_arg ~ " is ref-returned from " ~ callee;

            if (SELF_TEST)
                BUG("Unknown reason.");

            return "Unknown reason.";
        }


        //

        fn RESOLVE_byAAR(read!: i32, write!: i32, trySoft!: bool)
        {
            AAR || BUG();

            read != write || BUG("RESOLVE_byAAR: read == write");

            // Soft vs hard risk -
            //  Non-direct reads from arguments put the argument at hard risk.
            if (!trySoft || !nested(read).acceptsSoftRisk)
                if (!_current_fn.flow.at_hard_risk.grow_if_oob(write).add_once(read))
                    return true; // Done this already.

            // So, on first add -
            if (!_current_fn.flow.at_soft_risk.grow_if_oob(write).add_once(read))
                return true; // Done this already.

            // Shake [1] - decomp write parents on first add.
            let ascendWrites = ||
            {
                let parents = _current_fn.flow.arg_parents.unless_oob(write);
                if (parents)
                {
                    for (mut i = 0; i < parents.len; i++)
                    {
                        let parent = parents[i];

                        // Here's the smart ascent thing -
                        //  A write through some parent binding
                        //   can't invalidate the same binding's read.
                        //
                        // This is a bit crazy, I think it wouldn't be necessary
                        //  if we could remove the invalidation edges on the go.
                        //
                        if (parent != read)
                            RESOLVE_byAAR(:read, write: parent, :trySoft);
                    }

                    return true; // AAR always succeeds.
                }
            };

            // Shake [2] - decomp read parents on first add.
            let ascendReads = ||
            {
                let parents = _current_fn.flow.arg_parents.unless_oob(read);
                if (parents)
                {
                    for (mut i = 0; i < parents.len; i++)
                    {
                        let parent = parents[i];

                        // TODO failcase without this if, suite doesn't catch items
                        if (parent != write)
                            RESOLVE_byAAR(:write, read: parent, trySoft: false);
                    }

                    return true; // AAR always succeeds.
                }
            };

            // Climb one way or the other.
            let firstTry_to_ascendWrites = write > read;
            for (mut i = 0; i < 2; i++)
                if (!i == firstTry_to_ascendWrites) // if (!0 == true or !1 == false)
                    ascendWrites();
                else
                    ascendReads();

            //
            return true; // AAR always succeeds.
        }

        fn RESOLVE_byAAR(write!: i32, reads!: [i32], trySoft!: bool)
        {
            reads.each: |read|
                if (read && read != write)
                    RESOLVE_byAAR(:read, :write, :trySoft);

            return true;
        }


        //

        fn RESOLVE_byAAR(writes!: WriteID[], read!: i32, trySoft!: bool)
        {
            for (mut i = 0; i < writes.len; i++)
                RESOLVE_byAAR(write: writes[i].locid, :read, :trySoft);

            return true;
        }


        // Converting lets into vals:

        fn RESOLVE_byMutvar(target: Target)
        {
            return target.globid == _current_fn.target.globid
                && RESOLVE_byMutvar(target.locid);
        }

        fn RESOLVE_byMutvar(target: i32)
        {
            BCK || BUG();

            let t = nested(target);
            ref o = GET_mut(t);

            if (!o.acceptsTempCopies)
                return false;

            o.type.is_mutref && BUG(
                o ~ ": Not F_REF but type.is_mutref"
                        ~ " in RESOLVE_byMutvar: is this a problem?");

            o.kind == "var" || BUG("RESOLVE_byMutvar: Not a variable.");
            TEST_varLifetime(o.type.lifetime);

            if (!o.type.is_rx_copy)
                return false;

            if !(o.flags & F_MUT)
            {
                o.flags  |= F_MUT;
                let t_let = clear_refs(o.type);

                o.solved.type = t_let;
            }

            return true;
        }


        // Inserting a temporary.

        fn RESOLVE_byTempCopy(ref callsite!: SolvedNode, position: i32, debug!: string)
        {
            let target      = callsite.target;
            ref arg         = callsite.items[position];

            return RESOLVE_byTempCopy(:arg, :target, :position, :debug);
        }

        fn RESOLVE_byTempCopy(ref arg!: SolvedNode, target!: Target, position: i32, debug!: string)
        {
            BCK || BUG();

            // No copy injection in fast fns.
            if (_current_fn.asserts & A_FAST)
                return CantTempCopy_FastFn;

            // Back here.
            let host_args   = target.args;
            let host_arg    = host_args[position];

            // No go if arg is nocopy.
            if (!arg.is_rx_copy)
                return CantTempCopy_NonCopiable;

            // Try to introduce a copy on an intermediate variable.
            //  This should help with closures and stuff.
            if (arg.kind == "call" && RESOLVE_byMutvar(arg.target))
                return [];

            // We don't allow this on implicit arguments, which includes closures.
            //  Implicitly copying implicit arguments is a bit much (TODO not sure, is it?).
            let r = host_arg.rejectsTempCopies;
            if (r)
                return r;

            // Re: m_and_c_cant_alias_002 test:
            //  We don't want to return a reference to the temporary,
            //   so for now we just forbid this.
            let isReturned = target.type.lifetime
                            .Lifetime_has(argidx: position);

            if (isReturned)
                return CantTempCopy_ReturnedFromFn;

            // Go.
            {
                let slot = host_args[position].type;

                // Reconstruct a maybe-copyable value type -
                //  slot is a ref which may not need q_rx_copy.
                shadow let slot = slot.clear_refs().make_copyable();

                // TODO FIX How do we defer this copy?
                //  MCOM needs to pick up something.
                maybeCopyOrMove(arg, slot, :debug);
                return [];
            }
        }


        //

        fn isInvalidatedBy(read: Lifetime, write: Lifetime)
        {
            write.Lifetime_each: |locid!w|
            {
                if (w && Lifetime_hasInter(read, flow.rg_invalidates.unless_oob(w)))
                    return true;
            }

            return false;
        }

        fn softRiskSafe(arg: SolvedNode)
        {
            // TODO FIX REFERENCE STABILITY: the problem is that
            //  when we have a ref with some lt, we don't know if
            //   - it points directly to the bytes of x
            //   - or is some kind of computed thing,
            //      e.g. ptr to some rellocatable mem it owns.
            //
            // TODO FIX this can't be currently correct for views,
            //  where an argument that evaluates later can easily
            //   invalidate the view.
            //
            // Currently appears to be addressed
            //  by the TODO_FIX_isArray in updateScope.
            //
            return isFieldChain(arg);
        }


        //

        fn SLOW_find(test): SolvedNode
        {
            SLOW_traverse(root): |node|
                if (test(:node))
                    return node;

            return [];
        }

        fn SLOW_findByReadID(read!: i32, loop_start!: i32)
        {
            fn checkLoopStart(_loop_start: i32)
            {
                if (_loop_start <= loop_start)
                    return _loop_start == loop_start;

                for (mut i = 0; i < _helpers_data.len; i++)
                {
                    let h = _helpers_data[i];
                    if (h.locals_start == _loop_start)
                        return checkLoopStart(
                            h.postdom.parent_loop_start);
                }

                return false;
            }

            return SLOW_find(|node|
                node.kind == "call" &&
                node.target.isLocal &&
                node.target.locid == read &&
                checkLoopStart(:node._loop_start))
                    || BUG("Cannot find read(" ~ nested(read) ~ ") in loop(" ~ loop_start ~ ").");
        }


        //

        fn RWEvent_stack(write: WriteID)
        {
            let locid = write.locid;

            SLOW_traverse(root): |node|
            {
                if (node.token.tokenHash != write.tokenHash)
                    continue;
                if (node.kind != "call" && node.kind != "pragma")
                    continue;

                if (node.kind == "call")
                {
                    for (mut i = 0; i < node.items.len; i++)
                    {
                        let arg = node.items[i];
                        if (arg.lifetime.Lifetime_has(:locid))
                        {
                            let host_arg = node.target.args[i];
                            if (host_arg.flags & F_WRITTEN_TO)
                                return node.token.addr_and_snippet
                                     ~ "\n\tAt call to " ~ node.target
                                     ~ qSTACK(node.target, position: i);
                        }
                    }
                }
                else if (node.kind == "pragma")
                {
                    for (mut i = 0; i < node.items.len; i++)
                    {
                        let arg = node.items[i];
                        if (arg.is_mutref && arg.lifetime.Lifetime_has(:locid))
                            return arg.token.addr_and_snippet
                                 ~ "\n\tvia pragma " ~ node.value.qID;
                    }
                }

                continue;
            }

            return "\n\n\tCOMPILER BUG: RWEvent_stack could not find write to " ~ nested(write.locid);
        }


        // Reads.

        fn flow         = _current_fn.flow;
        fn events       = _current_fn.events;

        fn Reference_trackArgument(target: i32, position: i32)
        {
            // Argument position -> target,
            //  this is only needed for collecting the outcomes at the end.
            flow.arg_targets.len <= position || BUG("Reference_trackArgument: positions out of order.");
            flow.arg_targets.grow(position + 1);
            flow.arg_targets[position] = target;

            // Speed up memberships checks.
            flow.is_arg.add(target);
        }

        fn Lifetime_getRefLocid_unlessStatic(lifetime: Lifetime)
        {
            mut left: i32;

            lifetime.Lifetime_each: |locid, isStatic|
            {
                // Doesn't seem to matter right now, doing this for ZSTs,
                //  which we might want to always have static.
                if (isStatic)
                    continue;

                (left && BUG("Lifetime_getRefLocid_unlessStatic: multiple locids in left_lt"))
                    = locid || BUG("Lifetime_getRefLocid_unlessStatic: non-locid/non-static in left_lt");
            };

            return left;
        }

        fn Reference_trackLocalRef(t_left: Type, right: Lifetime)
        {
            let left = Lifetime_getRefLocid_unlessStatic(t_left.lifetime);
            if (!left)
                return;

            //
            shadow let right = right.Lifetime_process(|locid, continue_keep|
            {
                if (locid)
                    continue_keep();
            });

            // trackLocalRef during bck:
            //  defers lead to out-of-order bck,
            //   so this doesn't hold.
            //
            // If defers solved in the right order
            //  it'd be nice to run this back on,
            //   now we're running with scissors.
            //
            // flow.invalidates.len <= left || assert();

            mut parents:    Lifetime;
            mut siblings:   Lifetime;

            parents.Lifetime_add(right);

            right.Lifetime_each: |shadow locid!right, paths|
            {
                if !(right)
                    continue;

                if (SELF_TEST)
                {
                    if (!right)
                        BUG("Reference_trackLocalRef: right has non-locals.");

                    let t_right = nested(right).type;
                    type_mayPointInto(host: t_right, t_left)
                        || BUG("type_mayPointInto fails for "
                                    ~ nested(left) ~ " := " ~ nested(right));
                }

                flow.rg_children.grow_if_oob(right).set::add(left);

                //
                parents.Lifetime_add(
                    Lifetime_op_join(
                        flow.rg_parents.unless_oob(right), paths));

                //
                siblings.Lifetime_add(flow.rg_invalidates.unless_oob(right));

                // Propagate alised arguments.
                if (flow.is_arg.has(right))
                {
                    flow.is_arg.add(left);
                    flow.arg_parents.grow_if_oob(left).set::add(right);
                }
            }

            // Disjointness, here we notice references with common ancestors
            //  that don't actually intersect and can't invalidate each other.
            //
            siblings = siblings.Lifetime_process(|locid!sibling, continue_keep|
            {
                let sibling_parents = flow.rg_parents.unless_oob(sibling);
                if (Lifetime_hasInter(parents, sibling_parents))
                    continue_keep();
            });

            // So, if:
            //  LEFT = &RIGHT;
            if (siblings)
            {
                if (SELF_TEST && siblings.Lifetime_has(locid: left))
                    BUG("siblings.has(left)");

                // Siblings rule:
                //  LEFT invalidates everything RIGHT invalidates.
                //
                // Same thing backward:
                //  Everything that RIGHT invalidates potentially invalidates LEFT.
                //
                (flow.rg_invalidates.grow_if_oob(left)
                    && BUG("rg_invalidates already set"))
                        = siblings;

                siblings.Lifetime_each: |locid!sibling|
                {
                    if (SELF_TEST && !sibling)
                        BUG("Reference_trackLocalRef: siblings has non-locals.");

                    flow.rg_invalidates.grow_if_oob(sibling)
                        .Lifetime_add(t_left.lifetime);
                }
            }

            if (parents)
            {
                (flow.rg_parents.grow_if_oob(left)
                    && BUG("rg_parents already set"))
                        = parents;

                // Parent rule, one-sided:
                //  Finally, RIGHT invalidates LEFT.
                parents.Lifetime_each: |locid!parent|
                {
                    if (SELF_TEST && !parent)
                        BUG("Reference_trackLocalRef: parents has non-locals.");

                    flow.rg_invalidates.grow_if_oob(parent)
                        .Lifetime_add(t_left.lifetime);
                }
            }
        }

        fn bck_trackRead(callsite: SolvedNode)
        {
            if (!callsite.target.isLocal)
                return;

            // println("bck_trackRead " ~ target ~ " " ~ callsite.value);

            _here           = callsite.token;
            let target      = callsite.target.locid;
            let loop_start  = callsite._loop_start || BUG("bck_trackRead: loop_start not set on callsite.");

            TEST_varLifetime(callsite.type.lifetime, locid: target, staticOK: TODO_FIX_static_ZSTs);

            // Writes invalidate subsequent reads.
            if (events.invalidated_by.len > target)
            {
                let u = events.invalidated_by[target];
                if (u)
                {
                    if (AAR ? !RESOLVE_byAAR(read: target, writes: u, trySoft: true /* F_REF check inside */)
                            : !RESOLVE_byMutvar(target))
                    {
                        fail("Cannot access"
                            ~ " " ~        target.nested ~ ", reference invalidated by write to"
                            ~ " " ~ u.first.locid.nested ~ " at "
                            ~ RWEvent_stack(u.first));
                    }

                    if (OPTI_bck)
                        events.invalidated_by[target] = [];
                }
            }

            // Track reads in a loop.
            if (target < loop_start)
                events.used_in_a_loop.add(target);
        }


        // Writes.

        fn bck_trackWrites(callOrPragma: SolvedNode, lifetime: Lifetime)
        {
            let loop_start  = callOrPragma._loop_start || BUG("bck_trackWrites: _loop_start not set on callsite.");
            let OPTI_isLoop = loop_start != 1 && !!events.used_in_a_loop;
            let OPTI_hasPRA = !!events.preceding_ref_args;

            //
            lifetime.Lifetime_each: |locid!write, region!write_region, paths!write_paths|
            {
                if (!write)
                {
                    // TODO FIX - we're getting weird stuff here,
                    //  probably statics from arr[i] Lifetime_makeShared.
                    //
                    // BUG("bck_trackWrites: Non-local region.");
                    continue;
                }

                // println("bck_trackWrite " ~ target ~ " " ~ callsite.value);

                mut all_written = write_region;

                // The write may not invalidate its parents,
                //  but it might still change their value.
                //   Search tests for:
                //
                //      a * { ref x = z || a; x++ }
                //
                // Doing it for all args, including the first arg.
                //  Search tests for:
                //
                //      { ref x = z || a; x++ } * a
                //
                // In both cases we need to sequence the order of eval of `a` and `x++`.
                //
                all_written.Lifetime_add(
                    Lifetime_op_join(
                        flow.rg_parents.unless_oob(write),
                        write_paths));

                let invalidates = flow.rg_invalidates.unless_oob(write);

                if (SELF_TEST && invalidates.Lifetime_has(locid: write))
                    BUG("flow.invalidates[write].has(write): " ~ GET(nested(write)));

                shadow let invalidates = invalidates.Lifetime_process(
                    |locid!invalidatee, continue_keep|
                    {
                        let parents = flow.rg_parents.unless_oob(invalidatee);
                        if (Lifetime_hasInter(parents, all_written))
                            continue_keep();
                    });

                // Writes in a loop invalidate preceding reads.
                if (OPTI_isLoop) invalidates.Lifetime_each: |locid!read|
                {
                    read || BUG("bck_trackWrites: invalidates contains non-locals.");
                    if (read < loop_start)
                    {
                        if (events.used_in_a_loop.has(read))
                        {
                            if (AAR)
                                RESOLVE_byAAR(:read, :write, trySoft: true /* F_REF check inside */);
                            else
                                RESOLVE_byMutvar(read) || fail(
                                    "Write to " ~ write.nested
                                        ~ (callOrPragma.kind == "call" && " at call to " ~ callOrPragma.target)
                                        ~ " invalidates the use of " ~ read.nested ~ " at "
                                        ~ SLOW_findByReadID(:read, :loop_start).token.addr_and_snippet
                                        ~ "\n\t... on next loop iteration.\n\n\tWritten"
                                        ~ qSTACK(callOrPragma, :write));
                        }
                    }
                }

                // Order of eval.
                let writeID = WriteID(locid: write, token: callOrPragma.token);

                // TODO FIX clean it up, previously in bck_call, shoehorned here.
                if (OPTI_hasPRA)
                {
                    mut all_written_and_invalidated = all_written;

                    all_written_and_invalidated.Lifetime_add(invalidates,
                        flatCountMismatchOK: true);


                    // Check if this write invalidates
                    //  any preceding reference argument bindings.

                    mut w = -1

                    for (shadow mut i = 0; i < _current_fn.preceding_ref_args.len; i++)
                    {
                        ref pra = _current_fn.preceding_ref_args[i];

                        //
                        if (pra.w < 0)
                            w >= 0 || BUG("preceding_ref_args: No leading .w position.");
                        else
                            w = pra.w;

                        let r = pra.r;

                        //
                        let bound   = pra.arg.type.lifetime;
                        let inter   = bound.Lifetime_interLocids(all_written_and_invalidated);
                        if (!inter)
                            continue;

                        // We'll have to inject a copy here.
                        if (AAR ? !RESOLVE_byAAR(:write, reads: inter,

                                    // Considered making this host_arg.acceptsSoftRisk,
                                    //  which would work (should it though?) if:
                                    //
                                    //      ref arg_binding = read;
                                    //
                                    // But this could also be:
                                    //
                                    //      ref arg_binding = read[something];
                                    //
                                    // So the succeeding write to another argument
                                    //  can invalidate the binding.
                                    //
                                    // Could revisit this when we have some notion of reference stability,
                                    //  but currently the rule is soft-risk only applies to
                                    //   direct use of arguments without intermediate bindings,
                                    //    and here we're introducing an intermedite binding - the callee argument.
                                    //
                                    trySoft: softRiskSafe(pra.arg))

                                : !!RESOLVE_byTempCopy(:pra.target, :pra.arg, r, debug: "bck:pra " ~ write))
                        {
                            // Appease bck
                            shadow ref pra = _current_fn.preceding_ref_args[i];

                            //
                            _here = pra.callsite_token;

                            fail("At call to " ~ pra.target ~ ", binding for "
                                ~ pra.target.args[r] ~ " (arg #" ~ r ~ ") at "
                                ~ pra.arg.token.addr_and_snippet
                                ~ "\n\t... invalidated by subsequent write to "
                                ~ nested(write) ~ " upon evaluation of "
                                ~ pra.target.args[w] ~ " (arg #" ~ w ~ ") at "
                                ~ RWEvent_stack(writeID));
                        }
                    }
                }

                // Track writes, easy.
                invalidates.Lifetime_each: |locid!invalidatee|
                {
                    ref set = events.invalidated_by.grow_if_oob(invalidatee);
                    if (BCK)
                    {
                        // BCK only needs a single event to do its thing.
                        if (!set)
                            set ~= writeID;
                    }
                    else
                    {
                        // AAR needs each unique target,
                        //  we don't hash the tokens so set::add should do it.
                        //
                        if (SELF_TEST)
                            writeID._locid_and_hash.i32 == write || BUG(
                                "AAR: writeID._locid != write locid, set::add wont be able to dedupe");

                        set.set::add(writeID);
                    }
                }
            }
        }

        fn bck_trackInit(target: Target)
        {
            let index   = target.locid;

            // TODO FIX addrofn emits target=0 lets,
            //  this is stupid, no need for such garbage to stay in the ast.
            if (!index)
                return;

            // Clear invalidation event -
            //  we mistakenly collect these for writes to vars we depend on before init event.
            //   But this same technique can also be used for ref reassignment later on.
            //
            // NOT EXPECTING THIS RIGHT NOW //////////////////////////
            events.invalidated_by.unless_oob(index) && BUG();       //
            // if (events.invalidated_by.unless_oob(index))         //
            //     events.invalidated_by[index] = WriteID();        //
            //////////////////////////////////////////////////////////
        }


        //

        fn bck_let(ref node: SolvedNode)
        {
            // Solve init expr.
            bck_node(node.items[LET_INIT]);

            // Track references.
            if (node.is_ref && !node.target.willPassByValue())
            {
                node.flags & F_ARG && BUG("bck_let: Found an argument!");

                let init = node.items[LET_INIT];
                init.type.is_ref || BUG("What!");

                Reference_trackLocalRef(
                    t_left: node.target.type,
                    right:  init.type.lifetime);
            }

            // De-invalidate after init expr,
            //  could be invalidated by the init expr, for example:
            //   let c = a = b;
            //
            bck_trackInit(node.target);
        }


        //

        fn bck_call(ref callsite: SolvedNode)
        {
            fn target   = callsite.target;
            fn args     = callsite.items;

            if (!args)
            {
                if (target.kind == "var")
                    bck_trackRead(callsite);

                return;
            }

            let RTL         = target.isRTL;
            let host_args   = target.args;

            ///////////////////////////////////////////////
            {
                let pra_len0 = _current_fn.preceding_ref_args.len;

                mut pra_first = -1;

                argsForward(:RTL, :host_args, |i, host_arg, ooe_isLast|
                {
                    // We keep a current .w position on
                    //  the first PrecedingRefArg we emit,
                    //   we pick those up when checking PRAs,
                    //    and use them to emit a nicer error message.
                    //
                    // The .w is the index of the argument
                    //  whose evaluation results in a write,
                    //   == the one we're running bck_node on.
                    //
                    if (pra_first >= 0)
                        _current_fn.preceding_ref_args[pra_first]
                            .w = i;

                    //
                    ref arg = args[i];
                    bck_node(arg);

                    if (!ooe_isLast && arg.is_ref && host_arg.is_ref)
                    {
                        mut pra: SolvedNode;
                        pra.kind = "__preceding_ref_arg";

                        let pra_index = _current_fn.preceding_ref_args.len;
                        pra.helpers.index = pra_index;

                        if (pra_first < 0)
                            pra_first = pra_index;

                        swap(pra, arg);

                        _current_fn.preceding_ref_args ~= PrecedingRefArg(
                            callsite_token: callsite.token,
                            :target, r: i, w: -1, arg: pra);
                    }
                });

                for (mut i = 0; i < args.len; i++)
                {
                    ref arg = args[i];
                    if (arg.kind == "__preceding_ref_arg")
                    {
                        ref pra = _current_fn.preceding_ref_args[arg.helpers.index];

                        if (SELF_TEST)
                            pra.target == target && pra.r == i || BUG(
                                "preceding_ref_args got messed up");

                        swap(arg, pra.arg);
                    }
                }

                _current_fn.preceding_ref_args.shrink(pra_len0);
            }
            ///////////////////////////////////////////////

            // BORROWCK ////////////////
            mut bck_writes: Lifetime;

            mut mutref_first    = -1;
            mut mutref_last     = -1;
            mut ref_first       = -1;
            mut ref_last        = -1;

            //
            mut bck_unwound: Lifetime[];

            mut arg_first       = -1;
            mut arg_last        = -1;
            ////////////////////////////


            for (mut i0 = 0; i0 < args.len; i0++)
            {
                let host_arg0   = host_args[i0];
                let expect      = host_arg0.type;

                // BORROWCK: multiple mutrefs error,
                //  this is the only thing we can't workaround by copying.
                if (expect.is_ref)
                {
                    // Lazy init unwound lifetimes.
                    if !(bck_unwound)
                    {
                        if (mutref_first >= 0 || ref_first >= 0 && expect.is_mutref)
                        {
                            bck_unwound.resize(args.len);
                            for (shadow mut i0 = ref_first; i0 <= ref_last; i0++)
                            {
                                let unwound = bck_unwound[i0] = Lifetime_unwind(
                                    args[i0].type.lifetime, locals_only: true);

                                // Locate first and last callsite arguments
                                //  that refer to caller arguments,
                                //   so we can later on loop over them faster.
                                //
                                // TODO: args at risk: ignore closures & implicits,
                                //  they are disjoint by definition.
                                //   But are they? You can totally have
                                //    an implicit ref a = implicit b.
                                //
                                // TODO: args at risk: ignore non-aliasable types.
                                //
                                unwound.Lifetime_each: |locid|
                                {
                                    if (locid)
                                    {
                                        arg_first   = arg_first < 0 ? i0 : arg_first;
                                        arg_last    = i0;
                                        continue;
                                    }
                                }
                            }
                        }
                    }

                    // Validate aliasing.
                    if (bck_unwound)
                    {
                        let arg0     = args[i0];
                        let shallow0 = arg0.type.lifetime;
                        let unwound0 = bck_unwound[i0] = Lifetime_unwind(
                            shallow0, locals_only: true);

                        // Keep track of caller arguments.
                        unwound0.Lifetime_each: |locid|
                        {
                            if (locid)
                            {
                                arg_first   = arg_first < 0 ? i0 : arg_first;
                                arg_last    = i0;
                                continue;
                            }
                        }

                        //
                        fn validate(i1: i32)
                        {
                            let host_arg1 = host_args[i1];

                            // Can the fn handle aliasing here?
                            if (host_arg0.may_invalidate.has(i1) && host_arg1.may_invalidate.has(i0))
                                return;

                            let arg1     = args[i1];
                            let shallow1 = arg1.type.lifetime;

                            // A note on something that's non-obvious -
                            //  the AAR stuff here DOESNT CARE ABOUT ALIASING -
                            //   we've already dealt with aliasing by the time this runs.
                            //
                            // Also the invalidates/invalidators AAR stuff doesn't affect parenting,
                            //  so we don't get intersections in unwound0 and unwound1.
                            //
                            if (AAR)
                            {
                                if (i0 >= arg_first && i0 <= arg_last &&
                                    i1 >= arg_first && i1 <= arg_last)
                                {
                                    shallow0.Lifetime_each: |locid!region0|
                                    {
                                        if !(region0)
                                            continue;

                                        shallow1.Lifetime_each: |locid!region1|
                                        {
                                            if !(region1 && region0 != region1)
                                                continue;

                                            if (host_arg0.is_mutref)
                                                RESOLVE_byAAR(write: region0, read: region1,
                                                    trySoft: host_arg0.may_alias.has(i1) && arg1.softRiskSafe);

                                            if (host_arg1.is_mutref)
                                                RESOLVE_byAAR(read: region0, write: region1,
                                                    trySoft: host_arg1.may_alias.has(i0) && arg0.softRiskSafe);
                                        }
                                    }
                                }

                                // AAR ends here, inters are not relevant, etc.
                                return;
                            }

                            // Do we see any aliasing here?
                            let unwound1 = bck_unwound[i1];

                            if !(Lifetime_hasInter(unwound0, unwound1))
                                return;

                            // Soft risk check -
                            //  If neither is listed as a hard risk,
                            //   and neither invalidates the other, then we should be good.
                            if (host_arg0.may_alias.has(i1) &&
                                host_arg1.may_alias.has(i0))
                            {
                                if ((host_arg0.may_invalidate.has(i1) || arg1.softRiskSafe && !shallow1.isInvalidatedBy(write: shallow0)) &&
                                    (host_arg1.may_invalidate.has(i0) || arg0.softRiskSafe && !shallow0.isInvalidatedBy(write: shallow1)))
                                {
                                    // Soft risk ok -
                                    //  this is the new thing, further relaxing the bck.
                                    return makeNote(N_AARSoftRisk);
                                }
                            }

                            // Try to resolve by injecting a copy -
                            //  notice this is an either or, no need to pick one,
                            //   one is a writing mutref so only one could accept a temporary.
                            mut noTempCopy0: ArgRationale;
                            mut noTempCopy1: ArgRationale;

                            if ((noTempCopy0 = RESOLVE_byTempCopy(:callsite, i0, debug: "bck:vi " ~ i1)) &&
                                (noTempCopy1 = RESOLVE_byTempCopy(:callsite, i1, debug: "bck:vi " ~ i0)))
                            {
                                // Else emit an args-cannot-alias error.
                                mut err = "At call to " ~ target.str;

                                err ~= host_args.len == 2 && target.flags & F_OPERATOR
                                    ?   ", both operands alias:\n"
                                    :   ", arguments:\n\n\t    " ~ (i0 + 1) ~ ":\t" ~ host_arg0
                                        ~         " and\n\t    " ~ (i1 + 1) ~ ":\t" ~ host_arg1
                                        ~           "\n\n\t    both alias:\n";

                                Lifetime_interLocids(unwound0, unwound1).each: |locid|
                                    err ~= "\n\t    " ~ explainWhichFn(
                                        nested(locid), fmt: FullContext);

                                shadow let noTempCopy0 = noTempCopy0.ArgRationale_explain(target, arg0, host_arg0);
                                shadow let noTempCopy1 = noTempCopy1.ArgRationale_explain(target, arg1, host_arg1);

                                err ~= "\n\tCan't resolve aliasing by a temporary copy:";
                                err ~= "\n\n\t    " ~ noTempCopy0;

                                if (noTempCopy0 != noTempCopy1)
                                    err ~= "\n\n\t    " ~ noTempCopy1;

                                _here = args[i0].token;
                                fail(err);
                            }
                        }

                        // If we have a mutref, go over all refs.
                        if (expect.is_mutref) {
                            for (mut i = ref_first; i <= ref_last; i++)
                                if (host_args[i].is_ref)
                                    validate(i);
                        }

                        // Else we only care about mutrefs here.
                        else {
                            for (mut i = mutref_first; i <= mutref_last; i++)
                                if (host_args[i].is_mutref)
                                    validate(i);
                        }
                    }

                    // Track the two lists.
                    {
                        if (ref_first < 0)
                            ref_first = i0;

                        ref_last = i0;
                    }

                    if (expect.is_mutref)
                    {
                        if (mutref_first < 0)
                            mutref_first = i0;

                        mutref_last = i0;

                        // We'll batch all writes together in a bit.
                        if (host_arg0.flags & F_WRITTEN_TO)
                        {
                            let arg0 = args[i0];

                            host_arg0.is_mutref || BUG(host_arg0.name.human.qID ~ ": host_arg0.written but !host_arg0.is_mutref");
                            arg0.is_mutref      || BUG(host_arg0.name.human.qID ~ ": host_arg0.written but !arg.is_mutref");

                            bck_writes.Lifetime_add(arg0.lifetime);
                        }
                    }
                }
            }

            // Track all writes at once, not important for reads,
            //  but tracking args one by one would prevent args-at-risk.
            //
            if (bck_writes)
            {
                _here = callsite.token;

                bck_trackWrites(callsite, bck_writes);
            }
        }


        //

        fn bck_loop(ref node: SolvedNode)
        {
            ref items = node.items;

            bck_node(items[0]);

            for (mut i = 1; i < items.len; i++)
                bck_node(items[i]);

            // Postdom.
            let parent_loop_start =
                node.helpers.postdom.parent_loop_start || BUG(
                    "bck_loop: parent_loop_start not set.");

            _current_fn.events.used_in_a_loop.clear(start: parent_loop_start);
        }

        fn bck_if(ref node: SolvedNode)
        {
            ref items = node.items;

            // Cond.
            ref cond = items[0];
            bck_node(cond);

            let ae_cond = tryAbstractEvalAsBool(cond);
            if (ae_cond)
            {
                ref cons = items[ae_cond == SE_True ? 1 : 2];
                bck_node(cons);

                node = createBlock(items[0], cons);
                return;
            }

            // Cons //////////////////////////////////////////////
            let e_Restore_AfterCond     = _current_fn.events.snap;
            //////////////////////////////////////////////////////

            bck_node(items[1]);

            // Alt ///////////////////////////////////////////////
            let e_Merge_AfterCons       = _current_fn.events.snap;

            _current_fn.events.Events_restore(e_Restore_AfterCond,
                parent_loop_start: node._loop_start);
            //////////////////////////////////////////////////////

            bck_node(items[2]);

            // Done //////////////////////////////////////////////
            _current_fn.events   .Events_merge(e_Merge_AfterCons);
            //////////////////////////////////////////////////////
        }

        fn bck_and_or(ref node: SolvedNode)
        {
            ref items = node.items;
            for (mut i = 0; i < items.len; i++)
            {
                ref expr = items[i];
                bck_node(expr);

                let ae_expr = tryAbstractEvalAsBool(expr, voidOk: i == items.len - 1);
                if (ae_expr)
                {
                    let isAnd = node.kind == "and";
                    if (isAnd == (ae_expr == SE_False))
                    {
                        items.shrink(i + 1);
                        node.vfacts |= isAnd ? AlwaysFalse : AlwaysTrue;
                        break;
                    }
                    else if (i < items.len - 1)
                    {
                        let cond = steal(expr);
                        items.splice(i, 1);

                        ref cons = items[i--];
                        cons = createBlock(cond, cons);
                    }
                }
            }

            if (node.items.len < 2)
                node = node.items.only;
        }

        fn bck_not(ref node: SolvedNode)
        {
            ref expr = node.items.only;
            bck_node(expr);

            let ae_expr = tryAbstractEvalAsBool(expr);
            if (ae_expr)
                node.vfacts |= ae_expr == SE_True
                    ? AlwaysFalse
                    : AlwaysTrue;
        }

        fn bck_block(ref node: SolvedNode)
        {
            mut defers: SolvedNode[];

            // Regular items forward.
            ref items = node.items;
            for (mut i = 0; i < items.len; i++)
            {
                ref stmt = items[i];
                if (stmt.kind == "defer")
                {
                    defers ~= stmt.items.only;
                }
                else
                    bck_node(stmt);

                // #tryAbstractEval #tryAbstractEvalAsBool:
                //  Abstract eval needs to do these too unfortunately,
                //   so if it's gonna happen during bck
                //    i guess this is where it's gonna happen.
                //
                if (stmt.type.is_never)
                {
                    if (SELF_TEST && stmt.kind == "defer")
                        BUG("bck, block: defer.is_never");

                    items.shrink(i + 1);
                    if !(node.helpers.mask & HM_LabelUsed)
                        node.type = t_never;

                    break;
                }
            }

            //////////////////////////////////////////////////////
            _current_fn.events.Events_merge(node.helpers.postevt);
            //////////////////////////////////////////////////////

            // Defers in reverse.
            for (mut i = defers.len; i --> 0; )
                bck_node(defers[i]);
        }


        // Borrow check router.

        fn bck_node(ref node: SolvedNode)
        {
            let k = node.kind;

            if (k == "call")
            {
                // This is the only place where reads & writes actually happen.
                bck_call(node);
            }
            else if (k == "loop")
            {
                // The extra stuff we need to check backward jumps.
                bck_loop(node);
            }
            else if (k == "letdef")
            {
                // INDIRECTION !!!!
                swap(GET_mut(node.target).solved, node);
                bck_node(node);
                swap(GET_mut(node.target).solved, node);
            }
            else if (k == "let")
            {
                // Variable initialization.
                bck_let(node);
            }
            else if (k == "if")
            {
                // Isolate cons from alt and combine effects on exit.
                bck_if(node);
            }
            else if (k == "and" || k == "or")
            {
                // Previously below with blocks, now also abstract eval.
                bck_and_or(node);
            }
            else if (k == "not")
            {
                // Previously below with blocks, now also abstract eval.
                bck_not(node);
            }
            else if (k == "block")
            {
                // TODO If broken-from, hide effects and append to jumped-to.
                bck_block(node);
            }
            else if (k == "root"
                  || k == "jump"
                  || k == "try"

                  || k == "copy" || k == "move" // TODO shouldn't occur before bck
                  || k == "arrlit")             // TODO get rid of arrlits
            {
                // The default - descend recursively.
                ref items = node.items;
                for (mut i = 0; i < items.len; i++)
                    bck_node(items[i]);

                //
                if (k == "jump")
                {
                    if (node.helpers.postevt)
                        Events_merge(node.helpers.postevt, _current_fn.events);
                    else
                        node.helpers.postevt = _current_fn.events.snap;

                    //
                    _current_fn.events.Events_restore(
                        [], :node.helpers.postdom.parent_loop_start || BUG(
                            "bck_node(jump): helpers.postdom.parent_loop_start not set."));
                }
            }
            else if (k == "pragma")
            {
                // Without this we fail to notice all the writes in pragma emits etc,
                //  caught this thanks to the new isDiscardable stuff.
                //
                for (mut i = 0; i < node.items.len; i++)
                {
                    ref item = node.items[i];

                    // We have to assume some order of evaluation,
                    //  here we assume left-to-right,
                    //   this is totally best effort,
                    //    not in any way sound.
                    //
                    bck_node(item);

                    if (item.is_mutref)
                    {
                        _here = item.token;

                        bck_trackWrites(node, item.lifetime);
                    }
                }
            }
            else if (node.items)
            {
                fail("TODO: bck_node(non-empty " ~ k ~ ").");
            }
        }


        // BCK PASS 1: Local analysis & resolve-by-copy.

        // Nothing special, just run.


        // BCK PASS 2: ARGUMENTS AT RISK
        //
        // Previously we had a separate AAR thing going,
        //  now we're trying to piggy back on the regular bck stuff as much as possible,
        //   and only handle things differently when we would otherwise emit an error.
        //
        if (AAR)
        {
            mut consts: Lifetime;
            mut refs:   Lifetime;

            // We only need to seed invalidations from mutref arguments.
            {
                _current_fn_eachArg_FWD: |target|
                {
                    target.globid == _current_fn.target.globid || BUG();

                    let type    = target.solved.type;
                    let region  = Lifetime_AAR(:target.locid);

                    if (!Lifetime_getRefLocid_unlessStatic(region))
                        continue;

                    // Notice we don't consider refs we don't write to as mutrefs for AAR.
                    //  This is meant as an opti, but also tests we've tagged everything correctly.
                    if (type.is_mutref && _current_fn.ever_written.has(target.locid))
                        refs.Lifetime_add(region);
                    else if (type.is_ref && !target.willPassByValue())
                        consts.Lifetime_add(region);
                }
            }

            //
            mut refs_len = 0;
            refs.Lifetime_each: |locid|
            {
                locid || BUG("AAR: refs contains non-locals");
                refs_len++;
            };

            // No point in doing AAR if there are no mutref arguments,
            //  or if there's just one mutref argument and no constref args.
            if (!refs_len || refs_len == 1 && !consts)
            {
                // TODO we can do better -
                //  we can skip AAR if we can observe that none of the
                //   mutref/mutref and mutref/constref pairs are aliasable type-wise.
                //
                // Ideally, even when we can't skip AAR,
                //  we wouldn't add invalidation edges between non-aliasable arguments.
                //
                return;
            }

            // Reset these, here we use them for the speculative aliasing.
            _current_fn.flow.clear();
            _current_fn.events.clear();

            // Index arguments.
            _current_fn_eachArg_FWD: |target, position|
            {
                target.globid == _current_fn.target.globid || BUG(
                    "Arg target not local to current-fn: " ~ target);

                Reference_trackArgument(target.locid, :position);
            }

            // Setup the AAR invalidation matrix -
            //  we assume that each ref argument invalidates EVERY other argument.
            //
            // As bck runs, instead of raising errors when this causes issues,
            //  we take note that the args can't alias for things to work,
            //   and this becomes our hard_risks/soft_risks solution.
            //
            shadow ref flow = _current_fn.flow;

            refs.Lifetime_each: |locid!target, others!other_refs|
            {
                target || BUG();

                // First, ref -> const relationships, cheaper setup.
                if (consts)
                    (flow.rg_invalidates.grow_if_oob(target) && BUG("AAR: ref arg already has invalidates."))
                        = consts;

                // Finally set up the ref <-> ref relationships,
                //  which are symmetric.
                if (other_refs)
                    flow.rg_invalidates.grow_if_oob(target)
                        .Lifetime_add(other_refs);

                // OOE/AAR:
                // Search tests for:
                //
                //      mul({ ref x = z || a; x++ }, hello)
                //
                // Also see comment above on:
                //
                //      a * { ref x = z || a; x++ }
                //
                // Basically for all_written_BUT_NOT_invalidated to consider other arguments,
                //  we list them as if they were parents to each ref argument.
                if (consts || other_refs)
                    (flow.rg_parents.grow_if_oob(target) && BUG("AAR: ref arg already has parents."))
                        = flow.rg_invalidates.unless_oob(target) || BUG("AAR: (refs.len > 1 || consts), but no invalidates.");
            }

            // trackReferences uses flow.invalidates to locate siblings,
            //  so we gotta add them here for constants too.
            if (refs)
            {
                consts.Lifetime_each: |locid!target|
                {
                    target || BUG();

                    // Same as above but flipped.
                    (flow.rg_invalidates.grow_if_oob(target) && BUG(
                        "AAR: const arg already has invalidates."))
                            = refs;

                    // No point in doing this - we're never ascending .parents for reads.
                    //  The thing above appears to be sufficient:
                    //   - listing consts as .parents of refs takes care of refs pointing into consts.
                    //   - listing consts as .invalidates for refs takes care of consts point into refs.
                    //
                    (flow.rg_parents.grow_if_oob(target) && BUG(
                        "AAR: const arg already has parents."))
                            = refs;
                }
            }

            // Go.
            refs || BUG("Wasting time on AAR without ref args.");
            _current_fn.events = Events();
        }

        bck_node(root);
    }



    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    lax fn test_node(lax node: SolvedNode, lax pass: SolverPass)
    {
        if (!SELF_TEST)
            return;

        for (mut i = 0; i < node.items.len; i++)
            test_node(node.items[i], :pass);

        _here = node.token;

        if (node.is_never && node.usage)
            BUG("node.is_never but some usage bits set");

        //
        let k = node.kind;

        !node.is_ref == !node.lifetime || BUG(
            node ~ ": !!ref != !!lt: " ~ humanizeType(node.type));

        //
        if (k == "call")
        {
            let o           = GET(node.target);
            shadow let k    = o.kind;

            let host_args   = node.target.args;
            let args        = node.items;

            fn err(reason: string)
                BUG(node ~ " " ~ o ~ ": " ~ reason);

            // TODO FAILCASE enable this, allowing non-inline callsites to inline fns
            //  helps us navigate some nasty inline-recursions,
            //   but there's no guarantee that the recursion will converge,
            //    if the inline fn finishes solving with no-change,
            //     the callsite could stay as-is.
            //
            // This problem will go away if we move inlining to a later global pass,
            //  where everything is solved and can get recursively relaxed & inlined.
            //
            // k == "field" || k == "enumv" || k == "type" || k == "__native" || k == "var" || k == "fn" || err(
            //     "Bad target.kind: " ~ explainWhichFn(o));
            //
            host_args.len == args.len || k == "type" && !args.len || err(
                "host_args.len (" ~ host_args.len ~ ") != args.len (" ~ args.len ~ "):"
                    ~ "\n\t\t" ~ mangleArgTypes(args)
                    ~ "\n\t\t" ~ explainWhichFn(node.target));


            if (o.kind == "type" && o.type.tryLookupUserType.kind == "struct")
            {
                // TODO FIX skipping constructors
                //  because of partial usage,
                //   gotta make the stuff below work.
            }
            else for (mut i = 0; i < args.len; i++)
            {
                let host_arg = host_args[i];
                let arg      = args[i];

                if (host_arg.isIrrelevant)
                    continue;

                isAssignableAsArgument(host: host_arg.type, arg.type) || err(
                    "Arg #" ~ i ~ ", " ~ host_arg.name.human.qID ~ " not assignable to host_arg: "
                        ~ explainTypeDiff(host_arg.type, arg.type, "<-"));
            }

            if (o.kind != "field")
                isAssignable(host: node.type, o.type) || err(
                    "Return value of " ~ node ~ " not assignable to node.type: "
                        ~ explainTypeDiff(node.type, o.type, "<-"));
        }
        else if (k == "let")
        {
            node.items.len == 2 || BUG("let.items.len: " ~ node.items.len);
            node.items[0] && BUG("let.items[0] not empty: " ~ node.items[0].kind);
        }
        else if (k == "block" || k == "and" || k == "or" || k == "if")
        {
            fn checkLt(actual: Type,
                       actualCopy: string,
                       expect: SolvedNode = node,
                       expectCopy: string = node.kind ~ ".type")
            {
                if (!expect.type.is_ref)
                    return;

                // Previously we were testing if
                //  unexpected := Lifetime_diff(actual, expected)
                //   was non-empty.
                //
                // For unexpected to be non-empty,
                //  there must be something in actual that's not in expected.
                //
                // Thus, the union of actual and expected is > expected.
                //
                let union = Lifetime_union(expect.lifetime, actual.lifetime);

                if (union != expect.lifetime)
                {
                    let debug = Lifetime_union(expect.lifetime, actual.lifetime);

                    BUG(node ~ ": " ~ actualCopy ~ " mentions a lifetime not listed in "
                                    ~ expectCopy ~ ":"
                              ~ "\n\n\t\t" ~ actualCopy ~ ":\t" ~ actual.humanizeType(lt: true)
                              ~ "\n\n\t\t" ~ expectCopy ~ ":\t" ~ expect.humanizeType(lt: true)
                              ~ "\n\n\t\tUNION:\t\t" ~ debug);
                }
            }

            if (k == "block")
            {
                // node.items || BUG(debug ~ " is empty");

                checkLt(node.items.if_last, "block.tail");

                if (node.helpers.ret_actual /*TODO FIX: */&& !(node.helpers.mask & HM_Function))
                    checkLt(node.helpers.ret_actual, "helpers.ret_actual");
            }
            else if (k == "and" || k == "or")
            {
                node.items.len >= 2 || BUG(node ~ ".len: " ~ node.items.len);

                let start = k == "and" && !node.is_mutref && node.items.len - 1;
                for (mut i = start; i < node.items.len; i++)
                    checkLt(node.items[i], k ~ ".items[" ~ i ~ "]");
            }
            else if (k == "if")
            {
                node.items.len == 3 || BUG(node ~ ".len: " ~ node.items.len);

                if (node.type.is_never)
                {
                    node.items[1].is_never || BUG(node ~ " never.cons not never: " ~ node.items[1]);
                    node.items[2].is_never || BUG(node  ~ " never.alt not never: " ~ node.items[2]);
                }

                checkLt(node.items[1], "if.then");
                checkLt(node.items[2], "if.else");
            }

            let items = node.items;
            for (mut i = 0; i < items.len; i++)
                items[i].kind || BUG(node ~ ": No .kind on item[" ~ i ~ "].");
        }
        else if (k == "jump")
        {
            if (pass >= RelaxCopyResize)
            {
                // During solve we collect jump expression types via superType,
                //  so none of the jumps actually has access to the final block ret_actual.
                //   So, we either have to ignore this before first propagate type,
                //    or maybe even address this during mcom, not sure.
                //
                let h       = node.helpers;
                let expr    = node.items.only;

                h.ret_actual.isAssignable(expr)
                    || BUG("BROKEN JUMP TYPE"
                        ~ "\n\t\tret_actual: " ~ (h.ret_actual ? h.ret_actual.humanizeType : "N/A".qBAD)
                        ~ "\n\t\tret_expect: " ~ (h.ret_expect ? h.ret_expect.humanizeType : "N/A".qBAD)
                        ~ "\n\t\texpr: " ~ expr);
            }
        }
        else if (k == "try")
        {
            node.items.len == 3 || BUG("try.items.len != 3");
            let err = node.items[TRY_ERR];
            err.kind == "letdef" || err.kind == "empty" || BUG(
                "TRY_ERR not a letdef/empty: " ~ node.items[TRY_ERR]);
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn mcom_BlockReturns_CopyOrMoveDecision(h: Helpers)
    {
        if (!h.ret_actual.is_ref)
            return;

        fn Lifetime_vs(lifetime: Lifetime, locals_start!?: i32)
        {
            locals_start || BUG("Lifetime_vs: No locals_start");

            fn isRefArg(o: Overload) =
                o.flags & F_ARG && o.kind == "var"
                                && o.solved.type.is_ref;

            mut neg = false;
            mut pos = false;
            lifetime.Lifetime_each: |isTemp, locid|
                if (isTemp)
                    pos = true;
                else if (locid < locals_start)
                    neg = true;
                else if (locid.nested.isRefArg)
                    neg = true;
                else
                    pos = true;

            return neg == pos ? 0 : neg ? -1 : +1;
        }

        // If the jump is a return-current-fn:
        //  We cannot promote var lifetimes past this fn
        //   (we actually can but its more complicated and not necessary)
        //    BUT we dont have to worry about retval users,
        //     so just change the retval to reflect the current var/ref situation.
        //
        if (h.mask & HM_Function)
        {
            let unwind = Lifetime_unwind(h.ret_actual.lifetime);
            if (Lifetime_vs(unwind, :h.locals_start) < 0)
                h.ret_actual.lifetime = unwind;
            else
                reportReturnType(:h, clear_refs(h.ret_actual));
        }
        // Otherwise, we can extend local LTs,
        //  so that's what we're gonna do for now.
        //   We need to figure out how to determine if LT-extend is better/worse than cpy/mov -
        //    depends on what you do with the result, if you later cpy, the mov would have been better,
        //     if you just use as ref, LT-extend is better.
        //
        else
        {
            let locals_start = h.locals_start;
            let unwound = Lifetime_unwind(
                :h.ret_actual.lifetime, :locals_start);

            unwound.Lifetime_each: |locid|
            {
                if (locid >= locals_start)
                {
                    ref o = GET_mut(nested(locid));
                    if !(o.flags & F_ARG)
                        o.status |= SS_HOIST;
                }
            }
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn runAllPasses(ref node: SolvedNode)
    {
        if (_current_fn)
        {
            if (currentFn_mustBecomeInline)
                return;

            if (_current_fn.target.status & SS_Debug_AllPassesComplete)
                BUG("runAllPasses: All passes already complete.");
        }

        ////////////////////////////////////
        if (SELF_TEST)
        {
            PROFILE(.TestPass);
            test_node(node, :node.helpers.pass);
        }
        ////////////////////////////////////

        {
            PROFILE(.RelaxMut);
            node.helpers.pass = "RelaxMut";

            _current_fn.var_usage  && BUG("_current_fn.var_usage not empty before propagateType.");
            _current_fn.postdom    && BUG("_current_fn.postdom not empty before propagateType.");
            Postdom_resetAtFnEnd(_current_fn);
            propagateType(node, node.type, relax_mask: RELAX_before_bck);
        }

        ////////////////////////////////////
        if (SELF_TEST)
        {
            PROFILE(.TestPass);
            test_node(node, :node.helpers.pass);
        }
        ////////////////////////////////////

        {
            PROFILE(.BorrowCheck);
            node.helpers.pass = "BorrowCheck";

            PASS_borrowCheck(node, BCK_bck);
        }

        ////////////////////////////////////
        // Noticed we were missing a test pass here,
        // if (SELF_TEST)
        // {
        //     PROFILE(.TestPass);
        //     test_node(node, :node.helpers.pass);
        // }
        ////////////////////////////////////

        {
            PROFILE(.ArgumentsAtRisk);
            node.helpers.pass = "ArgumentsAtRisk";

            _current_fn.TODO_FIX_children = _current_fn.flow.rg_children;

            PASS_borrowCheck(node, BCK_aar);
        }

        ////////////////////////////////////
        if (SELF_TEST)
        {
            PROFILE(.TestPass);
            test_node(node, :node.helpers.pass);
        }
        ////////////////////////////////////

        {
            PROFILE(.RelaxCopyResize);
            node.helpers.pass = "RelaxCopyResize";

            _current_fn.fx_mask = [];
            _current_fn.relaxed = [];

            _current_fn.parent_loop_start == 1 || BUG("_current_fn.loop_start leak.");
            Postdom_resetAtFnEnd(_current_fn);

            propagateType(node, node.type, relax_mask: RELAX_all);
        }

        ////////////////////////////////////
        if (SELF_TEST)
        {
            PROFILE(.TestPass);
            test_node(node, :node.helpers.pass);
        }
        ////////////////////////////////////

        if (_current_fn)
        {
            if (currentFn_mustBecomeInline)
                BUG("runAllPasses: currentFn_mustBecomeInline after all.");

            _current_fn.target.GET_mut.status |= SS_Debug_AllPassesComplete;
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn compilerBreak()
    {
        mut debug = "\nCompiler break:";

        // Print all locals.
        if (_current_fn.target)
        {
            let t  = _current_fn.target;
            debug ~= "\n    Current fn: " ~ t ~ " at (" ~ t.modid ~ ", " ~ t.globid ~ "):";

            let locals = t.locals;
            for (mut i = 0; i < locals.len; i++)
            {
                let item = locals[i];
                debug ~= "\n        " ~ item;
            }
        }

        if (debug)
            println(debug);

        //
        debug::break();
    }


    //

    fn Scope_observeDefects(items: ScopeItem[])
    {
        mut hasLets         = false;
        mut hasPubTemplates = false;

        mut privates: Target[];

        for (mut i = 0; i < items.len; i++)
        {
            let t = items[i].target;
            if (t.modid != module.modid)
                continue;

            let o = GET(t);
            if (o.kind == "var")
            {
                hasLets = true;
                if !(o.flags & F_PUB)
                    privates ~= t;
            }
            else if (o.kind == "fn")
            {
                if !(o.flags & F_PUB)
                    privates ~= t;
            }
            else if (o.kind == "template")
            {
                if (o.flags & F_PUB)
                    hasPubTemplates = true;
            }
        }

        // Note if we need to orchestrate c++ static init order.
        //  OPTIMIZABLE: not every let needs static init,
        //   flag constexpr stuff here instead of in codegen.
        if (hasLets)
            makeNote(N_SD_HasStaticInit);

        // Ensuring public templates have access
        //  to private stuff across translation units.
        if (privates && hasPubTemplates)
        {
            makeNote(N_SD_ExternPrivates);

            // F_PUB all privates so they get externed by codegen,
            //  so public templates can access them from other translation units.
            for (mut i = 0; i < privates.len; i++)
            {
                ref o = GET_mut(privates[i]);
                o.flags |= F_EXTERN;
            }
        }
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    fn nestingFnort_ensureArgSequencing()
    {
        mut _may_alias: bitset::BitSet[];
        mut _argPos_1b: i32[];

        _nestingFnort.args.each: |host_arg, i|
        {
            if (!host_arg.type.is_ref)
                continue;

            _argPos_1b.grow_if_oob(host_arg.target.locid)
                = i + 1;

            let may_alias = host_arg.flags & F_WRITTEN_TO && host_arg.may_alias;
            if (may_alias)
            {
                if (SELF_TEST)
                {
                    if (!host_arg.is_mutref)
                        BUG("ensureArgSequencing: F_WRITTEN_TO but !is_mutref");
                    if (!may_alias.has(i))
                        BUG("ensureArgSequencing: may_alias does not list self [1]");
                }

                _may_alias.grow_if_oob(i) = may_alias;
            }
        }


        //

        struct Regions {
            locals:     bitset::BitSet;
            arguments:  bitset::BitSet;
        };

        fn has_inter(a: Regions, b: Regions)
            a.locals.has_inter(b.locals) ||
            a.arguments.has_inter(b.arguments);

        infix fn |=(ref a: Regions, b: Regions)
            for (fieldname i: Regions)
                a.i |= b.i;

        fn clear(ref regions: Regions)
            for (fieldname i: Regions)
                regions.i.clear();


        //

        struct Unsequenced {
            writes:     Regions;
            moves:      Regions;
            reads:      Regions;
        };

        fn clear(ref events: Unsequenced)
            for (fieldname i: Unsequenced)
                events.i.clear();

        infix fn |=(ref events: Unsequenced, other: Unsequenced)
            for (fieldname i: Unsequenced)
                events.i |= other.i;

        fn flag(
            ref regions: Regions, lifetime: Lifetime,
            /*TODO const*/  dontUse_may_alias!?: bool /*,
              TODO const    dontCheckArguments!?: bool */)
        {
            lifetime.Lifetime_each: |locid|
            {
                if (locid && regions.locals.add_once(locid - 1))
                {
                    ///////////////////////////////////////
                    // TODO PERF not necessary for moves //
                    ///////////////////////////////////////

                    // AAR sequencing.
                    let argPos_1b = _argPos_1b.unless_oob(locid);
                    if (argPos_1b)
                    {
                        let i = argPos_1b - 1;
                        let may_alias = !dontUse_may_alias
                                     && _may_alias.unless_oob(i);

                        if (may_alias)
                        {
                            if (SELF_TEST && !may_alias.has(i))
                                BUG("ensureArgSequencing: may_alias does not list self [2]");

                            regions.arguments |= may_alias;
                        }
                        else
                        {
                            regions.arguments.add(i);
                        }
                    }

                    // Continue.
                    regions.flag(
                        nested(locid).Lifetime_climbType.lifetime,
                        :dontUse_may_alias);
                }
            }
        }

        //
        mut _unseqDepth = 0;
        mut _inner: Unsequenced;

        //
        fn visit(ref node: SolvedNode)
        {
            if (node.kind == "call")
            {
                let o = GET(node.target);

                if (!node.items)
                {
                    // Track reads.
                    if (o.kind == "var")
                        if (_unseqDepth)
                            _inner.reads.flag(
                                o.type.lifetime,

                                // READS: No point in flagging
                                //  all potentially-aliased arguments,
                                //   if someone else writes to another,
                                //    they'll flag this one.
                                //
                                dontUse_may_alias: true);

                    // This handles zero-init constructors.
                    return;
                }

                // Sequenced calls - assignments & such.
                let RTL = o.isRTL;

                ////////////////////////////////////////////////////////////////
                let unsequencedOutside  = !!_unseqDepth;
                let unsequencedHere     = !RTL && node.items.len > 1;

                if (unsequencedHere)
                    _unseqDepth++;
                ////////////////////////////////////////////////////////////////

                mut outer = _inner.steal();
                mut parallel: Unsequenced;
                mut MUSTSEQ_mask = 0;

                let host_args   = node.target.args;
                ref args        = node.items;

                host_args.len == args.len ||
                    BUG(node.token, "ensureArgSequencing: host_args.len != args.len (" ~ host_args.len ~ " != " ~ args.len ~ "), nestingFnort= " ~ _nestingFnort.globid ~ " " ~ _nestingFnort);

                argsReverse(:RTL, :host_args): |i, host_arg, revSeqIdx|
                {
                    // This vs parallel arguments.
                    if (unsequencedHere)
                    {
                        if (revSeqIdx == 1)
                        {
                            parallel = steal(_inner);
                        }
                        else if (revSeqIdx > 1)
                        {
                            parallel |= _inner;
                            _inner.clear();
                        }
                    }

                    // Descend - collects inner reads, writes & moves.
                    ref arg = args[i];

                    // OPTI & c++ cg cleanup, special-case callsite moves,
                    //  move may-happen inside fn, no need to sequence here.
                    //   Adding this to be test-identical with what we had before.
                    //
                    shadow ref arg =
                        !OPTI_moves_inside_fns
                            || arg.kind != "move" ? arg :
                    {
                        // Move happens INSIDE fn,
                        //  so sequenced AFTER arg list.
                        //
                        ref expr = arg.items.only;
                        if (unsequencedOutside)
                            outer.moves.flag(expr.type.lifetime);

                        expr
                    };

                    //
                    visit(arg);

                    // Track writes.
                    if (unsequencedOutside)
                    {   //         ^^^^^^^
                        // We only need to bother with this if this call
                        //  is happening within the argument list of
                        //   another call with unsequenced arguments.
                        //
                        if (host_arg.flags & F_WRITTEN_TO)
                        {
                            outer.writes.flag(arg.type.lifetime);
                            // ^^^^^^^^^
                            // Writes happen inside the fn we're calling,
                            //  so they are sequenced AFTER all args have evaluated,
                            //   no need to consider them here.
                        }
                    }

                    // Ensure sequencing.
                    if (unsequencedHere)
                    {
                        let note =  _inner.moves.has_inter(parallel.reads) ||
                                    parallel.moves.has_inter(_inner.reads)
                                        ? N_MoveMustSeq
                                 :  _inner.writes.locals.has_inter(parallel.reads.locals) ||
                                    parallel.writes.locals.has_inter(_inner.reads.locals)
                                        ? N_BckMustSeq
                                 :  _inner.writes.arguments.has_inter(parallel.reads.arguments) ||
                                    parallel.writes.arguments.has_inter(_inner.reads.arguments)
                                        ? N_AARMustSeq
                                 :  { continue; };

                        makeNote(note);
                        MUSTSEQ_mask |= 1 << (i & 31);
                    }
                }

                ////////////////////////////////////////////////////////////////
                if (unsequencedHere)
                    _unseqDepth--;
                ////////////////////////////////////////////////////////////////

                node.helpers.index |= MUSTSEQ_mask;

                //
                if (unsequencedOutside)
                {
                    outer |= _inner;
                    outer |= parallel;
                    swap(_inner, outer);
                }
                else
                {
                    SELF_TEST && outer && BUG("!unsequencedOutside but outer events non-empty.");
                    _inner.clear();
                }

                // Done - children already visited.
                return;
            }

            if (node.kind == "letdef")
            {
                mut root = GET_mut(node.target).solved.steal();
                visit(root);
                swap(root, GET_mut(node.target).solved);

                // Done - no children.
                return;
            }

            if (node.kind == "move")
            {
                // Track moves.
                if (_unseqDepth)
                    if (node.kind == "move")
                        _inner.moves.flag(
                            node.items.only.type.lifetime);
            }

            for (mut i = 0; i < node.items.len; i++)
                visit(node.items[i]);
        }

        mut root = GET_mut(_nestingFnort).solved.items.last.steal();
        visit(root);
        swap(root, GET_mut(_nestingFnort).solved.items.last);
    }

    fn PASS_runAllVerifiers()
    {
        PROFILE(.EnsureArgSeq);

        _nestingFnort && BUG("PASS_runAllVerifiers: non-empty _nestingFnort");

        for (mut i = 0; i < _scope.overloads.len; i++)
        {
            ref o = _scope.overloads[i];
            if (o.kind == "fn")
            {
                _nestingFnort = Target(
                    :module.modid, globid: i + 1, locid: 0);

                // TODO only bother with this if backend is unsequenced,
                //  like c / c++, real moronic total waste of time.
                nestingFnort_ensureArgSequencing();
            }
        }

        _nestingFnort = [];
    }


    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////
    //////////////////////////////////////////////////////////////////////////

    // Import prelude / inject builtins.
    if (module.modid)
    {
        // Ensure can't reimport self.
        _scope.imports ~= module.modid;

        // Load prelude.
        _Scope_import__forceCopy(0);
    }
    else
    {
        // PRELUDE:
        //  Pre-populate with primitive types and such.
        //
        createRawTypedef("i8", t_i8, F_PUB);
        createRawTypedef("i16", t_i16, F_PUB);
        createRawTypedef("i32", t_i32, F_PUB);
        createRawTypedef("i64", t_i64, F_PUB);
        createRawTypedef("i128", t_i128, F_PUB);

        createRawTypedef("u8", t_u8, F_PUB);
        createRawTypedef("u16", t_u16, F_PUB);
        createRawTypedef("u32", t_u32, F_PUB);
        createRawTypedef("u64", t_u64, F_PUB);
        createRawTypedef("u128", t_u128, F_PUB);

        createRawTypedef("f32", t_f32, F_PUB);
        createRawTypedef("f64", t_f64, F_PUB);

        createRawTypedef("bool", t_bool, F_PUB);
        createRawTypedef("byte", t_byte, F_PUB);

        createRawTypedef("void", t_void, F_PUB);
        createRawTypedef("never", t_never, F_PUB);
    }

    // Solve.
    {
        // println("\n----------------------------\n");

        let root = solveNode(module.in.parse.root);

        _current_fn && BUG("non-empty _current_fn.");

        ///////////////////////
        PASS_runAllVerifiers();
        ///////////////////////

        _helpers_data[0] && BUG("non-empty _helpers_data[0].");

        // println("TOTAL OVERLOADS " ~ module.fname ~ ": " ~ _scope.overloads.len);

        // Global deoptis so it can all work.
        Scope_observeDefects(_scope.items);

        // TODO suppressing & opting out of warnings.
        for (mut i = 0; i < _warnings.len; i++)
        {
            let w = _warnings[i];
            if (w.token)
            {
                _here = w.token;
                fail(w.message);
            }
        }

        //
        if (RESOLVE_report) for (mut i = 1; i < _ephemeral.len; i++)
        {
            let target  = localfn(index: i);
            let REV     = target.revision.i32;
            if (REV > 5)
            {
                fn Indent()
                {
                    mut str = "";
                    for (shadow mut i = 0; i < REV; i++)
                        str ~= " ";

                    return str;
                }

                println("RESOLVE "
                    ~ Indent
                    ~ target.name ~ " :: "
                    ~ target.revision);
            }
        }

        // Exports.
        return SolverOutput(
            root:  root,
            scope: Scope_exports(_scope, :module.modid, _field_items, _pub_imports),
            notes: _notes);
    }
}
