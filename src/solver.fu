

// Overload flags.

using flags SolverStatus: u16
{
    SS_LAZY
    SS_DID_START
    SS_DIRTY
    SS_FINALIZED

    SS_UPDATED
    // ...
    // ...
    SS_FN_OOE_RTL                   // TODO get rid of this, silly

    SS_NAME_UNUSED                  // TODO GET RID OF THIS, SS_MATCHED is enough
    SS_UNUSED                       // also this feels redundant, if its unused, why is it still around
    SS_MATCHED
    SS_MOVED_FROM

    SS_EXTERNAL_LINKAGE
    SS_OBSERVED_BY_CONV_CACHE
    SS_TODO_FIX_was_rx_resize
    SS_Debug_AllPassesComplete
}


// Solver helpers.

using flags HelpersMask: u16
{
    HM_CanBreak
    HM_CanReturn
    HM_Anon
    HM_Function

    HM_Lambda
    HM_UserType
    HM_LabelUsed
    // ...

    HM_LoopPreheader
    HM_LoopBody
    // ...
    // ...
}


//

using flags DeclAsserts: u16
{
    A_NOCOPY
    A_NOVEC
    A_TRIVIAL
    A_NODISCARD

    A_PURE
    A_PURE_CTX
    A_PURE_FX
    // ...

    A_NOFLOW
    A_NOTHROW
    A_NOCRASH
    // ...

    A_NOIO
    // ...
    A_FAST
    // ...

    A_NOINLINE
    // ...
    // ...
    // ...
};


//

using flags ParseSyntax
{
    PS_PARENS

    PS_DISCARD_IF_BLOCK_TAIL
    PS_ALWAYS_DISCARD
    PS_NOT_AN_EXPRESSION

    PS_USING_EXPRESSION
};


//

using flags Flags: u32
{
    F_CALL_HAS_DOT          // TODO move into ParseSyntax
    F_CALL_HAS_ARGPARENS    // TODO move into ParseSyntax
    F_CALL_HAS_NAMED_ARGS   // TODO FIX do we need this really? the ast is self-explanatory
    F_OPERATOR

    F_TYPENAME
    // ...
    F_COMPOUND_ID
    F_ARGID_IS_OPTIONAL     // TODO move into ParseSyntax


    F_LAX
    F_SHADOW
    F_MUSTNAME
    // ...

    F_MUT                   // mutability & val-vs-ref semantics
    F_CONST                 //  now orthogonal.
    F_VAL
    F_REF


    F_IMPLICIT
    F_USING
    F_CONVERSION
    F_TEST_painted          // test_node check_painted

    F_PUB           // TODO group these three up
    F_EXTERN        //  in enum Linkage
    F_HOTSWAP       //   or enum Visibility or smth
    F_PREDICATE


    F_LT_RETURNED   // host-arg ref-returned from
    F_REST_ARG
    // ...
    F_INJECTED      // TODO move into SolverStatus

    F_TEMPLATE
    F_INLINE
    F_LAMBDA
    F_COW_INSIDE
};

let F_TODO_FIX_TRAILING_RETURN = F_LAMBDA;


//

using flags ExitPaths {
    XP_NonEmptyReturn
    XP_EmptyReturn
    XP_NoReturn
};


// Commons.

let LET_TYPE        = 0;
let LET_INIT        = 1;

let FN_RET_BACK     = -2;
let FN_BODY_BACK    = -1;
let FN_ARGS_BACK    = FN_RET_BACK;

let TYPECTOR_BACK   = -1;

let LOOP_INIT       = 0;
let LOOP_PRE_COND   = 1;
let LOOP_PRE        = 2;
let LOOP_BODY       = 3;
let LOOP_POST       = 4;
let LOOP_POST_COND  = 5;

let STRUCT_BASE     = 0;
let STRUCT_MEMBERS  = 1;

let TRY_TRY         = 0;
let TRY_ERR         = 1;
let TRY_CATCH       = 2;


//

let F_TESTCASE      = F_PREDICATE;


// Solver notes.

using flags SolverNotes: i32
{
    N_FnResolve
    N_FnReopen

    N_TypeResolve
    N_TypeReopen

    N_DeadCode
    N_DeadCall
    N_DeadLet
    N_DeadArrlit
    N_DeadLoopInit
    N_DeadConv

    N_NonTrivAutoCopy

    N_RelaxRespec

    N_UnusedImplicit
    N_UnusedCall
    N_UnusedDefer
    N_UnusedTry
    N_UnusedAndOr
    N_UnusedIfElse
    N_UnusedArrlit
    N_UnusedLet

    N_BckMustSeq

    N_AARMustSeq
    N_AARSoftRisk

    N_MoveMustSeq
    N_McomUnwrapsLetdef

    N_SD_HasStaticInit
    N_SD_ExternPrivates

    N_COWRestrict
}


//

using flags CGDefects
{
    GNUStmtExpr;
    Goto;
    PointlessMustSeq;
    LocalConstBool;
    ConstCast;
    PointlessLocal;
    IrrelevantLiteral;
    DuplicateFunctions;
};


//

enum Kind
{
    // LexerOnly: /////////////////////////
    sof                                 ///
    err                                 ///
    eof                                 ///
                                        ///
    id                                  ///
    op                                  ///
    // /LexerOnly                       ///
                                        ///
    // Literal:                         ///
    int                                 ///
    real                                ///
    char                                ///
    str                                 ///
    bool                                /// isLexeme end
                        ///////////////////
    definit             ///
    empty               ///
    // /Literal         ///
                        ///
    // Declaration:     ///
    struct              ///
    union               ///
                        ///
    primitive           ///
    flags               ///
    enum                ///
                        ///
    fn                  /// isImmediatelyDiscardable end
    // /Declaration ///////

    copy
    move
    arrlit

    not
    call
    call_indir
    argid

    root
    block

    // ControlFlow:
    if
    or
    and
    loop
    jump
    __far_jump
    defer
    try
    // /ControlFlow

    let
    letdef

    typecast
    typeassert
    typeparam

    unwrap
    pragma

    // ParseOnly_JumpKind:
    break
    return
    continue
    // /ParseOnly_JumpKind

    // ParseOnly_Placeholder:
    import
    addroffn
    forfieldsof
    // /ParseOnly_Placeholder

    members

    fnbranch
    pattern

    typeunion
    typetag


    // Solver: extra node kinds.

    __relaxed
    __convert
    __preceding_ref_arg

    __serialized_type               // Stepping stone towards fully-presolved type patterns,
    __serialized_addrof_type_fn     //  we'll just ad-hoc replace stuff we can resolve in type pattern ASTs for now

    __litfix_bound


    // Scope: overload types.

    __no_kind_yet
    __tombstone
    type
    var
    field
    enumv
    template
    __native
    inline
}

fn isImmediatelyDiscardable(k: Kind)
{
    return k <= "fn";
}

fn isFnOrTypeDeclaration(k: Kind)
{
    return k >= "struct" && k <= "fn";
}


// Experiments / extensions / dialects?

let X_OPTIONAL_SEMIS = true;


type Quals = u32; // cant use 64 now because of parseType
let Quals_bitsize = 32;

primitive MayEscapeVia: u32;


//

struct NukeOnRebuild
{
    files:      flat::Map(string, string);
    fuzzy:      flat::Map(string, string);
};

nocopy struct Context
{
    // Default modules & co.
    fudir:      string;

    // Error reporting & file snippets.
    base_dir:   string;

    //
    modules:    Module[];
    dep_order:  i32[];

    // Watch mode:
    //  every build should begin by clearing these.
    using nuke: NukeOnRebuild;
};

struct Module
{
    modid:      i32;
    fname:      string;

    in?:        ModuleInputs;
    order?:     ModuleOrder;
    out?:       ModuleOutputs;
    stats?:     ModuleStats;

    profile?:   profiler::Profile;
};

struct ModuleInputs
{
    src:        string;
    lex:        LexerOutput;
    parse:      ParserOutput;
};

struct ModuleOrder
{
    dep_depth:  i32;
};

struct ModuleOutputs
{
    types:      UserType[];
    solve:      SolverOutput;
    cpp:        CodegenOutput;
};

struct ModuleStats
{
    lex:        stat::ModuleStat;
    parse:      stat::ModuleStat;
    solve:      stat::ModuleStat;
    codegen:    stat::ModuleStat;
};


//

struct UserTypeCanon { modid: i32; index: i32 };

struct Shape
{
    // User primitives have an
    //  underlying base primitive type.
    //
    basePrim:       string;

    // Mask of non-trivial shape bits
    //  of all the non-trivial types owned inside.
    //   Use this to speed up myPointInto queries.
    //
    non_triv_mask:  u64;    // has at least one bit (1 << self.hash & 63) if non-triv,
                            //  else trivial and thus empty.
    hash:           u64;

    flatCount:      i32;
    declDepth:      i32;

    //
    usertypes:      flat::Set(UserTypeCanon);
    recursive:      bool;
};

struct UserType
{
    true kind:      Kind;
    name:           string;

    target?:        Target;
    items?:         ScopeItem[];    // TODO items -> members
    implicits?:     ScopeItem[];
    imports?:       flat::Set(i32);
    converts?:      Target[];

    // Size & co.
    using shape:    Shape;
};


//

struct LexerOutput
{
    tokens:     Token[];
};

struct Import
{
    token:      TokenIdx;
    pattern:    string;
    modid?:     i32;
};

struct ParserOutput
{
    root:       Node;
    imports:    Import[];
    warnings:   string[];
}

struct SolverOutput
{
    root:       SolvedNode;
    scope:      Scope;

    // Important solver events for testing.
    notes:      SolverNotes;
};

struct BuildHacks
{
    // Libraries and such.
    link?:              flat::Set(string);
    include_dirs?:      flat::Set(string);
    extra_sources?:     flat::Set(string);
};

struct CodegenOutput
{
    using src:  string;

    // #includes for change tracking.
    includes_headers?:  flat::Set(string);
    hacks?:             BuildHacks;

    // Testsuite dep modids (empty == no testsuite).
    testsuite_modids?:  flat::Set(i32);

    //
    defects?:           CGDefects;
};


//

struct LineColChars
{
    line:       i32;
    col:        i32;
    chars:      i32;
};

struct Token
{
    true kind:  Kind;
    using lcc:  LineColChars;
    value:      string;
};


//

struct Node
{
    true kind:  Kind;
    asserts?:   DeclAsserts;
    syntax?:    ParseSyntax;

    flags?:     Flags;
    value:      string;
    items?:     Node[];
    token:      TokenIdx;
};

struct TokenIdx
{
    modid:      i32;
    tokidx:     i32;
};


//

struct Target
{
    _packed!:   u64;
}

struct Helpers
{
    index:      i32;
};

struct SolvedNode
{
    true kind:      Kind;

    helpers:        Helpers; // TODO not here: I had room for it, but honestly this is not the best place for this.
    flags:          Flags;
    _loop_start?:   i32;

    value:          string;
    items:          SolvedNode[];
    token:          TokenIdx;

    using type:     Type;
    target:         Target;
}


//

struct ScopeItem
{
    true id:        string;
    _packed:        u64;
};

nocopy struct Scope
{
    overloads:      Overload[];
    extended:       Extended[];

    items:          ScopeItem[];
    implicits:      ScopeItem[];
    globals:        ScopeItem[];
    imports:        i32[];
    privates:       i32[];
    usings:         Target[];
    converts:       Target[];

    pub_items:      i32;
    pub_implicits:  i32;
    pub_globals:    i32;
    pub_converts:   i32;
};


//

struct Template
{
    true node:      Node;
    imports:        i32[];
};


//

struct Argument
{
    name?:          string;
    autocall?:      string;

    using type?:    Type;
    default?:       SolvedNode;
    target?:        Target;

    flags?:         Flags;

    // Original concept was a full-fledged lifetime here,
    //  but we're starting off with a simple usage mask.
    //
    written_to?:    Quals;

    // Argument A may safely invalidate argument B
    //  when all writes to A happen after the last use of B.
    //
    may_invalidate?:    ::BitSet;

    // Argument A may safely alias argument B
    //  if no unstable pointers derived from B
    //   are used after A is written to for the last time,
    //    and vice-versa.
    //
    may_alias?:         ::BitSet;
};

struct COWInside
{
    vtype:          ValueType;
    token:          TokenIdx;
    argTarget:      i32;
    mayEscapeVia:   MayEscapeVia;
    exitPaths:      ExitPaths;
};

struct Overload
{
    true kind:      Kind;

    flags:          Flags;
    status?:        SolverStatus;
    asserts?:       DeclAsserts;

    name:           string;

    type:           Type;

    solved:         SolvedNode;
};

struct Extended
{
    // Arity.
    min:            i32;
    max:            i32;
    args:           Argument[];

    cows_inside:    COWInside[];

    // The scopeskips here aren't needed in global scope (e.g. anything imported).
    spec_of?:       Target;
    true template:  Template;

    // The new nodelists.
    args_n_locals?: Overload[];

    // Previously we appended a fns signature hash to its name,
    //  now we'll do this in the codegen.
    //
    // But this could also be used for some kind of content addressed code thing,
    //  TBD where we can take this, deduplicate identical functions or something.
    //
    sighash?:       tea::TEA;

    //
    fx_mask?:       effects::FxMask; // 16
    rest_1b?:       u16;             // 16
    args_neg?:      i32;
};


//

struct ValueType
{
    quals?:         Quals;
    vfacts?:        VFacts;
    canon:          string;
};

struct Type
{
    using vtype:    ValueType;
    lifetime?:      Lifetime; // Excluding this from the truth check feels dangerous
};

struct Lifetime { uni0n!: byte[] };


// Instead of this we'd have a string listing qualities,
//  known value ranges, etc, but this should be enough to get the basics set it.

using flags VFacts
{
    AlwaysTrue
    AlwaysFalse
    Typename

    // Slices - whether they span all the way
    //  to either side of the underlying array.
    //
    // TODO replace these with something that goes on the lifetimes -
    //  a] will allow a mutvar to lose the L/R alignment when it degrades to a let,
    //  b] could be expressed as a bit on the final region -
    //      when set, it might imply a flatcount of 1 (pointer-indivisible),
    //       and instead of the flatcount could contain a [lo: locid, hi: locid]
    //        expression of some kind for borrow checking disjoint ranges.
    //
    LeftAligned
    RightAligned

    // Previously we had the is_AssumeNever_WhileSolvingRecursion experiment,
    //  which basically amounted to a 'never' value with a bogus 'q_rx_resize' qual.
    //   This can tag any type, not limited to never.
    //
    AssumingInfiniteRecursion
};


// Argument OOE, here for sharing in solver & cg.

fn isRTL(o: Overload): bool
    !!(o.status & SS_FN_OOE_RTL);

fn isRTL_set(ref o: Overload, rtl: bool)
    if (rtl)    o.status |=  SS_FN_OOE_RTL;
    else        o.status &= ~SS_FN_OOE_RTL;


// New argument order of evaluation rules -
//  1. everything left-to-right,
//  2. but all mutrefs after all non-mutrefs.
//
// Why:
//  1. generalizes the usual LTR vs RTL rules in c-like languages,
//      e.g. everything LTR, except assignments and arr[i] RTL, etc;
//  2. ensures that if some constref arg needs a temp copy,
//      we'll only copy the thing needed instead of everything it depends on;
//  3. will help with the COW crisis by making more copies happen
//      before new mutrefs are taken, which should help compile more stuff
//       if we need to forbid copies during borrows.

fn argsForward(lax RTL: bool, host_args: Argument[..], fn,
    seqIdx_start = 0)
{
//*
    mut seqIdx = 0;

    mut lastPass = 1;
    for (mut pass = 0; pass < lastPass; pass++)
    {
        for (mut i = 0; i < host_args.len; i++)
        {
            let host_arg = host_args[i];
            if (!!pass != (RTL ? !i : !!(host_arg.flags & F_IMPLICIT || host_arg.type.is_mutref)))
            {
                lastPass = 2;
                continue;
            }

            if (seqIdx_start <= seqIdx)
                fn(:i, host_arg?: host_arg, seqIdx?: seqIdx,
                     ooe_isLast?: seqIdx == host_args.len - 1);

            seqIdx++;
        }
    }
/*/
    mut seqIdx = 0;

    let N           = host_args.len;

    let start       = !RTL ? 0 : N - 1;
    let end         = !RTL ? N : 0 - 1;
    let incr        = !RTL ? +1  :  -1;

    for (mut i = start; i != end; i += incr)
    {
        if (seqIdx_start <= seqIdx)
            fn(:i, host_arg?: host_args[i], seqIdx?: seqIdx);

        seqIdx++;
    }
//*/
}

fn argsReverse(lax RTL: bool, host_args: Argument[..], fn)
{
//*
    mut revSeqIdx = 0;

    mut lastPass = 1;
    mut ooe_isLast = true;
    for (mut pass = 2; pass --> lastPass; )
    {
        for (mut i = host_args.len; i --> 0; )
        {
            let host_arg = host_args[i];
            if (!!pass != (RTL ? !i : !!(host_arg.flags & F_IMPLICIT || host_arg.type.is_mutref)))
            {
                lastPass = 0;
                continue;
            }

            fn(:i, :host_arg, ooe_isLast?: ooe_isLast, revSeqIdx?: revSeqIdx);
            ooe_isLast = false;

            revSeqIdx++;
        }
    }
/*/
    let N           = host_args.len;

    let start       = RTL ? 0 : N - 1;
    let end         = RTL ? N : 0 - 1;
    let incr        = RTL ? +1  :  -1;

    for (mut i = start; i != end; i += incr)
        fn(:i, host_arg: host_args[i], ooe_isLast?: i == start);
//*/
}


//

fn _token(implicit ctx: Context, idx: TokenIdx): Token
    ctx.modules[idx.modid].in.lex.tokens[idx.tokidx];

fn _fname(implicit ctx: Context, idx: TokenIdx): string
    ctx.modules[idx.modid].fname;


//

inline fn indexOfLocal(args_neg!: i32, locid!: i32): int
{
    return args_neg - (locid > 0 ? 1 : 0) + locid;
}

inline fn indexOfLocal(ext: Extended, locid!: i32): int
{
    return ext.args_neg - (locid > 0 ? 1 : 0) + locid;
}

inline fn nextIndexOfLocal(ext: Extended, asArgument!: bool): int
{
    return asArgument
        ? (-1) - ext.args_neg
        : ext.args_n_locals.len + (1 - ext.args_neg);
}


//

inline fn sign_rotate(v: i32)
    (v.u32 << 1) ^ (v < 0 ? 0xffffffff : 0x0)

inline fn sign_unrotate(v: u32)
    i32((v >> 1) ^ (v & 1 ? 0xffffffff : 0x0))


// Packed targets, one u64 packing modid+global+local.
//  This gives us a capacity of up to 1 million modids/globids/locids,
//   which is not a lot but should be relatively hard to hit in practice.
//
// Leaves us with the four msbits for flags & such,
//  we use them for specfails (msb set),
//   and for shadowing, stop-searching and could use them for F_PUBs too.
//
inline fn  modid(t: Target) i32(t._packed >> 40 & 0xfffff);
inline fn globid(t: Target) i32(t._packed >> 20 & 0xfffff);
inline fn  locid(t: Target) u32(t._packed       & 0xfffff).sign_unrotate;

fn Target(modid: i32, globid: i32, locid: i32)
{
    modid >= 0 && globid > 0 || throw(
        "Target: bad modid/index/locid");

    return Target(_packed: modid.u64 << 40
                        | globid.u64 << 20
                        |  locid.sign_rotate.u64);
}

inline fn isArg(locid!: i32)           locid < 0;
inline fn isArg(target: Target) target.locid < 0;


// Making these distinct,
//  so we don't waste a byte on locids where we dont need them.

fn parseLocalOrGlobal(str: string, ref offset!: i32)
{
    let modid  = str.helpers::parseVarint(:offset).i32;
    let globid = str.helpers::parseVarint(:offset).i32;
    let locid  = str.helpers::parseVarint(:offset).sign_unrotate;

    return Target(:modid, :globid, :locid);
}

fn appendLocalOrGlobal(ref str: string, using target: Target)
{
    modid >= 0 && globid > 0 || throw(
        "appendLocalOrGlobal: bad modid/globid/locid");

    str.helpers::appendVarint(modid.u32);
    str.helpers::appendVarint(globid.u32);
    str.helpers::appendVarint(locid.sign_rotate);
}


//

fn parseGlobal(str: string, ref offset!: i32)
{
    let modid  = str.helpers::parseVarint(:offset).i32;
    let globid = str.helpers::parseVarint(:offset).i32;

    return Target(:modid, :globid, locid: 0);
}

fn appendGlobal(ref str: string, using target: Target)
{
    modid >= 0 && globid > 0 && !locid || throw(
        "appendGlobal: bad modid/globid/locid");

    str.helpers::appendVarint(modid.u32);
    str.helpers::appendVarint(globid.u32);
}


//

fn add(ref mayEscapeVia: MayEscapeVia, locid!: i32)
{
    mayEscapeVia |= 1 << (locid.u32.MayEscapeVia % 32);
}


// Sad this has to be here, don't want an implicit ref p
//  because we have the module everywhere already
//   and it'd be a shame to have to inject another arg in every func.

inline fn PROFILE(lax id, implicit ref module: Module, lax reset!?: bool) unwrap
{
    if (profiler::PROFILE) unwrap
    {
        inline fn p     = module.profile;

        let now0        = profiler::Now();
        if (reset)
            p.now       = now0;

        let offset      = p.now - now0;

        defer {
            let now_end     = profiler::Now();
            let td          = now_end - p.now + offset;

            p.data.id.sample    += td;
            p.data.id.count     += 1;

            p.now           += td;
        };
    }
}







fn ensure(ref a: <T>[], exists!i: (TODO_REMOVE_bootstrap ? int : void)) {
    if (a.len <= i)
        a.grow(i + 1);

    return a[i];
}

fn if(ref a: <T>[..], exists!i: (TODO_REMOVE_bootstrap ? int : void), and?: <Then>, else!?)
    i.unsigned < a.len.unsigned
        ? Then -> [] ? a[i] : and(a[i])
        : else();

fn remove(ref a: <T>[..], at!: (TODO_REMOVE_bootstrap ? int : void), count = 1)
    a.splice(at, count);


//

fn hasIdentifierChars(id: string)
{
    for (mut i = 0; i < id.len; i++)
    {
        let c = id[i];
        if (c == '_' || c >= 'a' && c <= 'z'
                     || c >= 'A' && c <= 'Z'
                     || c >= '0' && c <= '9')
        {
            return true;
        }
    }

    return false;
}

fn hasNonIdentifierChars(id: string)
{
    for (mut i = 0; i < id.len; i++)
    {
        let c = id[i];
        if (c == '_' || c >= 'a' && c <= 'z'
                     || c >= 'A' && c <= 'Z'
                     || c >= '0' && c <= '9')
        {
            //
        }
        else
        {
            return true;
        }
    }

    return false;
}


//

fn zip_each(ref a: <T>[..], ref b: <U>[..], fn)
{
    a.len == b.len || throw("a.len != b.len");
    for (mut i = 0; i < a.len; i++)
        fn(a[i], b[i], i?: i);
}

fn zip_all(ref a: <T>[..], ref b: <U>[..], pred)
{
    zip_each(a, b): |shadow a, shadow b, i|
        if !(pred(a, b, i?: i))
            return false;

    return true;
}


//

fn clone(a: <T>)
case (T.is::copy) a;
case (T -> _[..]) a.map(fn clone);
case (T -> T) // <- weird, whats this for?
{
    mut res: T;
    for (fieldname i: T)
        res.i = a.i.clone();

    return res;
}

fn steal(ref a: <T>[], start!: i32, end!: i32)
{
    let size = end - start;

    mut ret: T[];
    ret.resize(size);

    for (mut i = 0; i < size; i++)
        swap(ret[i], a[i + start]);

    a.splice(start, count: size);
    return ret;
}

fn steal(ref a: <T>[], start!: i32)
{
    mut ret: T[];
    ret.resize(a.len - start);

    for (mut i = 0; i < ret.len; i++)
        swap(ret[i], a[i + start]);

    a.shrink(start);
    return ret;
}


//

fn parse10u32(ref offset: i32, str: string)
{
    mut result: u32;
    while (offset < str.len)
    {
        let c = str[offset];
        if (c < '0' || c > '9')
            break;

        offset++;
        result = result * 10 + (c.u32 - '0'.u32);
    }

    return result;
}

fn parse10s32(ref offset: i32, str: string)
{
    if (offset >= str.len)
        return 0;

    let mul = str[offset] == '-'
        ? { offset++; -1 }
        : +1;

    return parse10u32(offset, str).i32 * mul;
}


// WARNING dont use BACKTICKS elsewhere
//
// Varints -
//  Any number of msb-set bytes (>= 128),
//   followed by one [0-9], [A-Z], "_", "`" or [a-z] byte -
//    so ascii punctuation except for BACKTICKS and UNDERSCORES
//     can be used unambiguously elsewhere.
//
// WARNING dont use BACKTICKS elsewhere

fn parseVarint(ref offset: i32, str: byte[])
{
    mut shift:  u32;
    mut result: u32;

    mut c: byte;
    while (offset < str.len
            && (c = str[offset++]).u32 >= 128)
    {
        result |= (c.u32 & 0x7f) << shift;
        shift  += 7;
    }

    let sub = c >= '0' && c <= '9' ? '0'.u32
            : c >= 'A' && c <= 'Z' ? 'A'.u32 - 10
            : c >= '_' && c <= 'z' ? '_'.u32 - 36
            : throw("parseVarint: missing trailer");

    return result | (c.u32 - sub) << shift;
}

fn appendVarint(ref str: byte[], mut v: u32)
{
    while (v >= 64)
    {
        str ~= byte(v | 0x80);
        v  >>= 7;
    }

    let add = v < 10 ? '0'.u32
            : v < 36 ? 'A'.u32 - 10
                     : '_'.u32 - 36;

    str ~= (v + add).byte;
}


//

fn print(arr: <T>[..]) case (T.is::arithmetic)
{
    mut result = "";
    for (mut i = 0; i < arr.len; i++)
    {
        if (i == 5 && arr.len > 16)
        {
            i = arr.len - 5;
            result ~= ", ... (" ~ arr.len - 10 ~ " more) ...";
        }

        result ~= (i ? ", " : "[ ");
        result ~= arr[i];
    }

    result ~= result ? " ]" : "[]";
    return result;
}

fn print(arr: string[..]) {
    return arr ? "[ \"" ~ arr.join("\", \"") ~ "\" ]" : "[]";
}


//

fn trim(str: string)
{
    for (mut first = 0; first < str.len; first++)
        if (str[first] > ' ')
            for (mut last = str.len; last-- >= first; )
                if (str[last] > ' ')
                    return str.slice(first, last + 1);

    return "";
}


//

fn parse(v: byte[..], type as!<T>)
    case (T.is::enum || T.is::bitfield /*TODO .is::flags*/ )
{
    // now supported, there's a test for it, this parser is wrong though
    // if (T.is::bitfield)
    //     for (mut i = 1; i < v.len; i++)
    //         if (v[i] == "|")
    //             return parse(v[: i]) | parse(v[i + 1 :]);

    for (fieldname i: T)
        if (v == "i")
            return i; // TODO "i", was only allowed for enums

    return [];
}

fn parseWild(v: byte[..], type as!<T>)
{
    mut result: T;
    for (mut i = 0; i < v.len; i++)
    {
        if (v[i] == '*')
        {
            let prefix = v[.. i];
            let suffix = v[i + 1 ..];

            for (fieldname i: T)
            {
                let opt = "i";
                if (opt.starts(with: prefix) && opt.ends(with: suffix))
                    result |= i;
            }

            return result;
        }
    }

    return parse(:v, as: T);
}


//

fn cleanID(id: string)
{
    let start   = id.find('!') + 1;
    let end     = id.find('.', :start);
    if (start || end >= 0 && end < id.len)
        return id.slice(start, end >= 0 ? end : id.len)
            || throw("cleanID: ended up with an empty string");

    return id;
}


//

fn steal(ref v: <T>) {
    mut ret: T;
    swap(v, ret);
    return ret;
}

fn exchange(ref a: <T>, mut b: T) {
    swap(a, b);
    return b;
}

// TODO using this for _nestingFnort got me in trouble
//  with COW police, but there's no COW, Target is trivial
//
fn shadow(ref a: <T>, mut b: T) unwrap {
    swap(a, b);
    defer:ok swap(a, b);
}


//

fn leftpad(.str, minw: int, mut pad = "               ")
{
    if (str.len >= minw)
        return str;

    let needed = minw - str.len;
    while (pad.len < needed)
        pad ~= pad;

    pad.shrink(needed);
    return pad ~= str;
}


// Sketch, cursor-like empty ranges.

inline fn start  (ref arr: <T>[]) arr[.. 0];
inline fn end    (ref arr: <T>[]) arr[arr.len ..];
inline fn before (ref arr: <T>[], index: int) arr[i .. i];
inline fn after  (ref arr: <T>[], index: int) arr.before(i + 1);






pub let SELF_TEST = !!true;


//

pub fn getModuleSrc(implicit ctx: Context, modid!: i32)
{
    return ctx.modules[modid].in.src;
}

pub fn formatTokenCoord(token: TokenIdx, from!: i32, implicit ctx: Context)
{
    mut fname = from != token.modid && token._fname;

    // Doing this for testdiffs, we want to emit the same error messages
    //  irrespective of where on the fs your code is,
    //   we dont want /home/username/myproj/whatever in there.
    //
    if (fname && ctx.base_dir)
        fname = path::relative(from: ctx.base_dir, to: fname);

    return formatTokenCoord(:fname, token: token._token);
}

pub fn formatTokenCoord(fname!: string, token: LineColChars)
{
    let lcc     = token.line ~ ":" ~ token.col ~ "+" ~ token.chars;
    if (!fname)
        return ansi::DIM ~ lcc ~ ansi::RESET;

    let dir     = path::dirname(fname);
    let file    = fname.slice(dir.len, fname.len);
    let ext     = path::ext(file);
    let noext   = file.slice(0, file.len - ext.len);

    return ansi::DIM ~ dir ~ ansi::RESET
         ~ noext
         ~ ansi::DIM
         ~ ext ~ " " ~ lcc
         ~ ansi::RESET;
}

using pub flags CodeFmt
{
    FullContext
    NoLeadContext
    NoTailContext
    NoContext
};

pub fn formatCodeSnippet(src!: string, fmt?: CodeFmt, mut highlight!: LineColChars[])
{
    // TODO should be able to sort without the < 0, moronic
    highlight.sort(
        |a, b| (a.line - b.line || a.col - b.col) < 0);

    for (mut i = highlight.len - 1; i --> 0; )
    {
        let a = highlight[i];
        let b = highlight[i + 1];

        if (a.line != b.line)
        {
            if (SELF_TEST)      // Not BUGGing here because that'd sorta go recursive.
                a.line < b.line || throw("formatCodeSnippet: a.line !< b.line");

            continue;
        }

        // Discard duplicate / overlapping tokens.
        if (a.col + a.chars > b.col)
            highlight.splice(i, 1);
    }

    if (!highlight)
        return "";

    //
    let lines   = src.split("\n");

    let start   = highlight.first;
    let end     = highlight.last;

    mut l_start = start.line - 1;  // lines are 1 based.
    mut l_end   =   end.line;

    l_start     = l_start.min(lines.len).max(0);
    l_end       = l_end  .min(lines.len).max(0);

    mut result  = "";

    let leadContext = fmt & (NoContext | NoLeadContext) ? 0 : 2;
    let tailContext = fmt & (NoContext | NoTailContext) ? 0 : 2;

    // Leading context lines.
    for (mut i = max(0, l_start - leadContext); i < l_start; i++)
    {
        result ~= ansi::DIM ~ "      | ";
        result ~= lines[i];
        result ~= ansi::RESET ~ "\n";
    }

    // Highlighted lines.
    for (mut i = l_start; i < l_end; i++)
    {
        mut line = lines[i];
        let line_no = i + 1;

        // Numbered line margins.
        {
            mut margin = line_no ~ " | ";
            while (margin.len < 8)
                margin = " " ~ margin;

            result ~= ansi::DIM ~ margin ~ ansi::RESET;
        }

        // Highlight error tokens on this line.
        for (shadow mut i = highlight.len; i --> 0; )
        {
            let token = highlight[i];
            if (token.line == line_no)
            {
                let c0 = (token.col - 1   ).min(line.len).max(0);
                let c1 = (c0 + token.chars).min(line.len);

                line.splice(c1, 0, ansi::RESET);
                line.splice(c0, 0, ansi::BAD);
            }
        }

        result ~= line ~ "\n";
    }

    // Trailing context lines.
    for (mut i = l_end; i < min(lines.len, l_end + tailContext); i++)
    {
        result ~= ansi::DIM ~ "      | ";
        result ~= lines[i];
        result ~= ansi::RESET ~ "\n";
    }

    return result;
}

pub fn formatCodeSnippet(mut tokens: TokenIdx[], from!: i32, fmt?: CodeFmt)
{
    tokens.sort(|a, b| a.modid < b.modid);

    mut append = "";
    for (mut i = 0; i < tokens.len - 1; i++)
    {
        let a = tokens[i];
        let b = tokens[i + 1];

        if (a.modid != b.modid)
        {
            append ~= "\n";
            append ~= formatCodeSnippet(tokens.slice(i + 1), :from);
            tokens.shrink(i + 1);
            break;
        }
    }

    let head = tokens.if_first;
    if (!head)
        return append;

    // Head token coord will print the filename unless == :from.
    mut result = "";
    result ~= formatTokenCoord(head, :from);

    // The rest of the remaining tokens here are in the same file.
    for (mut i = 1; i < tokens.len; i++)
        (result ~= ' ') ~= formatTokenCoord(tokens[i]._token, fname: "");

    result ~= ":\n";

    if !(fmt & (NoContext | NoLeadContext))
        result ~= "\n";

    //
    mut highlight: LineColChars[] = [];
    for (mut i = 0; i < tokens.len; i++)
        highlight.push(tokens[i]._token.lcc);

    let src = getModuleSrc(:head.modid);
    result ~= formatCodeSnippet(:src, :fmt, :highlight);

    //
    result ~= append;
    return result;
}


//

implicit ref _here: TokenIdx;

pub inline fn HERE(node.token: TokenIdx)
{
    if (node)
        _here = node;
}

pub fn FAIL_text(tokens: TokenIdx[], reason: string): string
{
    let snippet = formatCodeSnippet(:tokens, from: -1);

    return snippet ~ "\n\t" ~ reason ~ "\n";
}

pub fn FAIL_text(
    fname!: string, src!: string,
    token!: LineColChars, reason!: string): string
{
    let addr    = formatTokenCoord(:fname, :token);
    let snippet = formatCodeSnippet(:src, highlight: [ token ]);

    return addr ~ ":\n\n" ~ snippet ~ "\n\t" ~ reason ~ "\n";
}

pub fn FAIL(reason: string, tokens!: TokenIdx[] = [ _here ]): never
{
    throw (FAIL_text(:tokens, :reason));
}

pub fn FAIL(
    fname!: string, src!: string,
    token!: LineColChars, reason!: string): never
{
    throw (FAIL_text(:fname, :src, :token, :reason));
}

pub fn BUG(mut reason?: string)
{
    FAIL("COMPILER BUG:\n\n\t" ~ (reason || "Assertion failed."));
}

pub fn TEST_true(inline assertion, inline msg?: string)
{
    if (SELF_TEST)
        return assertion || BUG(msg);
    else
        return assertion;
}



//

let SR_empty        = "\x00\x00";


// Current encoding -
//
//  r & 1 == 0          ? locid
//  r & 3 == 3 (1 + 2)  ? argpos
//  r & 3 == 1          ? either static, temp or zeroes
//
//  r & 15 == 1         ? static
//  r & 15 == 5 (1 + 4) ? zeroes
//  r & 15 == 9 (1 + 8) ? temp
//
// The point of tracking the zero-init lifetime separately
//  is that you can move from it unlike other statics.

let byte_STATIC     = byte(0b0001);
let byte_ZEROES     = byte(0b0101);
let byte_TEMP       = byte(0b1001);

inline fn isZeroes(r: u32)          r == 0b0101;
inline fn isStaticOrZeroes(r: u32)  r & 11 == 1;
inline fn isTemporary(r: u32)       r == 0b1001;
inline fn isArgIdx(r: u32)          r & 3 == 3;


//

let Region_STATIC   = byte_STATIC   ~ SR_empty;
let Region_ZEROES   = byte_ZEROES   ~ SR_empty;
let Region_TEMP     = byte_TEMP     ~ SR_empty;

fn parse7bit(str: byte[..], ref offset: int)
{
    mut shift:  u32;
    mut result: u32;

    mut c: byte;
    while (offset < str.len
            && (c = str[offset++]).u32 >= 128)
    {
        result |= (c.u32 & 0x7f) << shift;
        shift  += 7;
    }

    return result | c.u32 << shift;
}

fn append7bit(ref str: byte[], mut v: u32)
{
    while (v >= 128)
    {
        str ~= byte(v | 0x80);
        v  >>= 7;
    }

    str ~= byte(v);
}


/*
    a               ;       .A;     .A*;    .A*;    .A*B,.C;
    b               .A;     .B;     .A;     ;       .C*;

    UNION(a, b)     ;       .AB;    .A;     ;       .A*B,.C;
    INTER(a, b)     .A;     \       .A*;    .A*;    .C;

    We're going with full path serialize-parse for starters to keep things a little simpler,
     i think once we got this figured out it should be relatively easy
      to optimize each op to directly process the raw bytes.
*/

pub inline fn walkPaths(str: byte[..], ref offset, lax tailOK!?: bool,
    onPathStart!?,

    onSubRegion!?,
    onLastSubRegion!?,

    onPathDone!?,
    onDone!?)
{
    lax let offset0 = offset + 0 /* i'm having a bad time, otherwise this returns a ref, which relaxes ... */;

    // A non-empty list of "paths" ...
    for (;;)
    {
        mut isLastPath          = false;
        mut isFirstSubRegion    = true;

        let path0               = offset;

        onPathStart();

        // ... which are non-empty lists of subregions ...
        for (;;)
        {
            // Subregion flatCount.
            let subregion0      = offset;
            let raw_flatOffset  = str.parse7bit(:offset);
            let isLastSubRegion = !(raw_flatOffset & 1);

            let raw_flatCount   = isLastSubRegion
                ? str.parse7bit(:offset)
                : 3;

            isLastPath          = !(raw_flatCount & 1);

            let flatCount       = i32(raw_flatCount  >> 1);
            let flatOffset      = i32(raw_flatOffset >> 1);

            onSubRegion(
                ?:isFirstSubRegion,
                ?:isLastSubRegion,
                ?:isLastPath,
                ?:flatCount,
                ?:flatOffset,

                raw_prefix?:    str[path0 .. subregion0]);

            if (isLastSubRegion)
            {
                onLastSubRegion(
                    ?:isFirstSubRegion,
                    ?:isLastSubRegion,
                    ?:isLastPath,
                    ?:flatCount,
                    ?:flatOffset,

                    raw_prefix?:    str[path0 .. subregion0]);

                break;
            }

            isFirstSubRegion    = false;
        }

        onPathDone(
            isLastPath?:        isLastPath,
            raw_path?:          str[path0 .. offset]);

        if (isLastPath)
            break;
    }

    if (SELF_TEST && !tailOK)
        offset == str.len || BUG("walkPaths(!tailOK): excess bytes");

    onDone();

    return offset0;
}


//

pub lax fn assertPathsValid(
    lax str: byte[..],
    lax mut expect_flatCount = -1,
    lax mut region_flatCount = -1,
    lax flatCountMismatchOK! = false,
    lax selfIntersectOK! = false,
    lax minPathDepth! = 1)
{
    if (!SELF_TEST)
        return;

    mut pathDepth       = -1001;
    mut numPaths        = 0;

    mut offset = 0;
    str.walkPaths(:offset,

        onPathStart: ||
        {
            pathDepth = 0;

            numPaths++;
            if (numPaths > 64)
                BUG("assertPathsValid: numPaths > 64, we're likely stuck in an infinite loop.");
        },

        onPathDone: ||
        {
            pathDepth >= minPathDepth || BUG(
                "assertPathsValid: pathDepth(" ~ pathDepth ~ ")"
                    ~ " !>= minPathDepth(" ~ minPathDepth ~ ")");
        },

        onSubRegion: |flatOffset, flatCount, isLastSubRegion, isFirstSubRegion|
        {
            pathDepth++;
            if (pathDepth > 64)
                BUG("assertPathsValid: pathDepth > 64, we're likely stuck in an infinite loop.");

            if (isFirstSubRegion && region_flatCount >= 0)
            {
                flatOffset + flatCount <= region_flatCount || BUG(
                    "assertPathsValid: flatOffset(" ~ flatOffset ~ ")"
                        ~ " + flatCount(" ~ flatCount ~ ")"
                        ~ " !<= region_flatCount(" ~ region_flatCount ~ ")");
            }

            if (isLastSubRegion && !flatCountMismatchOK)
            {
                if (expect_flatCount < 0)
                    expect_flatCount = flatCount;
                else
                    expect_flatCount == flatCount || BUG(
                        "assertPathsValid: expect_flatCount(" ~ expect_flatCount ~ ")"
                            ~ " != flatCount(" ~ flatCount ~ ")");
            }
        });
}


//

struct SubRegion
{
    flatCount:      i32;
    flatOffset:     i32;
};

type Paths = SubRegion[][];

fn parsePaths_each(str: byte[..], each)
{
    mut path: SubRegion[];

    mut _o = 0;
    str.walkPaths(offset: _o,

        onPathStart: || {
            path.clear();
        },

        onSubRegion: |flatCount, flatOffset| {
            path ~= SubRegion(:flatCount, :flatOffset);
        },

        onPathDone: || {
            each(path);
        });
}

fn parsePaths(str: byte[..]): Paths
{
    mut paths:      SubRegion[][];
    mut path:       SubRegion[];

    mut _o = 0;
    str.walkPaths(offset: _o,

        onSubRegion: |flatCount, flatOffset| {
            path ~= SubRegion(:flatCount, :flatOffset);
        },

        onPathDone: || {
            paths ~= helpers::steal(path);
        },

        onDone: || {
            return paths;
        });
}

fn printPaths(str: byte[..]): string
{
    mut result = "";

    mut _o = 0;
    str.walkPaths(offset: _o,

        onPathStart: || {
            result ~= "\n\tPath:\n";
        },

        onPathDone: |isLastPath| {
            result ~= "\t/Path\tisLastPath=" ~ isLastPath;
        },

        onSubRegion: |flatCount, flatOffset, isFirstSubRegion, isLastSubRegion| {
            result ~= "\t\tSubReg\t flatCount="         ~ flatCount
                                ~ " isFirstSubRegion="  ~ isFirstSubRegion
                                ~ " isLastSubRegion="   ~ isLastSubRegion
                                ~ "\n";

            result ~= "\t\t\tflatOffset=" ~ flatOffset ~ "\n";
        },

        onDone: || {
            return result;
        });
}


//

inline fn appendSubRegion(ref uni0n: byte[],
    flatCount: i32, flatOffset: i32,
    isLastSubRegion!: bool, isLastPath!: bool)
{
    if (SELF_TEST)
        flatOffset >= 0 && flatCount > 0 && (isLastSubRegion || flatCount == 1) || BUG(
            "appendSubRegion: flatCount(" ~ flatCount ~ ")"
                          ~ " flatOffset(" ~ flatOffset ~ ")"
                          ~ " isLastSubRegion(" ~ isLastSubRegion ~ ")");

    uni0n.append7bit(
        flatOffset.u32 << 1
            | (isLastSubRegion ? 0 : 1));

    if (isLastSubRegion)
        uni0n.append7bit(
            flatCount.u32 << 1
                | (isLastPath ? 0 : 1));
}

fn appendPaths(ref str: byte[], paths: Paths,
    lax emptyOK! = false,
    lax flatCountMismatchOK! = false,
    lax selfIntersectOK! = false)
{
    lax let str0 = str.len;

    if (SELF_TEST)
        emptyOK || paths || BUG("appendPaths: zero paths");

    // A non-empty list of "paths" ...
    for (mut i = 0; i < paths.len; i++)
    {
        let path            = paths[i];
        let isLastPath      = i == paths.len - 1;

        if (SELF_TEST)
            path || BUG("appendPaths: zero subregions");

        // ... which are non-empty lists of subregions ...
        for (shadow mut i = 0; i < path.len; i++)
        {
            let subregion       = path[i];
            if (SELF_TEST)
            {
                subregion || BUG("appendPaths: empty subregion");

                subregion.flatCount

                    // TODO FIX statics and temporaries are special right now.
                    || path.len == 1
                    || subregion.flatOffset == 0
                    || BUG("appendPaths: empty flatCount");
            }

            let isLastSubRegion = i == path.len - 1;

            // Subregion flatCount.
            str.appendSubRegion(
                :subregion.flatCount, :subregion.flatOffset,
                :isLastSubRegion, :isLastPath);
        }
    }

    if (SELF_TEST)
        str ? assertPathsValid(str[str0 ..], :flatCountMismatchOK, :selfIntersectOK)
            : emptyOK || BUG("appendPaths: empty output");
}


//

fn Paths_union(ref result: SubRegion[][], path: SubRegion[])
{
    // Starting off really simple here,
    //  just ensure we don't get two identical paths,
    //   and also ignore attempts to add `a.b` to `a`.
    //
    for (mut i = 0; i < result.len; i++)
    {
        let host = result[i];

        let minL = min(path.len, host.len);
        if (SELF_TEST)
            minL || BUG("Paths_union: found an empty path.");

        if (path[.. minL - 1] == host[.. minL - 1])
        {
            let a_sr = host[minL - 1];
            let b_sr = path[minL - 1];

            // Does one completely wrap the other?
            let a0 = a_sr.flatOffset;
            let a1 = a0 + a_sr.flatCount;

            let b0 = b_sr.flatOffset;
            let b1 = b0 + b_sr.flatCount;

            let host_within_path = a0 >= b0 && a1 <= b1;
            let path_within_host = a0 <= b0 && a1 >= b1;

            if (path_within_host && path.len >= host.len)
            {
                // Nothing to add.
                return false;
            }

            if (host_within_path && host.len >= path.len)
            {
                // Get rid of the host path entry,
                //  we'll add it below after we've had the chance
                //   to get rid of more host paths.
                result.splice(i, 1);
                i--;
            }
        }
    }

    // UNION(a, b) -> a|b
    result ~= path;
    return true;
}


//

fn Paths_union(ref str: byte[], a: byte[..], b: byte[..],
    flatCountMismatchOK! = false)
{
    mut result = parsePaths(a);

    b.parsePaths_each: |b_path|
        result.Paths_union(b_path);

    str.appendPaths(result, :flatCountMismatchOK);
}

fn Paths_inter(ref str: byte[], a: byte[..], b: byte[..])
{
    if (a.len < b.len)
        return Paths_inter(str, b, a);

    mut result: SubRegion[][] = [];
    mut inter: SubRegion[];

    a.parsePaths_each: |a_path|
    {
        :EACH_B_PATH
        b.parsePaths_each: |b_path|
        {
            let N = min(a_path.len, b_path.len);
            for (mut i = 0; i < N; i++)
            {
                shadow let a = a_path[i];
                shadow let b = b_path[i];

                let overlap = min(
                    b.flatOffset + b.flatCount - a.flatOffset,
                    a.flatOffset + a.flatCount - b.flatOffset);

                if (overlap <= 0)
                {
                    inter.clear();
                    continue :EACH_B_PATH;
                }

                let flatCount   = min(a.flatCount,  b.flatCount);
                let flatOffset  = max(a.flatOffset, b.flatOffset);

                if (SELF_TEST)
                    overlap >= flatCount || BUG("Paths_inter: self-intersection:"
                        ~ "\n\t\ta.flatOffset(" ~ a.flatOffset ~ ") a.flatCount(" ~ a.flatCount ~ ")"
                        ~ "\n\t\tb.flatOffset(" ~ b.flatOffset ~ ") b.flatCount(" ~ b.flatCount ~ ")"
                        ~ "\n\t\toverlap(" ~ overlap ~ ")");

                inter ~= SubRegion(:flatCount, :flatOffset);
            }

            if (SELF_TEST)
                inter || BUG("Paths_inter: empty inter, about to append suffix");

            if (a_path.len > b_path.len) inter ~= a_path[b_path.len ..];
            if (b_path.len > a_path.len) inter ~= b_path[a_path.len ..];

            result.Paths_union(inter);
        }
    }

    str.appendPaths(result,
        emptyOK: true,
        selfIntersectOK: true,
        flatCountMismatchOK: true);
}


//

fn Paths_hasInter(a: byte[..], b: byte[..],
    rw_left?:  usage::RWQuals or [],
    rw_right?: usage::RWQuals or [])
{
    a.parsePaths_each: |a_path|
    {
        :EACH_B_PATH
        b.parsePaths_each: |b_path|
        {
            let N = min(a_path.len, b_path.len);

            shadow mut a: SubRegion;
            shadow mut b: SubRegion;

            for (mut i = 0; i < N; i++)
            {
                a = a_path[i];
                b = b_path[i];

                let overlap = min(
                    b.flatOffset + b.flatCount - a.flatOffset,
                    a.flatOffset + a.flatCount - b.flatOffset);

                if (overlap <= 0)
                    continue :EACH_B_PATH;
            }

            lax fn TEST_verifyUsageBitRanges(lax shadow a: SubRegion, lax rw: usage::RWQuals)
            {
                if (!SELF_TEST)
                    return;

                let range = usage::getRegionUsage(:a.flatOffset, :a.flatCount);

                // All quals.uage bits must be contained within the lifetime subregion,
                range & rw.usage == rw.usage
                    //
                    // ... at least some usage bits must be set,
                    && range & rw.usage
                    //
                    // ... and all rw.written_to must be a subset rw.usage.
                    && rw.written_to & rw.usage == rw.written_to
                        || BUG("range(" ~ range ~ ") rw.usage(" ~ rw.usage ~ ") rw.written_to(" ~ rw.written_to ~ ")");
            }

            fn checkUsage(shadow a: SubRegion, rw: Quals)
            {
                let range = usage::getRegionUsage(:a.flatOffset, :a.flatCount);
                if !(range & rw)
                    continue :EACH_B_PATH;

                // println("USAGE INTERSECTS range(" ~ range ~ ") usage(" ~ usage ~ ") inter(" ~ (range & usage) ~ ")");
            }

            //
            lax mut abs_left: usage::RWQuals;

            if !(rw_left.typeof -> [])
            {
                // We can't use left-usage when a_path is longer than b-path,
                //  meaning a-path is not fully dereferenced on intersection.
                //
                if (a_path.len <= b_path.len)
                {
                    abs_left = usage::USAGE_structUsageFromFieldUsage(
                        rw_left, memberFlatOffset: a.flatOffset);

                    TEST_verifyUsageBitRanges(a, abs_left);

                    checkUsage(b, rw_right.typeof -> [] || rw_right.written_to
                        ? abs_left.usage
                        : abs_left.written_to);
                }
            }

            if !(rw_right.typeof -> [])
            {
                if (b_path.len <= a_path.len)
                {
                    let abs_right = usage::USAGE_structUsageFromFieldUsage(
                        rw_right, memberFlatOffset: b.flatOffset);

                    TEST_verifyUsageBitRanges(b, abs_right);

                    checkUsage(a, rw_left.typeof -> [] || rw_left.written_to
                        ? abs_right.usage
                        : abs_right.written_to);

                    // Finally, if both sides are talking about the same region,
                    //  the two usage masks, if provided, must intersect.
                    if !(rw_left.typeof -> [])
                    {
                        if (b_path.len == a_path.len)
                        {
                            if !(abs_right.written_to & abs_left.usage ||
                                 abs_left.written_to & abs_right.usage)
                            {
                                ///////////////////////////////////////////////////////
                                // MEANINGFUL FAILCASE test suite never arrives here //
                                // BUG("// TODO FAILCASE //"); ////////////////////////
                                ///////////////////////////////////////////////////////

                                continue :EACH_B_PATH;
                            }
                        }
                    }
                }
            }

            return true;
        }
    }

    return false;
}


//

pub fn Lifetime_shiftUsage(paths: byte[..], usage: Quals)
{
    mut result: Quals;

    mut offset = 0;
    walkPaths(paths, offset, onSubRegion:
        |isFirstSubRegion, isLastSubRegion, flatCount, flatOffset|
    {
        if (!isFirstSubRegion)
            continue;

        if (!isLastSubRegion)
        {
            result |= usage::getRegionUsage(:flatOffset, :flatCount);
        }
        else
        {
            let usageBits       = usage::q_USAGE_bitsize - usage.unsigned.bit::clz;
            let usagePopcount   = usage.unsigned.bit::popcount;

            usageBits <= flatCount
                || usagePopcount <= flatCount
                || BUG("Lifetime_shiftUsage: flatOffset(" ~ flatOffset ~ ")"
                        ~ " flatCount(" ~ flatCount ~ ")"
                        ~ " usageBits(" ~ usageBits ~ ")"
                        ~ " usagePopcount(" ~ usagePopcount ~ ")");

            shadow let usage = usage::USAGE_structUsageFromFieldUsage(
                usage,
                memberFlatOffset: flatOffset);

            result |= usage;
        }
    });

    return result;
}


//

inline fn appendLocid(ref str: byte[], locid!: i32)
{
    // Current -
    // str.append7bit(locid.u32 << 1);

    // Next -
    str.append7bit(locid.sign_rotate << 1);

    // Faster? -
    // str.append7bit((locid.u32 & 0x8000000) >> 30 | locid.u32 << 2);
}

inline fn unpackLocid(r: u32)
{
    // Current -
    // return i32(r & 1 ? 0 : r >> 1);

    // Next -
    return r & 1 ? 0 : (r >> 1).sign_unrotate;

    // Faster? -
    // return r & 1 ? 0 : i32(r >> 2 | (r & 2) << 30);
}


//

pub fn Lifetime_from(locid!: i32, flatCount: i32): Lifetime =
{
    if (SELF_TEST)
        locid != 0 || BUG("Lifetime_from: Bad locid");

    mut uni0n: byte[];
    uni0n.appendLocid(:locid);
    uni0n.appendSubRegion(
        :flatCount, flatOffset: 0,
        isLastPath: true, isLastSubRegion: true);

    return Lifetime(:uni0n);
}

pub fn Lifetime_from(argidx!: i32, paths: byte[..]): Lifetime =
{
    if (SELF_TEST)
        argidx >= 0 || BUG("Lifetime_from: Bad argidx");

    mut uni0n: byte[];
    uni0n.append7bit((argidx.u32 << 2) | 3);
    uni0n ~= paths;

    return Lifetime(:uni0n);
}

pub let Lifetime_AAR_hasFalsePositives = true;

pub fn Lifetime_AAR(locid!: i32): Lifetime =
{
    if (SELF_TEST)
        locid < 0 || BUG("Lifetime_from: Bad locid");

    mut uni0n: byte[];
    uni0n.appendLocid(:locid);
    uni0n ~= SR_empty;

    return Lifetime(:uni0n);
}


//

inline fn merge !<B, L, R, Either, Rest>(

    l_chars.uni0n,
    r_chars.uni0n,

    both!?: B, left!?: L, right!?: R,

    either!?: Either,

    left_done!?,
    right_done!?,

    rest!?: Rest)
{
    mut l_start: i32;
    mut r_start: i32;

    mut l_paths0: i32;
    mut r_paths0: i32;

    mut l_offset: i32;
    mut r_offset: i32;

    mut l: u32;
    mut r: u32;

    mut l_dirty = true;
    mut r_dirty = true;

    mut l_done = false;
    mut r_done = false;

    lax let rest_chars =
    {
        :REST
        {
            for (;;)
            {
                if (l_dirty) {
                    l_dirty = false;
                    l_start = l_offset;

                    if (l_offset < l_chars.len) {
                        l = l_chars.parse7bit(l_offset);
                        l_paths0 = l_chars.walkPaths(offset: l_offset, tailOK: true);
                    }
                    else {
                        left_done();
                        if !(Rest -> [])
                            break :REST r_chars[r_dirty ? r_offset : r_start ..];
                        else
                            l_done = true;
                    }
                }

                if (r_dirty) {
                    r_dirty = false;
                    r_start = r_offset;

                    if (r_offset < r_chars.len) {
                        r = r_chars.parse7bit(r_offset);
                        r_paths0 = r_chars.walkPaths(offset: r_offset, tailOK: true);
                    }
                    else {
                        right_done();
                        if !(Rest -> [])
                            break :REST l_chars[l_dirty ? l_offset : l_start ..];
                        else
                            r_done = true;
                    }
                }

                let cmp = l_done ? r_done ? { return; } : +1
                                 : r_done ? -1

                        // Because we historically like to iterate lifetimes
                        //  from innermost to outermost, we compare backwards here,
                        //   so that we end up with the same reverse iteration order,
                        //    we basically store them innermost to outermost.
                        //
                        : (l.isStaticOrZeroes) != (r.isStaticOrZeroes) ? r.isStaticOrZeroes ? -1 : +1
                        : (l.isTemporary)      != (r.isTemporary)      ? r.isTemporary      ? +1 : -1

                        // Additionally complicated by locid sign-rotation.
                        //
                        // TODO FIX sign rotate the two instead,
                        //  which might reverse the order of arg-positions
                        //   but it shouldn't matter.
                        //
                        : (l & 3 == 2)  ? (r & 3 == 2)  ? l <> r
                                                        : +1
                                        : (r & 3 == 2)  ? -1
                                                        : r <> l;

                let either_chars =
                {
                    :EITHER
                    {
                        if (cmp == 0)
                        {
                            l_dirty = true;
                            r_dirty = true;
                            if !(B -> [])
                            {
                                both(l_chars[l_start .. l_paths0],  l_chars[l_paths0 .. l_offset],
                                                                    r_chars[r_paths0 .. r_offset],

                                     locid?: r.unpackLocid);

                                continue;
                            }
                        }
                        else if (cmp < 0)
                        {
                            l_dirty = true;
                            if !(Either -> [])
                                break :EITHER l_chars[l_start .. l_offset];

                            if !(L -> [])
                            {
                                left(l_chars[l_start .. l_offset]);
                                continue;
                            }
                        }
                        else
                        {
                            r_dirty = true;
                            if !(Either -> [])
                                break :EITHER r_chars[r_start .. r_offset];

                            if !(R -> [])
                            {
                                right(r_chars[r_start .. r_offset]);
                                continue;
                            }
                        }

                        continue;
                    }
                };

                //
                either(either_chars);
            }

            return;
        }
    };

    //
    rest(rest_chars);
}


//

pub fn Lifetime_union(a: Lifetime, b: Lifetime,
    flatCountMismatchOK! = false): Lifetime =
{
    mut result: Lifetime;

    merge(a, b,

        either: |raw| result.uni0n ~= raw,

        both: |r_both, sr_left, sr_right| {
            result.uni0n ~= r_both;

            if (sr_left == sr_right || sr_left == SR_empty)
                result.uni0n ~= sr_left;
            else if (sr_right == SR_empty)
                result.uni0n ~= sr_right;
            else
                Paths_union(
                    result.uni0n, sr_left, sr_right,
                    :flatCountMismatchOK);
        },

        // Early exits.
        left_done: || {
            if (!result)
                return b;
        },
        right_done: || {
            if (!result)
                return a;
        },
        rest: |either| {
            result.uni0n ~= either;
            break;
        });

    return result;
}

pub fn Lifetime_inter(a: Lifetime, b: Lifetime): Lifetime =
{
    mut result: Lifetime;

    mut inter: byte[];

    merge(a, b,

        both: |r_both, sr_left, sr_right|
        {
            let sr_chars =
            {
                :INTER
                {
                    if (sr_left == sr_right || sr_right == SR_empty)
                        break :INTER sr_left;
                    if (sr_left == SR_empty)
                        break :INTER sr_right;

                    inter.clear();
                    Paths_inter(inter, sr_left, sr_right);
                    if (inter)
                        break :INTER inter;

                    continue;
                }
            };

            result.uni0n ~= r_both;
            result.uni0n ~= sr_chars;
        },

        // Early exits.
        rest: |_| { break; });

    return result;
}

pub fn Lifetime_hasInter(a: Lifetime, b: Lifetime,
    rw_left?:  usage::RWQuals or [],
    rw_right?: usage::RWQuals or []): bool =
{
    if !(rw_left.typeof -> [] || rw_right.typeof -> [])
        if !(rw_left.written_to || rw_right.written_to)
            return false;

    merge(a, b,

        both: |_, sr_left, sr_right|
        {
            if (sr_left == sr_right

                    ? rw_left.typeof -> [] || rw_right.typeof -> []
                            || !!(rw_left.written_to & rw_right.usage ||
                                  rw_right.written_to & rw_left.usage)

                    : sr_left == SR_empty || sr_right == SR_empty
                            || Paths_hasInter(sr_left,  sr_right,
                                             :rw_left, :rw_right))
            {
                return true;
            }
        },

        // Early exits.
        rest: |_| { break; });

    return false;
}

pub fn Lifetime_interLocids(a: Lifetime, b: Lifetime): i32[] =
{
    mut result: i32[];

    merge(a, b,

        both: |_, locid, sr_left, sr_right|
        {
            if (!locid)
                continue;

            if (sr_left == sr_right
                || sr_left == SR_empty || sr_right == SR_empty
                || Paths_hasInter(sr_left, sr_right))
            {
                result ~= locid;
            }
        },

        // Early exits.
        rest: |_| { break; });

    //
    return result;
}


//

pub fn Lifetime_add(ref l: Lifetime, r: Lifetime,
    flatCountMismatchOK! = false)
{
    if (r)
        l = Lifetime_union(l, r, :flatCountMismatchOK);
}


//

pub fn Lifetime_each(lifetime: Lifetime, each)
{
    let chars = lifetime.uni0n;
    mut offset = 0;

    while (offset < chars.len)
    {
        lax let offset0 = offset;

        let r       = chars.parse7bit(:offset);
        lax mut sr  = chars.walkPaths(:offset, tailOK: true);

        each(
            locid?:     r.unpackLocid,
            argidx?:    i32(r & 1 ? r >> 2 : 0),

            isAlwaysMoveable?:  r.isZeroes || r.isTemporary,
            isStatic?:  r.isStaticOrZeroes,
            isTemp?:    r.isTemporary,
            isArgIdx?:  r.isArgIdx,

            region?:    Lifetime(uni0n: chars.slice(offset0, offset)),
            others?:    Lifetime(uni0n: chars[.. offset0] ~ chars[offset ..]),

            r_raw?:     chars[offset0 .. sr],
            paths?:     chars[sr .. offset],

            isOnly?:    !offset0 && offset == chars.len);
    }
}

pub fn Lifetime_process(lifetime: Lifetime, each)
{
    mut result: Lifetime;
    mut maybeOutOfOrder = false;

    fn visit(shadow lifetime: Lifetime)
    {
        let chars = lifetime.uni0n;
        mut offset = 0;

        while (offset < chars.len)
        {
            lax let offset0 = offset;

            :TEST
            {
                fn continue_climb(mut parent: Lifetime)
                {
                    maybeOutOfOrder = true;
                    visit(parent);
                    continue;
                }

                fn continue_replace(replacement: Lifetime)
                {
                    maybeOutOfOrder = true;
                    result.Lifetime_add(replacement);
                    continue;
                }

                fn continue_keep()
                {
                    // Doing this in a convoluted way so that
                    //  you can inline this multiple times at no cost.
                    break :TEST;
                }

                //
                let r       = chars.parse7bit(:offset);
                lax let sr  = chars.walkPaths(:offset, tailOK: true);

                each(continue_keep?: fn continue_keep,
                    continue_climb?: fn continue_climb,
                  continue_replace?: fn continue_replace,

                    // Same as above.
                    locid?:     r.unpackLocid,
                    argidx?:    i32(r & 1 ? r >> 2 : 0),
                    isStatic?:  r.isStaticOrZeroes,
                    isTemp?:    r.isTemporary,
                    isArgIdx?:  r.isArgIdx,

                    paths?:     chars[sr .. offset]);

                continue;
            }

            if (maybeOutOfOrder)
                result = Lifetime_union(result,
                    Lifetime(uni0n: chars.slice(offset0, offset)));
            else
                result.uni0n ~= chars[offset0 .. offset];
        }
    }

    visit(lifetime);

    return result;
}


//

pub let Lifetime_static_moveable =
    Lifetime(uni0n: Region_ZEROES);

pub let Lifetime_static_immoveable =
    Lifetime(uni0n: Region_STATIC);

pub let Lifetime_temporary =
    Lifetime(uni0n: Region_TEMP);

pub fn hasTemporary(lifetime: Lifetime): bool
    lifetime.uni0n.starts(with: Region_TEMP);

pub fn hasStatic(lifetime: Lifetime): bool {
    let n = lifetime.uni0n.len;
    return n >= 3
        && lifetime.uni0n[n - 2 ..] == SR_empty
        && lifetime.uni0n[n - 3].u32.isStaticOrZeroes;
}

pub fn isStaticOrZeroes(lifetime: Lifetime): bool {
    return lifetime.uni0n.len == 3
        && lifetime.uni0n[0].u32.isStaticOrZeroes;
}


// TODO worst := temp | static
//
// My thinking is, if you really don't want to rely on any guarantees a lifetime gives you,
//  temporary means you can't rely on it surviving, and static means you can't move from it.

pub let Lifetime_worst = Lifetime_temporary;


//

pub fn Lifetime_some(lifetime: Lifetime, some)
{
    Lifetime_each(:lifetime):
        |locid, argidx, isStatic, isTemp, isArgIdx, isAlwaysMoveable|
    {
        if (some(?:locid,    ?:argidx,
                 ?:isStatic, ?:isTemp, ?:isAlwaysMoveable,
                 ?:isArgIdx))
        {
            return true;
        }
    }

    return false;
}

pub fn Lifetime_if_only(lifetime: Lifetime, if_only)
{
    Lifetime_each(:lifetime):
        |isOnly, locid, argidx, isStatic, isTemp, isArgIdx, isAlwaysMoveable|
    {
        return isOnly && if_only(?:locid,    ?:argidx,
                                 ?:isStatic, ?:isTemp, ?:isAlwaysMoveable,
                                 ?:isArgIdx);
    }

    return [];
}

pub fn Lifetime_has(lifetime: Lifetime, locid!search: i32)
    lifetime.Lifetime_some(
        |locid| locid == search);

pub fn Lifetime_has(lifetime: Lifetime, argidx!search: i32)
    lifetime.Lifetime_some(
        |isArgIdx, argidx| isArgIdx && argidx == search);

pub fn Lifetime_makeShared(lifetime: Lifetime, flatCount!: i32): Lifetime =
    Lifetime_union(
        Lifetime_op_deref(lifetime, :flatCount),
        Lifetime_static_immoveable);


/*
    We have three operations on lifetimes:

    .field:     Innermost subregion flatCount -= (>= 0), offset += (>= 0),
                    we're selecting a single field from a structure.

    *deref:     We append a new region, flatCount = dereferencedType.flatCount, offset = 0,
                    we're selecting an array item.

    join:       We're replacing a reference with whatever it is refering to,
                    and we join parent lifetime ~ child paths,
                        glueing the innermost parent subregion
                            with the outermost child subregion.

                Feels like the last one is an N*M situation unfortunately.
*/

inline fn Lifetime_op(lt: Lifetime, each, minPathDepth! = 1)
{
    mut result: byte[];

    lt.Lifetime_each: |r_raw, paths, lax locid, lax isStatic, lax isTemp|
    {
        result ~= r_raw;

        if (paths == SR_empty)
        {
            result ~= paths;
            continue;
        }

        if (SELF_TEST)
            locid || BUG("Lifetime_op: non-locid non-x00x00 subregion.");

        //
        lax let result0 = result.len;

        each(:result, :paths);

        assertPathsValid(result[result0 ..], :minPathDepth);
    }

    return Lifetime(uni0n: result);
}

pub fn Lifetime_op_field(lt: Lifetime, flatCount: i32, flatOffset: i32)
{
    return lt.Lifetime_op(|paths, ref result|
    {
        mut offset = 0;
        paths.walkPaths(:offset,

            onLastSubRegion: |isLastSubRegion, isLastPath, raw_prefix, lax flatCount!struct_flatCount, flatOffset!struct_flatOffset|
            {
                if (SELF_TEST)
                    flatCount + flatOffset <= struct_flatCount || BUG(
                        "Lifetime_op_field: field.flatOffset(" ~ flatOffset ~ ")"
                            ~ " + field.flatCount(" ~ flatCount ~ ")"
                            ~ " !<= struct.flatCount(" ~ struct_flatCount ~ ")");

                result ~= raw_prefix;
                result.appendSubRegion(
                    :flatCount, :isLastSubRegion, :isLastPath,
                    flatOffset: struct_flatOffset + flatOffset);
            });
    });
}

pub fn Lifetime_op_mask(lt: Lifetime, quals: Quals)
{
    let usage       = quals & usage::q_USAGE;
    let clz         = usage.bit::clz;
    let ctz         = usage.bit::ctz;

    let flatOffset  = ctz     - usage::q_USAGE_offset;
    let flatCount   = usage && (usage::q_USAGE_bitsize - flatOffset - clz);

    if (SELF_TEST)
        flatCount > 0 || BUG("Lifetime_op_mask: flatCount(" ~ flatCount ~ ") flatOffset(" ~ flatOffset ~ ") clz(" ~ clz ~ ") ctz(" ~ ctz ~ ") usage(" ~ usage ~ ")");

    lt.Lifetime_each: |paths|
    {
        mut offset = 0;
        paths.walkPaths(:offset,

            onLastSubRegion: |isLastSubRegion, isLastPath, raw_prefix, lax flatCount!struct_flatCount|
            {
                if (struct_flatCount > usage::q_USAGE_bitsize)
                    return lt;

                if (SELF_TEST)
                    struct_flatCount >= flatCount || BUG(
                        "Lifetime_op_mask: struct_flatCount(" ~ struct_flatCount ~ ") !>= flatCount(" ~ flatCount ~ ")");

                return lt.Lifetime_op_field(:flatCount, :flatOffset);
            });
    }

    BUG("Lifetime_op_mask: empty lifetime.");
}

pub fn Lifetime_op_deref(lt: Lifetime, flatCount!deref_flatCount: i32)
{
    return lt.Lifetime_op(minPathDepth: 2, |paths, ref result|
    {
        mut offset = 0;
        paths.walkPaths(:offset,

            onLastSubRegion: |isLastPath, raw_prefix, flatCount!parent_flatCount, flatOffset!parent_flatOffset|
            {
                if (SELF_TEST)
                    parent_flatCount == 1 || BUG("Lifetime_op_deref: parent_flatCount(" ~ parent_flatCount ~ ") != 1");

                result ~= raw_prefix;

                result.appendSubRegion(
                    flatCount:  parent_flatCount,
                    flatOffset: parent_flatOffset,
                    :isLastPath, isLastSubRegion: false);

                // This is the actual deref.
                result.appendSubRegion(
                    flatCount:  deref_flatCount,
                    flatOffset: 0,
                    :isLastPath, isLastSubRegion: true);
            });
    });
}

pub fn Lifetime_op_join(lt: Lifetime, paths!child: byte[..])
{
    return lt.Lifetime_op(|paths!parent, ref result|
    {
        mut _p0 = 0;
        parent.walkPaths(offset: _p0,

            onLastSubRegion: |
                isLastPath      !parent_isLastPath,

            lax flatCount       !parent_flatCount,
                flatOffset      !parent_flatOffset,

                raw_prefix      !parent_rawPrefix|
            {
                // So we've got the raw parent prefix,
                //  the last parent subregion flatCount and flatOffsets.
                //
                // We offset each final parent flatOffset
                //  with each head offset of the child path,
                //   this is an N*M combo + needs uniqueness:
                //
                // Last Parent Subregion: [ parentOffset0, parentOffset1 ]
                // First Child Subregion: [ childOffset0, childOffset1 ]
                //
                // Resulting Subregion: [ p0 + c0, p0 + c1, p1 + c0, p1 + c1 ]
                //
                mut _c0 = 0;
                child.walkPaths(offset: _c0,

                    onSubRegion: |
                        isFirstSubRegion    !child_isFirstSubRegion,
                        isLastSubRegion     !child_isLastSubRegion,
                        isLastPath          !child_isLastPath,

                        flatCount           !child_flatCount,
                        flatOffset          !child_flatOffset|
                    {
                        // Begin a new path -
                        //  take everything from parent path,
                        //   up to the final subregion.
                        //
                        if (child_isFirstSubRegion)
                            result ~= parent_rawPrefix;

                        let result_flatOffset =
                            !child_isFirstSubRegion ? child_flatOffset :
                            {
                                if (SELF_TEST)
                                    child_flatOffset + child_flatCount <= parent_flatCount || BUG(
                                        "Lifetime_op_join: child_flatOffset(" ~ child_flatOffset ~ ")"
                                            ~ " + child_flatCount(" ~ child_flatCount ~ ")"
                                            ~ " !<= parent_flatCount(" ~ parent_flatCount ~ ")");

                                child_flatOffset + parent_flatOffset
                            };

                        // Use the child flatCount.
                        result.appendSubRegion(
                            flatCount:          child_flatCount,
                            flatOffset:         result_flatOffset,
                            isLastSubRegion:    child_isLastSubRegion,
                            isLastPath:         parent_isLastPath && child_isLastPath);
                    });
            });
    });
}

pub fn solve()
{
    struct Flow
    {
        rg_invalidates:     [];
    };

    struct CurrentFn
    {
        using flow?:        Flow;
    };

    lax mut _current_fn:        CurrentFn;

    fn PASS_borrowCheck() {
        fn flow = _current_fn.flow;
        fn bck_trackWrites(callOrPragma: SolvedNode, lifetime: Lifetime)
            lifetime.Lifetime_each: |locid!write, paths!write_paths|
                lax let invalidates = flow.rg_invalidates.if(exists: write);
    }
}
