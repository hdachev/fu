import lexer;
import parser;
import types;
import scope;
import helpers;

pub nocopy struct Context
{
    modules: Module[];

    // FS facts.
    files: Map(string, string);
    fuzzy: Map(string, string);
};


//

pub fn _token(implicit ctx: Context, idx: TokenIdx): Token
    ctx.modules[idx.modid].in.lex.tokens[idx.tokidx];

pub fn _fname(implicit ctx: Context, idx: TokenIdx): string
    ctx.modules[idx.modid].fname;


//

fn resolveFile(
    implicit ctx: &mut Context,
    from: string, name: string): string
{
    let path    = from ~ name;
    let cached  = ctx.fuzzy[path];
    if (cached)
        return cached == "\v" ? "" : cached;

    fn tryResolve(): string
    {
        let exists = file::size(path) >= 0;
        if (exists)
            return path;

        // TODO FIX
        {
            shadow let path = from ~ "lib/" ~ name;
            shadow let exists = file::size(path) >= 0;
            if (exists)
                return path;
        }

        // TODO FIX
        {
            shadow let path = from ~ "vendor/" ~ name;
            shadow let exists = file::size(path) >= 0;
            if (exists)
                return path;
        }

        // TODO FIX
        {
            shadow let path = from ~ "fu/lib/" ~ name;
            shadow let exists = file::size(path) >= 0;
            if (exists)
                return path;
        }

        /////////////////////////////////
        let fallback = from.path_dirname;
        if (!fallback || fallback.len >= from.len)
            return "";

        return resolveFile(
            from: fallback, :name);
    };

    let resolve = tryResolve();
    ctx.fuzzy[path] = resolve || "\v";
    return resolve;
}

pub fn resolveFile(
    implicit ctx: &mut Context,
    path: string): string
{
    let fuzzy = path.find('\v');
    if (fuzzy > 0)
    {
        let from = path.slice(0, fuzzy);
        let name = path.slice(fuzzy + 1);
        if (from && name && !name.has('\v'))
        {
            let res = resolveFile(:from, :name);
            if (res)
                return res;

            // Tests have the files prepopulated,
            //  we only pay the cost of lookup when about to fail compile.
            let prepopulated = from ~ name;
            if (ctx.files.has(prepopulated))
                return prepopulated;
        }
    }

    return path;
}

pub fn resolveFile_x(
    implicit ctx: Context,
    path: string)
{
    // TODO FIX
    let clean = path.replace(all: "\v", "");
    let match = ctx.fuzzy[clean];

    return match && match != "\v"
         ? match
         : clean;
}


//

pub fn getFile(
    implicit ctx: &mut Context,
    mut path: string): string
{
    let cached = ctx.files[path];
    if (cached)
        return cached == "\v" ? "" : cached;

    let read = file::read(path);
    ctx.files[path] = read || "\v";
    return read;
}

pub fn getModule(
    implicit ctx: &mut Context,
    fname: string)
{
    for (mut i = 0; i < ctx.modules.len; i++)
        if (ctx.modules[i].fname == fname)
            return ctx.modules[i];

    let i = ctx.modules.len;
    ctx.modules.push(Module(modid: i, :fname));
    return ctx.modules[i];
}

pub fn setModule(
    implicit ctx: &mut Context,
    module: Module)
{
    ref current = ctx.modules[module.modid];
    current.fname == module.fname || assert();
    current = module.clone();
}


//

pub fn lookupStruct(
    implicit module: Module,
    implicit ctx: Context,
    type: Type)
{
    if (type.modid == module.modid)
        return module.out.types[type.canon.structIndex]
            || assert();

    return ctx.modules[type.modid].out.types[type.canon.structIndex]
        || assert();
}

pub fn tryLookupStruct(type: Type)
    type.isStruct && lookupStruct(type);

pub fn lookupTypeImports(type: Type)
    tryLookupStruct(type).imports;

pub fn lookupTypeConverts(type: Type)
    tryLookupStruct(type).converts;


//

pub fn formatCodeSnippet(implicit ctx: Context, to: TokenIdx, mut from?: TokenIdx, extraLines = 2): string
{
    let src     = ctx.modules[to.modid].in.src;
    let lines   = src.split("\n");

    let start   = (from || to)._token;
    let end     = to._token;

    mut l_start = start.line - extraLines - 1;  // lines are 1 based.
    mut l_end   =   end.line + extraLines;

    l_start     = l_start.max(0);
    l_end       = l_end  .min(lines.len);

    // TODO use color to highlight the offending line & token
    //
    // FUN syntax highlight the thing!
    //  Could use the lexer to re-lex
    //   and add colors to each token value.

    mut result  = "";
    for (mut i = l_start; i < l_end; i++)
    {
        // Extra lines: dim color, no line number
        if (i < start.line - 1 || i >= end.line) {
            result ~= ansi::DIM ~ "      | ";
        }
        else {
            mut margin = (i + 1) ~ " | ";
            while (margin.len < 8)
                margin = " " ~ margin;

            result ~= margin;
        }

        mut line = lines[i];

        // Highlight error token -
        //  note this will break for string literals with escapes but whatever,
        //   I guess we do need the end column coordinate.
        if (i == end.line - 1)
        {
            let c0 = (end.col - 1).max(0);
            let c1 = c0 + end.value.len.min(line.len);

            line.splice(c1, 0, ansi::RESET);
            line.splice(c0, 0, ansi::BAD);
        }

        result ~= line;

        // Reset ansi coloring.
        if (i < start.line - 1 || i >= end.line)
            result ~= ansi::RESET;

        result ~= "\n";
    }

    return result;
}
